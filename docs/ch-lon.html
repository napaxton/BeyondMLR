<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Two-Level Longitudinal Data | Beyond Multiple Linear Regression</title>
  <meta name="description" content="An applied textbook on generalized linear models and multilevel models for advanced undergraduates, featuring many real, unique data sets. It is intended to be accessible to undergraduate students who have successfully completed a regression course. Even though there is no mathematical prerequisite, we still introduce fairly sophisticated topics such as likelihood theory, zero-inflated Poisson, and parametric bootstrapping in an intuitive and applied manner. We believe strongly in case studies featuring real data and real research questions; thus, most of the data in the textbook arises from collaborative research conducted by the authors and their students, or from student projects. Our goal is that, after working through this material, students will develop an expanded toolkit and a greater appreciation for the wider world of data and statistical modeling." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Two-Level Longitudinal Data | Beyond Multiple Linear Regression" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="data/book_cover.jpg" />
  <meta property="og:description" content="An applied textbook on generalized linear models and multilevel models for advanced undergraduates, featuring many real, unique data sets. It is intended to be accessible to undergraduate students who have successfully completed a regression course. Even though there is no mathematical prerequisite, we still introduce fairly sophisticated topics such as likelihood theory, zero-inflated Poisson, and parametric bootstrapping in an intuitive and applied manner. We believe strongly in case studies featuring real data and real research questions; thus, most of the data in the textbook arises from collaborative research conducted by the authors and their students, or from student projects. Our goal is that, after working through this material, students will develop an expanded toolkit and a greater appreciation for the wider world of data and statistical modeling." />
  <meta name="github-repo" content="proback/BeyondMLR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Two-Level Longitudinal Data | Beyond Multiple Linear Regression" />
  
  <meta name="twitter:description" content="An applied textbook on generalized linear models and multilevel models for advanced undergraduates, featuring many real, unique data sets. It is intended to be accessible to undergraduate students who have successfully completed a regression course. Even though there is no mathematical prerequisite, we still introduce fairly sophisticated topics such as likelihood theory, zero-inflated Poisson, and parametric bootstrapping in an intuitive and applied manner. We believe strongly in case studies featuring real data and real research questions; thus, most of the data in the textbook arises from collaborative research conducted by the authors and their students, or from student projects. Our goal is that, after working through this material, students will develop an expanded toolkit and a greater appreciation for the wider world of data and statistical modeling." />
  <meta name="twitter:image" content="data/book_cover.jpg" />

<meta name="author" content="Paul Roback and Julie Legler" />


<meta name="date" content="2021-01-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-multilevelintro.html"/>
<link rel="next" href="ch-3level.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block/empty-anchor.js"></script>
<script src="libs/kePrint/kePrint.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Beyond Multiple Linear Regression</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#description"><i class="fa fa-check"></i>Description</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-authors"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#versions-of-r-packages-used"><i class="fa fa-check"></i>Versions of R Packages Used</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html"><i class="fa fa-check"></i><b>1</b> Review of Multiple Linear Regression</a><ul>
<li class="chapter" data-level="1.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="1.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#introduction-to-beyond-multiple-linear-regression"><i class="fa fa-check"></i><b>1.2</b> Introduction to Beyond Multiple Linear Regression</a></li>
<li class="chapter" data-level="1.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#assumptions-for-linear-least-squares-regression"><i class="fa fa-check"></i><b>1.3</b> Assumptions for Linear Least Squares Regression</a><ul>
<li class="chapter" data-level="1.3.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#cases-without-assumption-violations"><i class="fa fa-check"></i><b>1.3.1</b> Cases Without Assumption Violations</a></li>
<li class="chapter" data-level="1.3.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#cases-with-assumption-violations"><i class="fa fa-check"></i><b>1.3.2</b> Cases With Assumption Violations</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#review-of-multiple-linear-regression"><i class="fa fa-check"></i><b>1.4</b> Review of Multiple Linear Regression</a><ul>
<li class="chapter" data-level="1.4.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#cs:derby"><i class="fa fa-check"></i><b>1.4.1</b> Case Study: Kentucky Derby</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#explorech1"><i class="fa fa-check"></i><b>1.5</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="1.5.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#data-organization"><i class="fa fa-check"></i><b>1.5.1</b> Data Organization</a></li>
<li class="chapter" data-level="1.5.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#univariate-summaries"><i class="fa fa-check"></i><b>1.5.2</b> Univariate Summaries</a></li>
<li class="chapter" data-level="1.5.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#bivariate-summaries"><i class="fa fa-check"></i><b>1.5.3</b> Bivariate Summaries</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg"><i class="fa fa-check"></i><b>1.6</b> Multiple Linear Regression Modeling</a><ul>
<li class="chapter" data-level="1.6.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#SLRcontinuous"><i class="fa fa-check"></i><b>1.6.1</b> Simple Linear Regression with a Continuous Predictor</a></li>
<li class="chapter" data-level="1.6.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#linear-regression-with-a-binary-predictor"><i class="fa fa-check"></i><b>1.6.2</b> Linear Regression with a Binary Predictor</a></li>
<li class="chapter" data-level="1.6.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multiple-linear-regression-with-two-predictors"><i class="fa fa-check"></i><b>1.6.3</b> Multiple Linear Regression with Two Predictors</a></li>
<li class="chapter" data-level="1.6.4" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg-inference"><i class="fa fa-check"></i><b>1.6.4</b> Inference in Multiple Linear Regression: Normal Theory</a></li>
<li class="chapter" data-level="1.6.5" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg-boot"><i class="fa fa-check"></i><b>1.6.5</b> Inference in Multiple Linear Regression: Bootstrapping</a></li>
<li class="chapter" data-level="1.6.6" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multiple-linear-regression-with-an-interaction-term"><i class="fa fa-check"></i><b>1.6.6</b> Multiple Linear Regression with an Interaction Term</a></li>
<li class="chapter" data-level="1.6.7" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg_build"><i class="fa fa-check"></i><b>1.6.7</b> Building a Multiple Linear Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#preview-of-remaining-chapters"><i class="fa fa-check"></i><b>1.7</b> Preview of Remaining Chapters</a><ul>
<li class="chapter" data-level="1.7.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#soccer"><i class="fa fa-check"></i><b>1.7.1</b> Soccer</a></li>
<li class="chapter" data-level="1.7.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#elephant-mating"><i class="fa fa-check"></i><b>1.7.2</b> Elephant Mating</a></li>
<li class="chapter" data-level="1.7.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#parenting-and-gang-activity"><i class="fa fa-check"></i><b>1.7.3</b> Parenting and Gang Activity</a></li>
<li class="chapter" data-level="1.7.4" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#crime"><i class="fa fa-check"></i><b>1.7.4</b> Crime</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a><ul>
<li class="chapter" data-level="1.8.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#conceptual-exercises"><i class="fa fa-check"></i><b>1.8.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="1.8.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#guided-exercises"><i class="fa fa-check"></i><b>1.8.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="1.8.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#open-ended-exercises"><i class="fa fa-check"></i><b>1.8.3</b> Open-Ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html"><i class="fa fa-check"></i><b>2</b> Beyond Least Squares: Using Likelihoods</a><ul>
<li class="chapter" data-level="2.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#learning-objectives-1"><i class="fa fa-check"></i><b>2.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#case-study-does-sex-run-in-families"><i class="fa fa-check"></i><b>2.2</b> Case Study: Does Sex Run in Families?</a><ul>
<li class="chapter" data-level="2.2.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#research-questions"><i class="fa fa-check"></i><b>2.2.1</b> Research Questions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-0-sex-unconditional-equal-probabilities"><i class="fa fa-check"></i><b>2.3</b> Model 0: Sex Unconditional, Equal Probabilities</a></li>
<li class="chapter" data-level="2.4" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sex_unconditional_model"><i class="fa fa-check"></i><b>2.4</b> Model 1: Sex Unconditional, Unequal Probabilities</a><ul>
<li class="chapter" data-level="2.4.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#what-is-a-likelihood"><i class="fa fa-check"></i><b>2.4.1</b> What Is a Likelihood?</a></li>
<li class="chapter" data-level="2.4.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#findMLE.sec"><i class="fa fa-check"></i><b>2.4.2</b> Finding MLEs</a></li>
<li class="chapter" data-level="2.4.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#summary"><i class="fa fa-check"></i><b>2.4.3</b> Summary</a></li>
<li class="chapter" data-level="2.4.4" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#is-a-likelihood-a-probability-function-optional"><i class="fa fa-check"></i><b>2.4.4</b> Is a Likelihood a Probability Function? (optional)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sex_conditional.sec"><i class="fa fa-check"></i><b>2.5</b> Model 2: Sex Conditional</a><ul>
<li class="chapter" data-level="2.5.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-specification"><i class="fa fa-check"></i><b>2.5.1</b> Model Specification</a></li>
<li class="chapter" data-level="2.5.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#application-to-hypothetical-data"><i class="fa fa-check"></i><b>2.5.2</b> Application to Hypothetical Data</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#case-study-analysis-of-the-nlsy-data"><i class="fa fa-check"></i><b>2.6</b> Case Study: Analysis of the NLSY Data</a><ul>
<li class="chapter" data-level="2.6.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-building-plan"><i class="fa fa-check"></i><b>2.6.1</b> Model Building Plan</a></li>
<li class="chapter" data-level="2.6.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#EDA.sec"><i class="fa fa-check"></i><b>2.6.2</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="2.6.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#likelihood-for-the-sex-unconditional-model"><i class="fa fa-check"></i><b>2.6.3</b> Likelihood for the Sex Unconditional Model</a></li>
<li class="chapter" data-level="2.6.4" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sex-cond-lik"><i class="fa fa-check"></i><b>2.6.4</b> Likelihood for the Sex Conditional Model</a></li>
<li class="chapter" data-level="2.6.5" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sec-lrtest"><i class="fa fa-check"></i><b>2.6.5</b> Model Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-3-stopping-rule-model-waiting-for-a-boy"><i class="fa fa-check"></i><b>2.7</b> Model 3: Stopping Rule Model (waiting for a boy)</a><ul>
<li class="chapter" data-level="2.7.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#non-nested-models"><i class="fa fa-check"></i><b>2.7.1</b> Non-nested Models</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#summary-of-model-building"><i class="fa fa-check"></i><b>2.8</b> Summary of Model Building</a></li>
<li class="chapter" data-level="2.9" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#likelihood-based-methods"><i class="fa fa-check"></i><b>2.9</b> Likelihood-Based Methods</a></li>
<li class="chapter" data-level="2.10" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#likelihoods-and-this-course"><i class="fa fa-check"></i><b>2.10</b> Likelihoods and This Course</a></li>
<li class="chapter" data-level="2.11" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#exercises-1"><i class="fa fa-check"></i><b>2.11</b> Exercises</a><ul>
<li class="chapter" data-level="2.11.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#conceptual-exercises-1"><i class="fa fa-check"></i><b>2.11.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="2.11.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#guided-exercises-1"><i class="fa fa-check"></i><b>2.11.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="2.11.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#open-ended-exercises-1"><i class="fa fa-check"></i><b>2.11.3</b> Open-Ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-distthry.html"><a href="ch-distthry.html"><i class="fa fa-check"></i><b>3</b> Distribution Theory</a><ul>
<li class="chapter" data-level="3.1" data-path="ch-distthry.html"><a href="ch-distthry.html#learning-objectives-2"><i class="fa fa-check"></i><b>3.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="3.2" data-path="ch-distthry.html"><a href="ch-distthry.html#introduction"><i class="fa fa-check"></i><b>3.2</b> Introduction</a></li>
<li class="chapter" data-level="3.3" data-path="ch-distthry.html"><a href="ch-distthry.html#discrete-random-variables"><i class="fa fa-check"></i><b>3.3</b> Discrete Random Variables</a><ul>
<li class="chapter" data-level="3.3.1" data-path="ch-distthry.html"><a href="ch-distthry.html#sec-binary"><i class="fa fa-check"></i><b>3.3.1</b> Binary Random Variable</a></li>
<li class="chapter" data-level="3.3.2" data-path="ch-distthry.html"><a href="ch-distthry.html#sec-binomial"><i class="fa fa-check"></i><b>3.3.2</b> Binomial Random Variable</a></li>
<li class="chapter" data-level="3.3.3" data-path="ch-distthry.html"><a href="ch-distthry.html#geometric-random-variable"><i class="fa fa-check"></i><b>3.3.3</b> Geometric Random Variable</a></li>
<li class="chapter" data-level="3.3.4" data-path="ch-distthry.html"><a href="ch-distthry.html#negative-binomial-random-variable"><i class="fa fa-check"></i><b>3.3.4</b> Negative Binomial Random Variable</a></li>
<li class="chapter" data-level="3.3.5" data-path="ch-distthry.html"><a href="ch-distthry.html#hypergeometric-random-variable"><i class="fa fa-check"></i><b>3.3.5</b> Hypergeometric Random Variable</a></li>
<li class="chapter" data-level="3.3.6" data-path="ch-distthry.html"><a href="ch-distthry.html#poisson-random-variable"><i class="fa fa-check"></i><b>3.3.6</b> Poisson Random Variable</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ch-distthry.html"><a href="ch-distthry.html#continuous-random-variables"><i class="fa fa-check"></i><b>3.4</b> Continuous Random Variables</a><ul>
<li class="chapter" data-level="3.4.1" data-path="ch-distthry.html"><a href="ch-distthry.html#exponential-random-variable"><i class="fa fa-check"></i><b>3.4.1</b> Exponential Random Variable</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch-distthry.html"><a href="ch-distthry.html#gamma-random-variable"><i class="fa fa-check"></i><b>3.4.2</b> Gamma Random Variable</a></li>
<li class="chapter" data-level="3.4.3" data-path="ch-distthry.html"><a href="ch-distthry.html#normal-gaussian-random-variable"><i class="fa fa-check"></i><b>3.4.3</b> Normal (Gaussian) Random Variable</a></li>
<li class="chapter" data-level="3.4.4" data-path="ch-distthry.html"><a href="ch-distthry.html#beta-random-variable"><i class="fa fa-check"></i><b>3.4.4</b> Beta Random Variable</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ch-distthry.html"><a href="ch-distthry.html#distributions-used-in-testing"><i class="fa fa-check"></i><b>3.5</b> Distributions Used in Testing</a><ul>
<li class="chapter" data-level="3.5.1" data-path="ch-distthry.html"><a href="ch-distthry.html#chi2-distribution"><i class="fa fa-check"></i><b>3.5.1</b> <span class="math inline">\(\chi^2\)</span> Distribution</a></li>
<li class="chapter" data-level="3.5.2" data-path="ch-distthry.html"><a href="ch-distthry.html#students-t-distribution"><i class="fa fa-check"></i><b>3.5.2</b> Student’s <span class="math inline">\(t\)</span>-Distribution</a></li>
<li class="chapter" data-level="3.5.3" data-path="ch-distthry.html"><a href="ch-distthry.html#f-distribution"><i class="fa fa-check"></i><b>3.5.3</b> <span class="math inline">\(F\)</span>-Distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ch-distthry.html"><a href="ch-distthry.html#additional-resources"><i class="fa fa-check"></i><b>3.6</b> Additional Resources</a></li>
<li class="chapter" data-level="3.7" data-path="ch-distthry.html"><a href="ch-distthry.html#exercises-2"><i class="fa fa-check"></i><b>3.7</b> Exercises</a><ul>
<li class="chapter" data-level="3.7.1" data-path="ch-distthry.html"><a href="ch-distthry.html#conceptual-exercises-2"><i class="fa fa-check"></i><b>3.7.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="3.7.2" data-path="ch-distthry.html"><a href="ch-distthry.html#guided-exercises-2"><i class="fa fa-check"></i><b>3.7.2</b> Guided Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html"><i class="fa fa-check"></i><b>4</b> Poisson Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#learning-objectives-3"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#introduction-to-poisson-regression"><i class="fa fa-check"></i><b>4.2</b> Introduction to Poisson Regression</a><ul>
<li class="chapter" data-level="4.2.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#poisson-regression-assumptions"><i class="fa fa-check"></i><b>4.2.1</b> Poisson Regression Assumptions</a></li>
<li class="chapter" data-level="4.2.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#a-graphical-look-at-poisson-regression"><i class="fa fa-check"></i><b>4.2.2</b> A Graphical Look at Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#case-studies-overview"><i class="fa fa-check"></i><b>4.3</b> Case Studies Overview</a></li>
<li class="chapter" data-level="4.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#cs-philippines"><i class="fa fa-check"></i><b>4.4</b> Case Study: Household Size in the Philippines</a><ul>
<li class="chapter" data-level="4.4.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#organizedata4"><i class="fa fa-check"></i><b>4.4.1</b> Data Organization</a></li>
<li class="chapter" data-level="4.4.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exploreHH"><i class="fa fa-check"></i><b>4.4.2</b> Exploratory Data Analyses</a></li>
<li class="chapter" data-level="4.4.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-PoisInference"><i class="fa fa-check"></i><b>4.4.3</b> Estimation and Inference</a></li>
<li class="chapter" data-level="4.4.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-Devtocompare"><i class="fa fa-check"></i><b>4.4.4</b> Using Deviances to Compare Models</a></li>
<li class="chapter" data-level="4.4.5" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#likelihood.sec"><i class="fa fa-check"></i><b>4.4.5</b> Using Likelihoods to Fit Models (optional)</a></li>
<li class="chapter" data-level="4.4.6" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#second-order-model"><i class="fa fa-check"></i><b>4.4.6</b> Second Order Model</a></li>
<li class="chapter" data-level="4.4.7" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#adding-a-covariate"><i class="fa fa-check"></i><b>4.4.7</b> Adding a Covariate</a></li>
<li class="chapter" data-level="4.4.8" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-PoisResid"><i class="fa fa-check"></i><b>4.4.8</b> Residuals for Poisson Models (optional)</a></li>
<li class="chapter" data-level="4.4.9" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-PoisGOF"><i class="fa fa-check"></i><b>4.4.9</b> Goodness-of-Fit</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#linear-least-squares-vs.-poisson-regression"><i class="fa fa-check"></i><b>4.5</b> Linear Least Squares  vs. Poisson Regression </a></li>
<li class="chapter" data-level="4.6" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#case-study-campus-crime"><i class="fa fa-check"></i><b>4.6</b> Case Study: Campus Crime</a><ul>
<li class="chapter" data-level="4.6.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#data-organization-1"><i class="fa fa-check"></i><b>4.6.1</b> Data Organization</a></li>
<li class="chapter" data-level="4.6.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>4.6.2</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="4.6.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#accounting-for-enrollment"><i class="fa fa-check"></i><b>4.6.3</b> Accounting for Enrollment</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#modeling-assumptions"><i class="fa fa-check"></i><b>4.7</b> Modeling Assumptions</a></li>
<li class="chapter" data-level="4.8" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#initial-models"><i class="fa fa-check"></i><b>4.8</b> Initial Models</a><ul>
<li class="chapter" data-level="4.8.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#tukeys-honestly-significant-differences"><i class="fa fa-check"></i><b>4.8.1</b> Tukey’s Honestly Significant Differences</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-overdispPois"><i class="fa fa-check"></i><b>4.9</b> Overdispersion</a><ul>
<li class="chapter" data-level="4.9.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#dispersion-parameter-adjustment"><i class="fa fa-check"></i><b>4.9.1</b> Dispersion Parameter Adjustment</a></li>
<li class="chapter" data-level="4.9.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#no-dispersion-vs.-overdispersion"><i class="fa fa-check"></i><b>4.9.2</b> No Dispersion vs. Overdispersion</a></li>
<li class="chapter" data-level="4.9.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#negative-binomial-modeling"><i class="fa fa-check"></i><b>4.9.3</b> Negative Binomial Modeling</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#cs:drinking"><i class="fa fa-check"></i><b>4.10</b> Case Study: Weekend Drinking</a><ul>
<li class="chapter" data-level="4.10.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#research-question"><i class="fa fa-check"></i><b>4.10.1</b> Research Question</a></li>
<li class="chapter" data-level="4.10.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#data-organization-2"><i class="fa fa-check"></i><b>4.10.2</b> Data Organization</a></li>
<li class="chapter" data-level="4.10.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exploratory-data-analysis-1"><i class="fa fa-check"></i><b>4.10.3</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="4.10.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#modeling"><i class="fa fa-check"></i><b>4.10.4</b> Modeling</a></li>
<li class="chapter" data-level="4.10.5" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#fitting-a-zip-model"><i class="fa fa-check"></i><b>4.10.5</b> Fitting a ZIP Model</a></li>
<li class="chapter" data-level="4.10.6" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#the-vuong-test-optional"><i class="fa fa-check"></i><b>4.10.6</b> The Vuong Test (optional)</a></li>
<li class="chapter" data-level="4.10.7" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#residual-plot"><i class="fa fa-check"></i><b>4.10.7</b> Residual Plot</a></li>
<li class="chapter" data-level="4.10.8" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#limitations"><i class="fa fa-check"></i><b>4.10.8</b> Limitations</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exercises-3"><i class="fa fa-check"></i><b>4.11</b> Exercises</a><ul>
<li class="chapter" data-level="4.11.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exer:concept"><i class="fa fa-check"></i><b>4.11.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="4.11.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#guided-exercises-3"><i class="fa fa-check"></i><b>4.11.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="4.11.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#open-ended-exercises-2"><i class="fa fa-check"></i><b>4.11.3</b> Open-Ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-glms.html"><a href="ch-glms.html"><i class="fa fa-check"></i><b>5</b> Generalized Linear Models: A Unifying Theory</a><ul>
<li class="chapter" data-level="5.1" data-path="ch-glms.html"><a href="ch-glms.html#learning-objectives-4"><i class="fa fa-check"></i><b>5.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="ch-glms.html"><a href="ch-glms.html#one-parameter-exponential-families"><i class="fa fa-check"></i><b>5.2</b> One-Parameter Exponential Families</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ch-glms.html"><a href="ch-glms.html#one-parameter-exponential-family-poisson"><i class="fa fa-check"></i><b>5.2.1</b> One-Parameter Exponential Family: Poisson</a></li>
<li class="chapter" data-level="5.2.2" data-path="ch-glms.html"><a href="ch-glms.html#one-parameter-exponential-family-normal"><i class="fa fa-check"></i><b>5.2.2</b> One-Parameter Exponential Family: Normal</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ch-glms.html"><a href="ch-glms.html#generalized-linear-modeling"><i class="fa fa-check"></i><b>5.3</b> Generalized Linear Modeling</a></li>
<li class="chapter" data-level="5.4" data-path="ch-glms.html"><a href="ch-glms.html#exercises-4"><i class="fa fa-check"></i><b>5.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-logreg.html"><a href="ch-logreg.html"><i class="fa fa-check"></i><b>6</b> Logistic Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="ch-logreg.html"><a href="ch-logreg.html#learning-objectives-5"><i class="fa fa-check"></i><b>6.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="ch-logreg.html"><a href="ch-logreg.html#introduction-to-logistic-regression"><i class="fa fa-check"></i><b>6.2</b> Introduction to Logistic Regression</a><ul>
<li class="chapter" data-level="6.2.1" data-path="ch-logreg.html"><a href="ch-logreg.html#logistic-regression-assumptions"><i class="fa fa-check"></i><b>6.2.1</b> Logistic Regression Assumptions</a></li>
<li class="chapter" data-level="6.2.2" data-path="ch-logreg.html"><a href="ch-logreg.html#a-graphical-look-at-logistic-regression"><i class="fa fa-check"></i><b>6.2.2</b> A Graphical Look at Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ch-logreg.html"><a href="ch-logreg.html#case-studies-overview-1"><i class="fa fa-check"></i><b>6.3</b> Case Studies Overview</a></li>
<li class="chapter" data-level="6.4" data-path="ch-logreg.html"><a href="ch-logreg.html#case-study-soccer-goalkeepers"><i class="fa fa-check"></i><b>6.4</b> Case Study: Soccer Goalkeepers</a><ul>
<li class="chapter" data-level="6.4.1" data-path="ch-logreg.html"><a href="ch-logreg.html#modeling-odds"><i class="fa fa-check"></i><b>6.4.1</b> Modeling Odds</a></li>
<li class="chapter" data-level="6.4.2" data-path="ch-logreg.html"><a href="ch-logreg.html#logistic-regression-models-for-binomial-responses"><i class="fa fa-check"></i><b>6.4.2</b> Logistic Regression Models for Binomial Responses</a></li>
<li class="chapter" data-level="6.4.3" data-path="ch-logreg.html"><a href="ch-logreg.html#theoretical-rationale-optional"><i class="fa fa-check"></i><b>6.4.3</b> Theoretical Rationale (optional)</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="ch-logreg.html"><a href="ch-logreg.html#case-study-reconstructing-alabama"><i class="fa fa-check"></i><b>6.5</b> Case Study: Reconstructing Alabama</a><ul>
<li class="chapter" data-level="6.5.1" data-path="ch-logreg.html"><a href="ch-logreg.html#data-organization-3"><i class="fa fa-check"></i><b>6.5.1</b> Data Organization</a></li>
<li class="chapter" data-level="6.5.2" data-path="ch-logreg.html"><a href="ch-logreg.html#exploratory-analyses"><i class="fa fa-check"></i><b>6.5.2</b> Exploratory Analyses</a></li>
<li class="chapter" data-level="6.5.3" data-path="ch-logreg.html"><a href="ch-logreg.html#initial-models-1"><i class="fa fa-check"></i><b>6.5.3</b> Initial Models</a></li>
<li class="chapter" data-level="6.5.4" data-path="ch-logreg.html"><a href="ch-logreg.html#sec-logisticInf"><i class="fa fa-check"></i><b>6.5.4</b> Tests for Significance of Model Coefficients</a></li>
<li class="chapter" data-level="6.5.5" data-path="ch-logreg.html"><a href="ch-logreg.html#confidence-intervals-for-model-coefficients"><i class="fa fa-check"></i><b>6.5.5</b> Confidence Intervals for Model Coefficients</a></li>
<li class="chapter" data-level="6.5.6" data-path="ch-logreg.html"><a href="ch-logreg.html#testing-for-goodness-of-fit"><i class="fa fa-check"></i><b>6.5.6</b> Testing for Goodness-of-Fit</a></li>
<li class="chapter" data-level="6.5.7" data-path="ch-logreg.html"><a href="ch-logreg.html#residuals-for-binomial-regression"><i class="fa fa-check"></i><b>6.5.7</b> Residuals for Binomial Regression</a></li>
<li class="chapter" data-level="6.5.8" data-path="ch-logreg.html"><a href="ch-logreg.html#sec-logOverdispersion"><i class="fa fa-check"></i><b>6.5.8</b> Overdispersion</a></li>
<li class="chapter" data-level="6.5.9" data-path="ch-logreg.html"><a href="ch-logreg.html#summary-1"><i class="fa fa-check"></i><b>6.5.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="ch-logreg.html"><a href="ch-logreg.html#linear-least-squares-vs.-binomial-regression"><i class="fa fa-check"></i><b>6.6</b> Linear Least Squares  vs. Binomial Regression </a></li>
<li class="chapter" data-level="6.7" data-path="ch-logreg.html"><a href="ch-logreg.html#case-study-trying-to-lose-weight"><i class="fa fa-check"></i><b>6.7</b> Case Study: Trying to Lose Weight</a><ul>
<li class="chapter" data-level="6.7.1" data-path="ch-logreg.html"><a href="ch-logreg.html#data-organization-4"><i class="fa fa-check"></i><b>6.7.1</b> Data Organization</a></li>
<li class="chapter" data-level="6.7.2" data-path="ch-logreg.html"><a href="ch-logreg.html#exploratory-data-analysis-2"><i class="fa fa-check"></i><b>6.7.2</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="6.7.3" data-path="ch-logreg.html"><a href="ch-logreg.html#initial-models-2"><i class="fa fa-check"></i><b>6.7.3</b> Initial Models</a></li>
<li class="chapter" data-level="6.7.4" data-path="ch-logreg.html"><a href="ch-logreg.html#drop-in-deviance-tests"><i class="fa fa-check"></i><b>6.7.4</b> Drop-in-Deviance Tests</a></li>
<li class="chapter" data-level="6.7.5" data-path="ch-logreg.html"><a href="ch-logreg.html#model-discussion-and-summary"><i class="fa fa-check"></i><b>6.7.5</b> Model Discussion and Summary</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="ch-logreg.html"><a href="ch-logreg.html#exercises-5"><i class="fa fa-check"></i><b>6.8</b> Exercises</a><ul>
<li class="chapter" data-level="6.8.1" data-path="ch-logreg.html"><a href="ch-logreg.html#conceptual-exercises-3"><i class="fa fa-check"></i><b>6.8.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="6.8.2" data-path="ch-logreg.html"><a href="ch-logreg.html#guided-exercises-4"><i class="fa fa-check"></i><b>6.8.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="6.8.3" data-path="ch-logreg.html"><a href="ch-logreg.html#open-ended-exercises-3"><i class="fa fa-check"></i><b>6.8.3</b> Open-Ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-corrdata.html"><a href="ch-corrdata.html"><i class="fa fa-check"></i><b>7</b> Correlated Data</a><ul>
<li class="chapter" data-level="7.1" data-path="ch-corrdata.html"><a href="ch-corrdata.html#learning-objectives-6"><i class="fa fa-check"></i><b>7.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="7.2" data-path="ch-corrdata.html"><a href="ch-corrdata.html#introduction-1"><i class="fa fa-check"></i><b>7.2</b> Introduction</a></li>
<li class="chapter" data-level="7.3" data-path="ch-corrdata.html"><a href="ch-corrdata.html#recognizing-correlation"><i class="fa fa-check"></i><b>7.3</b> Recognizing Correlation</a></li>
<li class="chapter" data-level="7.4" data-path="ch-corrdata.html"><a href="ch-corrdata.html#case-study-dams-and-pups"><i class="fa fa-check"></i><b>7.4</b> Case Study: Dams and Pups</a></li>
<li class="chapter" data-level="7.5" data-path="ch-corrdata.html"><a href="ch-corrdata.html#sources-of-variability"><i class="fa fa-check"></i><b>7.5</b> Sources of Variability</a></li>
<li class="chapter" data-level="7.6" data-path="ch-corrdata.html"><a href="ch-corrdata.html#scenario-1-no-covariates"><i class="fa fa-check"></i><b>7.6</b> Scenario 1: No Covariates</a></li>
<li class="chapter" data-level="7.7" data-path="ch-corrdata.html"><a href="ch-corrdata.html#scenario-2-dose-effect"><i class="fa fa-check"></i><b>7.7</b> Scenario 2: Dose Effect</a></li>
<li class="chapter" data-level="7.8" data-path="ch-corrdata.html"><a href="ch-corrdata.html#case-study-tree-growth"><i class="fa fa-check"></i><b>7.8</b> Case Study: Tree Growth</a><ul>
<li class="chapter" data-level="7.8.1" data-path="ch-corrdata.html"><a href="ch-corrdata.html#format-of-the-data-set"><i class="fa fa-check"></i><b>7.8.1</b> Format of the Data Set</a></li>
<li class="chapter" data-level="7.8.2" data-path="ch-corrdata.html"><a href="ch-corrdata.html#sources-of-variability-1"><i class="fa fa-check"></i><b>7.8.2</b> Sources of Variability</a></li>
<li class="chapter" data-level="7.8.3" data-path="ch-corrdata.html"><a href="ch-corrdata.html#analysis-preview-accounting-for-correlation"><i class="fa fa-check"></i><b>7.8.3</b> Analysis Preview: Accounting for Correlation</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="ch-corrdata.html"><a href="ch-corrdata.html#summary-2"><i class="fa fa-check"></i><b>7.9</b> Summary</a></li>
<li class="chapter" data-level="7.10" data-path="ch-corrdata.html"><a href="ch-corrdata.html#exercises-6"><i class="fa fa-check"></i><b>7.10</b> Exercises</a><ul>
<li class="chapter" data-level="7.10.1" data-path="ch-corrdata.html"><a href="ch-corrdata.html#conceptual-exercises-4"><i class="fa fa-check"></i><b>7.10.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="7.10.2" data-path="ch-corrdata.html"><a href="ch-corrdata.html#guided-exercises-5"><i class="fa fa-check"></i><b>7.10.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="7.10.3" data-path="ch-corrdata.html"><a href="ch-corrdata.html#note-on-correlated-binary-outcomes"><i class="fa fa-check"></i><b>7.10.3</b> Note on Correlated Binary Outcomes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html"><i class="fa fa-check"></i><b>8</b> Introduction to Multilevel Models</a><ul>
<li class="chapter" data-level="8.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#learning-objectives-7"><i class="fa fa-check"></i><b>8.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#cs:music"><i class="fa fa-check"></i><b>8.2</b> Case Study: Music Performance Anxiety</a></li>
<li class="chapter" data-level="8.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#explore"><i class="fa fa-check"></i><b>8.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="8.3.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#organizedata1"><i class="fa fa-check"></i><b>8.3.1</b> Data Organization</a></li>
<li class="chapter" data-level="8.3.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#explore1"><i class="fa fa-check"></i><b>8.3.2</b> Exploratory Analyses: Univariate Summaries</a></li>
<li class="chapter" data-level="8.3.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#explore2"><i class="fa fa-check"></i><b>8.3.3</b> Exploratory Analyses: Bivariate Summaries</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#twolevelmodeling"><i class="fa fa-check"></i><b>8.4</b> Two-Level Modeling: Preliminary Considerations</a><ul>
<li class="chapter" data-level="8.4.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#multregr"><i class="fa fa-check"></i><b>8.4.1</b> Ignoring the Two-Level Structure (not recommended)</a></li>
<li class="chapter" data-level="8.4.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#twostage"><i class="fa fa-check"></i><b>8.4.2</b> A Two-Stage Modeling Approach (better but imperfect)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#twolevelmodelingunified"><i class="fa fa-check"></i><b>8.5</b> Two-Level Modeling: A Unified Approach</a><ul>
<li class="chapter" data-level="8.5.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#ourframework"><i class="fa fa-check"></i><b>8.5.1</b> Our Framework</a></li>
<li class="chapter" data-level="8.5.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#random-vs.-fixed-effects"><i class="fa fa-check"></i><b>8.5.2</b> Random vs. Fixed Effects</a></li>
<li class="chapter" data-level="8.5.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#MVN"><i class="fa fa-check"></i><b>8.5.3</b> Distribution of Errors: Multivariate Normal</a></li>
<li class="chapter" data-level="8.5.4" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#multileveltechnical"><i class="fa fa-check"></i><b>8.5.4</b> Technical Issues when Testing Parameters (optional)</a></li>
<li class="chapter" data-level="8.5.5" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#initialmodel"><i class="fa fa-check"></i><b>8.5.5</b> An Initial Model with Parameter Interpretations</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#sec:buildmodel"><i class="fa fa-check"></i><b>8.6</b> Building a Multilevel Model</a><ul>
<li class="chapter" data-level="8.6.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#buildstrategy"><i class="fa fa-check"></i><b>8.6.1</b> Model Building Strategy</a></li>
<li class="chapter" data-level="8.6.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modela8"><i class="fa fa-check"></i><b>8.6.2</b> An Initial Model: Random Intercepts</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelb"><i class="fa fa-check"></i><b>8.7</b> Binary Covariates at Level One and Level Two</a><ul>
<li class="chapter" data-level="8.7.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#randomslopeandint"><i class="fa fa-check"></i><b>8.7.1</b> Random Slopes and Intercepts Model</a></li>
<li class="chapter" data-level="8.7.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#pseudoR2"><i class="fa fa-check"></i><b>8.7.2</b> Pseudo R-squared Values</a></li>
<li class="chapter" data-level="8.7.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelc"><i class="fa fa-check"></i><b>8.7.3</b> Adding a Covariate at Level Two</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#sec:modeld"><i class="fa fa-check"></i><b>8.8</b> Adding Further Covariates</a><ul>
<li class="chapter" data-level="8.8.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#interp:modeld"><i class="fa fa-check"></i><b>8.8.1</b> Interpretation of Parameter Estimates</a></li>
<li class="chapter" data-level="8.8.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#compare:modeld"><i class="fa fa-check"></i><b>8.8.2</b> Model Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#sec:modele"><i class="fa fa-check"></i><b>8.9</b> Centering Covariates</a></li>
<li class="chapter" data-level="8.10" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelf"><i class="fa fa-check"></i><b>8.10</b> A Final Model for Music Performance Anxiety</a></li>
<li class="chapter" data-level="8.11" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#multinecessary"><i class="fa fa-check"></i><b>8.11</b> Modeling Multilevel Structure: Is It Necessary?</a></li>
<li class="chapter" data-level="8.12" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#notesr8"><i class="fa fa-check"></i><b>8.12</b> Notes on Using R (optional)</a></li>
<li class="chapter" data-level="8.13" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#exercises-7"><i class="fa fa-check"></i><b>8.13</b> Exercises</a><ul>
<li class="chapter" data-level="8.13.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#conceptual-exercises-5"><i class="fa fa-check"></i><b>8.13.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="8.13.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#guided-exercises-6"><i class="fa fa-check"></i><b>8.13.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="8.13.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#open-ended-exercises-4"><i class="fa fa-check"></i><b>8.13.3</b> Open-Ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-lon.html"><a href="ch-lon.html"><i class="fa fa-check"></i><b>9</b> Two-Level Longitudinal Data</a><ul>
<li class="chapter" data-level="9.1" data-path="ch-lon.html"><a href="ch-lon.html#learning-objectives-8"><i class="fa fa-check"></i><b>9.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="9.2" data-path="ch-lon.html"><a href="ch-lon.html#cs:charter"><i class="fa fa-check"></i><b>9.2</b> Case Study: Charter Schools</a></li>
<li class="chapter" data-level="9.3" data-path="ch-lon.html"><a href="ch-lon.html#exploratoryanalysis"><i class="fa fa-check"></i><b>9.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="9.3.1" data-path="ch-lon.html"><a href="ch-lon.html#data"><i class="fa fa-check"></i><b>9.3.1</b> Data Organization</a></li>
<li class="chapter" data-level="9.3.2" data-path="ch-lon.html"><a href="ch-lon.html#missing"><i class="fa fa-check"></i><b>9.3.2</b> Missing Data</a></li>
<li class="chapter" data-level="9.3.3" data-path="ch-lon.html"><a href="ch-lon.html#generalanalyses"><i class="fa fa-check"></i><b>9.3.3</b> Exploratory Analyses for General Multilevel Models</a></li>
<li class="chapter" data-level="9.3.4" data-path="ch-lon.html"><a href="ch-lon.html#longitudinalanalyses"><i class="fa fa-check"></i><b>9.3.4</b> Exploratory Analyses for Longitudinal Data</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="ch-lon.html"><a href="ch-lon.html#twostage9"><i class="fa fa-check"></i><b>9.4</b> Preliminary Two-Stage Modeling</a><ul>
<li class="chapter" data-level="9.4.1" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostage"><i class="fa fa-check"></i><b>9.4.1</b> Linear Trends Within Schools</a></li>
<li class="chapter" data-level="9.4.2" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostageL2effects"><i class="fa fa-check"></i><b>9.4.2</b> Effects of Level Two Covariates on Linear Time Trends</a></li>
<li class="chapter" data-level="9.4.3" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostageerror2"><i class="fa fa-check"></i><b>9.4.3</b> Error Structure Within Schools</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostageerror"><i class="fa fa-check"></i><b>9.5</b> Initial Models</a><ul>
<li class="chapter" data-level="9.5.1" data-path="ch-lon.html"><a href="ch-lon.html#modela"><i class="fa fa-check"></i><b>9.5.1</b> Unconditional Means Model</a></li>
<li class="chapter" data-level="9.5.2" data-path="ch-lon.html"><a href="ch-lon.html#modelb9"><i class="fa fa-check"></i><b>9.5.2</b> Unconditional Growth Model</a></li>
<li class="chapter" data-level="9.5.3" data-path="ch-lon.html"><a href="ch-lon.html#othertimetrends"><i class="fa fa-check"></i><b>9.5.3</b> Modeling Other Trends over Time</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="ch-lon.html"><a href="ch-lon.html#finalmodel"><i class="fa fa-check"></i><b>9.6</b> Building to a Final Model</a><ul>
<li class="chapter" data-level="9.6.1" data-path="ch-lon.html"><a href="ch-lon.html#sec:modelc9"><i class="fa fa-check"></i><b>9.6.1</b> Uncontrolled Effects of School Type</a></li>
<li class="chapter" data-level="9.6.2" data-path="ch-lon.html"><a href="ch-lon.html#modeld"><i class="fa fa-check"></i><b>9.6.2</b> Add Percent Free and Reduced Lunch as a Covariate</a></li>
<li class="chapter" data-level="9.6.3" data-path="ch-lon.html"><a href="ch-lon.html#modelf9"><i class="fa fa-check"></i><b>9.6.3</b> A Final Model with Three Level Two Covariates</a></li>
<li class="chapter" data-level="9.6.4" data-path="ch-lon.html"><a href="ch-lon.html#longitudinal-paraboot"><i class="fa fa-check"></i><b>9.6.4</b> Parametric Bootstrap Testing</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="ch-lon.html"><a href="ch-lon.html#errorcovariance"><i class="fa fa-check"></i><b>9.7</b> Covariance Structure among Observations</a><ul>
<li class="chapter" data-level="9.7.1" data-path="ch-lon.html"><a href="ch-lon.html#standarderror"><i class="fa fa-check"></i><b>9.7.1</b> Standard Covariance Structure</a></li>
<li class="chapter" data-level="9.7.2" data-path="ch-lon.html"><a href="ch-lon.html#alternateerror"><i class="fa fa-check"></i><b>9.7.2</b> Alternative Covariance Structures</a></li>
<li class="chapter" data-level="9.7.3" data-path="ch-lon.html"><a href="ch-lon.html#non-longitudinal-multilevel-models"><i class="fa fa-check"></i><b>9.7.3</b> Non-longitudinal Multilevel Models</a></li>
<li class="chapter" data-level="9.7.4" data-path="ch-lon.html"><a href="ch-lon.html#final-thoughts-regarding-covariance-structures"><i class="fa fa-check"></i><b>9.7.4</b> Final Thoughts Regarding Covariance Structures</a></li>
<li class="chapter" data-level="9.7.5" data-path="ch-lon.html"><a href="ch-lon.html#optionalcov"><i class="fa fa-check"></i><b>9.7.5</b> Details of Covariance Structures (optional)</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="ch-lon.html"><a href="ch-lon.html#notesr9"><i class="fa fa-check"></i><b>9.8</b> Notes on Using R (optional)</a></li>
<li class="chapter" data-level="9.9" data-path="ch-lon.html"><a href="ch-lon.html#exercises-8"><i class="fa fa-check"></i><b>9.9</b> Exercises</a><ul>
<li class="chapter" data-level="9.9.1" data-path="ch-lon.html"><a href="ch-lon.html#conceptual-exercises-6"><i class="fa fa-check"></i><b>9.9.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="9.9.2" data-path="ch-lon.html"><a href="ch-lon.html#guided-exercises-7"><i class="fa fa-check"></i><b>9.9.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="9.9.3" data-path="ch-lon.html"><a href="ch-lon.html#open-ended-exercises-5"><i class="fa fa-check"></i><b>9.9.3</b> Open-Ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-3level.html"><a href="ch-3level.html"><i class="fa fa-check"></i><b>10</b> Multilevel Data With More Than Two Levels</a><ul>
<li class="chapter" data-level="10.1" data-path="ch-3level.html"><a href="ch-3level.html#learning-objectives-9"><i class="fa fa-check"></i><b>10.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="10.2" data-path="ch-3level.html"><a href="ch-3level.html#cs:seeds"><i class="fa fa-check"></i><b>10.2</b> Case Studies: Seed Germination</a></li>
<li class="chapter" data-level="10.3" data-path="ch-3level.html"><a href="ch-3level.html#explore3"><i class="fa fa-check"></i><b>10.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="10.3.1" data-path="ch-3level.html"><a href="ch-3level.html#organizedata3"><i class="fa fa-check"></i><b>10.3.1</b> Data Organization</a></li>
<li class="chapter" data-level="10.3.2" data-path="ch-3level.html"><a href="ch-3level.html#explore3v2"><i class="fa fa-check"></i><b>10.3.2</b> Exploratory Analyses</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ch-3level.html"><a href="ch-3level.html#initialmodels-3level"><i class="fa fa-check"></i><b>10.4</b> Initial Models</a><ul>
<li class="chapter" data-level="10.4.1" data-path="ch-3level.html"><a href="ch-3level.html#unconditional-means"><i class="fa fa-check"></i><b>10.4.1</b> Unconditional Means</a></li>
<li class="chapter" data-level="10.4.2" data-path="ch-3level.html"><a href="ch-3level.html#unconditional-growth"><i class="fa fa-check"></i><b>10.4.2</b> Unconditional Growth</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="ch-3level.html"><a href="ch-3level.html#sec:boundary"><i class="fa fa-check"></i><b>10.5</b> Encountering Boundary Constraints</a></li>
<li class="chapter" data-level="10.6" data-path="ch-3level.html"><a href="ch-3level.html#threelevel-paraboot"><i class="fa fa-check"></i><b>10.6</b> Parametric Bootstrap Testing</a></li>
<li class="chapter" data-level="10.7" data-path="ch-3level.html"><a href="ch-3level.html#sec:explodingvarcomps"><i class="fa fa-check"></i><b>10.7</b> Exploding Variance Components</a></li>
<li class="chapter" data-level="10.8" data-path="ch-3level.html"><a href="ch-3level.html#modelsDEF"><i class="fa fa-check"></i><b>10.8</b> Building to a Final Model</a></li>
<li class="chapter" data-level="10.9" data-path="ch-3level.html"><a href="ch-3level.html#error-3level"><i class="fa fa-check"></i><b>10.9</b> Covariance Structure (optional)</a><ul>
<li class="chapter" data-level="10.9.1" data-path="ch-3level.html"><a href="ch-3level.html#optionalerror"><i class="fa fa-check"></i><b>10.9.1</b> Details of Covariance Structures</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="ch-3level.html"><a href="ch-3level.html#usingR3"><i class="fa fa-check"></i><b>10.10</b> Notes on Using R (optional)</a></li>
<li class="chapter" data-level="10.11" data-path="ch-3level.html"><a href="ch-3level.html#exercises-9"><i class="fa fa-check"></i><b>10.11</b> Exercises</a><ul>
<li class="chapter" data-level="10.11.1" data-path="ch-3level.html"><a href="ch-3level.html#conceptual-exercises-7"><i class="fa fa-check"></i><b>10.11.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="10.11.2" data-path="ch-3level.html"><a href="ch-3level.html#guided-exercises-8"><i class="fa fa-check"></i><b>10.11.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="10.11.3" data-path="ch-3level.html"><a href="ch-3level.html#open-ended-exercises-6"><i class="fa fa-check"></i><b>10.11.3</b> Open-Ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-GLMM.html"><a href="ch-GLMM.html"><i class="fa fa-check"></i><b>11</b> Multilevel Generalized Linear Models</a><ul>
<li class="chapter" data-level="11.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#objectives"><i class="fa fa-check"></i><b>11.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="11.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#cs:refs"><i class="fa fa-check"></i><b>11.2</b> Case Study: College Basketball Referees</a></li>
<li class="chapter" data-level="11.3" data-path="ch-GLMM.html"><a href="ch-GLMM.html#explore-glmm"><i class="fa fa-check"></i><b>11.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="11.3.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#data-organization-5"><i class="fa fa-check"></i><b>11.3.1</b> Data Organization</a></li>
<li class="chapter" data-level="11.3.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#glmm-eda"><i class="fa fa-check"></i><b>11.3.2</b> Exploratory Analyses</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ch-GLMM.html"><a href="ch-GLMM.html#twolevelmodeling-glmm"><i class="fa fa-check"></i><b>11.4</b> Two-Level Modeling with a Generalized Response</a><ul>
<li class="chapter" data-level="11.4.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#multregr-glmm"><i class="fa fa-check"></i><b>11.4.1</b> A GLM Approach</a></li>
<li class="chapter" data-level="11.4.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#twostage-glmm"><i class="fa fa-check"></i><b>11.4.2</b> A Two-Stage Modeling Approach</a></li>
<li class="chapter" data-level="11.4.3" data-path="ch-GLMM.html"><a href="ch-GLMM.html#unified-glmm"><i class="fa fa-check"></i><b>11.4.3</b> A Unified Multilevel Approach</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="ch-GLMM.html"><a href="ch-GLMM.html#crossedre"><i class="fa fa-check"></i><b>11.5</b> Crossed Random Effects</a></li>
<li class="chapter" data-level="11.6" data-path="ch-GLMM.html"><a href="ch-GLMM.html#glmm-paraboot"><i class="fa fa-check"></i><b>11.6</b> Parametric Bootstrap for Model Comparisons</a></li>
<li class="chapter" data-level="11.7" data-path="ch-GLMM.html"><a href="ch-GLMM.html#sec:finalmodel-glmm"><i class="fa fa-check"></i><b>11.7</b> A Final Model for Examining Referee Bias</a></li>
<li class="chapter" data-level="11.8" data-path="ch-GLMM.html"><a href="ch-GLMM.html#estimatedRE"><i class="fa fa-check"></i><b>11.8</b> Estimated Random Effects</a></li>
<li class="chapter" data-level="11.9" data-path="ch-GLMM.html"><a href="ch-GLMM.html#usingR-glmm"><i class="fa fa-check"></i><b>11.9</b> Notes on Using R (optional)</a></li>
<li class="chapter" data-level="11.10" data-path="ch-GLMM.html"><a href="ch-GLMM.html#exercises-10"><i class="fa fa-check"></i><b>11.10</b> Exercises</a><ul>
<li class="chapter" data-level="11.10.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#conceptual-exercises-8"><i class="fa fa-check"></i><b>11.10.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="11.10.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#open-ended-exercises-7"><i class="fa fa-check"></i><b>11.10.2</b> Open-Ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Beyond Multiple Linear Regression</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-lon" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Two-Level Longitudinal Data</h1>
<div id="learning-objectives-8" class="section level2">
<h2><span class="header-section-number">9.1</span> Learning Objectives</h2>
<p>After finishing this chapter, you should be able to:</p>
<ul>
<li>Recognize longitudinal data as a special case of multilevel data, with time at Level One.</li>
<li>Consider patterns of missingness and implications of that missing data on multilevel analyses.</li>
<li>Apply exploratory data analysis techniques specific to longitudinal data.</li>
<li>Build and understand a taxonomy of models for longitudinal data.</li>
<li>Interpret model parameters in multilevel models with time at Level One.</li>
<li>Compare models, both nested and not, with appropriate statistical tests and summary statistics.</li>
<li>Consider different ways of modeling the variance-covariance structure in longitudinal data.</li>
<li>Understand how a parametric bootstrap test of significance works and when it might be useful.</li>
</ul>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="ch-lon.html#cb214-1"></a><span class="co"># Packages required for Chapter 9</span></span>
<span id="cb214-2"><a href="ch-lon.html#cb214-2"></a><span class="kw">library</span>(GGally)</span>
<span id="cb214-3"><a href="ch-lon.html#cb214-3"></a><span class="kw">library</span>(data.table)</span>
<span id="cb214-4"><a href="ch-lon.html#cb214-4"></a><span class="kw">library</span>(Hmisc)</span>
<span id="cb214-5"><a href="ch-lon.html#cb214-5"></a><span class="kw">library</span>(mice)</span>
<span id="cb214-6"><a href="ch-lon.html#cb214-6"></a><span class="kw">library</span>(lattice)</span>
<span id="cb214-7"><a href="ch-lon.html#cb214-7"></a><span class="kw">library</span>(nlme)</span>
<span id="cb214-8"><a href="ch-lon.html#cb214-8"></a><span class="kw">library</span>(reshape2)</span>
<span id="cb214-9"><a href="ch-lon.html#cb214-9"></a><span class="kw">library</span>(MASS)</span>
<span id="cb214-10"><a href="ch-lon.html#cb214-10"></a><span class="kw">library</span>(mnormt)</span>
<span id="cb214-11"><a href="ch-lon.html#cb214-11"></a><span class="kw">library</span>(lme4)</span>
<span id="cb214-12"><a href="ch-lon.html#cb214-12"></a><span class="kw">library</span>(gridExtra) </span>
<span id="cb214-13"><a href="ch-lon.html#cb214-13"></a><span class="kw">library</span>(knitr)</span>
<span id="cb214-14"><a href="ch-lon.html#cb214-14"></a><span class="kw">library</span>(kableExtra)</span>
<span id="cb214-15"><a href="ch-lon.html#cb214-15"></a><span class="kw">library</span>(broom)</span>
<span id="cb214-16"><a href="ch-lon.html#cb214-16"></a><span class="kw">library</span>(tidyverse)</span></code></pre></div>
</div>
<div id="cs:charter" class="section level2">
<h2><span class="header-section-number">9.2</span> Case Study: Charter Schools</h2>
<p>Charter schools were first introduced in the state of Minnesota in 1991 <span class="citation">(U.S. Department of Education <a href="#ref-CharterSchools" role="doc-biblioref">2018</a>)</span>. Since then, charter schools have begun appearing all over the United States. While publicly funded, a unique feature of charter schools is their independence from many of the regulations that are present in the public school systems of their respective city or state. Thus, charters will often extend the school days or year and tend to offer non-traditional techniques and styles of instruction and learning.</p>
<p>One example of this unique schedule structure is the KIPP (Knowledge Is Power Program) Stand Academy in Minneapolis, MN. KIPP stresses longer days and better partnerships with parents, and they claim that 80% of their students go to college from a population where 87% qualify for free and reduced lunch and 95% are African American or Latino <span class="citation">(KIPP <a href="#ref-KIPP" role="doc-biblioref">2018</a>)</span>. However, the larger question is whether or not charter schools are out-performing non-charter public schools in general. Because of the relative youthfulness of charter schools, data has just begun to be collected to evaluate the performance of charter versus non-charter schools and some of the factors that influence a school’s performance. Along these lines, we will examine data collected by the Minnesota Department of Education for all Minnesota schools during the years 2008-2010.</p>
<p>Comparisons of student performance in charter schools versus public schools have produced conflicting results, potentially as a result of the strong differences in the structure and population of the student bodies that represent the two types of schools. A study by the Policy and Program Studies Service of five states found that charter schools are less likely to meet state performance standards than conventional public schools <span class="citation">(Finnigan et al. <a href="#ref-Finnigan2004" role="doc-biblioref">2004</a>)</span>. However, <span class="citation">Witte et al. (<a href="#ref-Witte2007" role="doc-biblioref">2007</a>)</span> performed a statistical analysis comparing Wisconsin charter and non-charter schools and found that average achievement test scores were significantly higher in charter schools compared to non-charter schools, after controlling for demographic variables such as the percentage of white students. In addition, a study of California students who took the Stanford 9 exam from 1998 through 2002 found that charter schools, on average, were performing at the same level as conventional public schools <span class="citation">(Buddin and Zimmer <a href="#ref-Buddin2005" role="doc-biblioref">2005</a>)</span>. Although school performance is difficult to quantify with a single measure, for illustration purposes in this chapter we will focus on that aspect of school performance measured by the math portion of the Minnesota Comprehensive Assessment (MCA-II) data for 6th grade students enrolled in 618 different Minnesota schools during the years 2008, 2009, and 2010 <span class="citation">(Minnesota Department of Education <a href="#ref-MNDepartmentOfEducation" role="doc-biblioref">2018</a>)</span>. Similar comparisons could obviously be conducted for other grade levels or modes of assessment.</p>
<p>As described in <span class="citation">Green III, Baker, and Oluwole (<a href="#ref-Green2003" role="doc-biblioref">2003</a>)</span>, it is very challenging to compare charter and public non-charter schools, as charter schools are often designed to target or attract specific populations of students. Without accounting for differences in student populations, comparisons lose meaning. With the assistance of multiple school-specific predictors, we will attempt to model sixth grade math MCA-II scores of Minnesota schools, focusing on the differences between charter and public non-charter school performances. In the process, we hope to answer the following research questions:</p>
<ul>
<li>Which factors most influence a school’s performance in MCA testing?</li>
<li>How do the average math MCA-II scores for 6th graders enrolled in charter schools differ from scores for students who attend non-charter public schools? Do these differences persist after accounting for differences in student populations?</li>
<li>Are there differences in yearly improvement between charter and non-charter public schools?</li>
</ul>
</div>
<div id="exploratoryanalysis" class="section level2">
<h2><span class="header-section-number">9.3</span> Initial Exploratory Analyses</h2>
<div id="data" class="section level3">
<h3><span class="header-section-number">9.3.1</span> Data Organization</h3>
<p>Key variables in <code>chart_wide_condense.csv</code> which we will examine to address the research questions above are:</p>
<ul>
<li><code>schoolid</code> = includes district type, district number, and school number</li>
<li><code>schoolName</code> = name of school</li>
<li><code>urban</code> = is the school in an urban (1) or rural (0) location?</li>
<li><code>charter</code> = is the school a charter school (1) or a non-charter public school (0)?</li>
<li><code>schPctnonw</code> = proportion of non-white students in a school (based on 2010 figures)</li>
<li><code>schPctsped</code> = proportion of special education students in a school (based on 2010 figures)</li>
<li><code>schPctfree</code> = proportion of students who receive free or reduced lunches in a school (based on 2010 figures). This serves as a measure of poverty among school families.</li>
<li><code>MathAvgScore.0</code> = average MCA-II math score for all sixth grade students in a school in 2008</li>
<li><code>MathAvgScore.1</code> = average MCA-II math score for all sixth grade students in a school in 2009</li>
<li><code>MathAvgScore.2</code> = average MCA-II math score for all sixth grade students in a school in 2010</li>
</ul>
<p>This data is stored in WIDE format, with one row per school, as illustrated in Table <a href="ch-lon.html#tab:table1chp9">9.1</a>.</p>
<table class="table" style="font-size: 9px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:table1chp9">Table 9.1: </span>The first six observations in the wide data set for the Charter Schools case study.
</caption>
<thead>
<tr>
<th style="text-align:left;">
schoolid
</th>
<th style="text-align:left;">
schoolName
</th>
<th style="text-align:right;">
urban
</th>
<th style="text-align:right;">
charter
</th>
<th style="text-align:right;">
schPctnonw
</th>
<th style="text-align:right;">
schPctsped
</th>
<th style="text-align:right;">
schPctfree
</th>
<th style="text-align:right;">
MathAvgScore.0
</th>
<th style="text-align:right;">
MathAvgScore.1
</th>
<th style="text-align:right;">
MathAvgScore.2
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Dtype 1 Dnum 1 Snum 2
</td>
<td style="text-align:left;">
RIPPLESIDE ELEMENTARY
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
0.1176
</td>
<td style="text-align:right;">
0.3627
</td>
<td style="text-align:right;">
652.8
</td>
<td style="text-align:right;">
656.6
</td>
<td style="text-align:right;">
652.6
</td>
</tr>
<tr>
<td style="text-align:left;">
Dtype 1 Dnum 100 Snum 1
</td>
<td style="text-align:left;">
WRENSHALL ELEMENTARY
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0303
</td>
<td style="text-align:right;">
0.1515
</td>
<td style="text-align:right;">
0.4242
</td>
<td style="text-align:right;">
646.9
</td>
<td style="text-align:right;">
645.3
</td>
<td style="text-align:right;">
651.9
</td>
</tr>
<tr>
<td style="text-align:left;">
Dtype 1 Dnum 108 Snum 30
</td>
<td style="text-align:left;">
CENTRAL MIDDLE
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0769
</td>
<td style="text-align:right;">
0.1231
</td>
<td style="text-align:right;">
0.2615
</td>
<td style="text-align:right;">
654.7
</td>
<td style="text-align:right;">
658.5
</td>
<td style="text-align:right;">
659.7
</td>
</tr>
<tr>
<td style="text-align:left;">
Dtype 1 Dnum 11 Snum 121
</td>
<td style="text-align:left;">
SANDBURG MIDDLE
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0977
</td>
<td style="text-align:right;">
0.0827
</td>
<td style="text-align:right;">
0.2481
</td>
<td style="text-align:right;">
656.4
</td>
<td style="text-align:right;">
656.8
</td>
<td style="text-align:right;">
659.9
</td>
</tr>
<tr>
<td style="text-align:left;">
Dtype 1 Dnum 11 Snum 193
</td>
<td style="text-align:left;">
OAK VIEW MIDDLE
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0538
</td>
<td style="text-align:right;">
0.0954
</td>
<td style="text-align:right;">
0.1418
</td>
<td style="text-align:right;">
657.7
</td>
<td style="text-align:right;">
658.2
</td>
<td style="text-align:right;">
659.8
</td>
</tr>
<tr>
<td style="text-align:left;">
Dtype 1 Dnum 11 Snum 195
</td>
<td style="text-align:left;">
ROOSEVELT MIDDLE
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.1234
</td>
<td style="text-align:right;">
0.0886
</td>
<td style="text-align:right;">
0.2405
</td>
<td style="text-align:right;">
655.9
</td>
<td style="text-align:right;">
659.1
</td>
<td style="text-align:right;">
660.3
</td>
</tr>
</tbody>
</table>
<p>For most statistical analyses, it will be advantageous to convert WIDE format to LONG format, with one row per year per school. To make this conversion, we will have to create a time variable, which under the LONG format is very flexible—each school can have a different number of and differently-spaced time points, and they can even have predictors which vary over time. Details for making this conversion can be found in the R Markdown code for this chapter, and the form of the LONG data in this study is exhibited in the next section.</p>
</div>
<div id="missing" class="section level3">
<h3><span class="header-section-number">9.3.2</span> Missing Data</h3>
<p>In this case, before we convert our data to LONG form, we should first address problems with missing data.  Missing data is a common phenomenon in longitudinal studies. For instance, it could arise if a new school was started during the observation period, a school was shut down during the observation period, or no results were reported in a given year. Dealing with missing data in a statistical analysis is not trivial, but fortunately many multilevel packages (including the lme4 package in R) are adept at handling missing data.</p>
<p>First, we must understand the extent and nature of missing data in our study. Table <a href="ch-lon.html#tab:table2chp9">9.2</a> is a frequency table of missing data patterns, where 1 indicates presence of a variable and 0 indicates a missing value for a particular variable; this table is a helpful starting point. Among our 618 schools, 540 had complete data (all covariates and math scores for all three years), 25 were missing a math score for 2008, 35 were missing math scores in both 2008 and 2009, etc.</p>
<p>The number of schools with a particular missing data pattern are listed in the left column; the remaining columns of 0’s and 1’s describe the missing data pattern, with 0 indicating a missing value. Some covariates that are present for every school are not listed. The bottom row gives the number of schools with missing values for specific variables; the last entry indicates that 121 total observations were missing.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:table2chp9">Table 9.2: </span>A frequency table of missing data patterns.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
charter
</th>
<th style="text-align:right;">
MathAvgScore.2
</th>
<th style="text-align:right;">
MathAvgScore.1
</th>
<th style="text-align:right;">
MathAvgScore.0
</th>
<th style="text-align:right;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
540
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
25
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
4
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
35
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
6
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
7
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
46
</td>
<td style="text-align:right;">
61
</td>
<td style="text-align:right;">
121
</td>
</tr>
</tbody>
</table>
<p>Statisticians have devised different strategies for handling missing data; a few common approaches are described briefly here:</p>
<ul>
<li>Include only schools with complete data. This is the cleanest approach analytically; however, ignoring data from 12.6% of the study’s schools (since 78 of the 618 schools had incomplete data) means that a large amount of potentially useful data is being thrown away. In addition, this approach creates potential issues with informative missingness. Informative missingness occurs when a school’s lack of scores is not a random phenomenon but provides information about the effectiveness of the school type (e.g., a school closes because of low test scores).</li>
<li>Last observation carried forward. Each school’s last math score is analyzed as a univariate response, whether the last measurement was taken in 2008, 2009, or 2010. With this approach, data from all schools can be used, and analyses can be conducted with traditional methods assuming independent responses. This approach is sometimes used in clinical trials because it tends to be conservative, setting a higher bar for showing that a new therapy is significantly better than a traditional therapy. Of course, we must assume that a school’s 2008 score is representative of its 2010 score. In addition, information about trajectories over time is thrown away.</li>
<li>Imputation of missing observations. Many methods have been developed for sensibly “filling in” missing observations, using imputation models which base imputed data on subjects with similar covariate profiles and on typical observed time trends. Once an imputed data set is created (or several imputed data sets), analyses can proceed with complete data methods that are easier to apply. Risks with the imputation approach include misrepresenting missing observations and overstating precision in final results.</li>
<li>Apply multilevel methods, which use available data to estimate patterns over time by school and then combine those school estimates in a way that recognizes that time trends for schools with complete data are more precise than time trends for schools with fewer measurements. <span class="citation">Laird (<a href="#ref-Laird1988" role="doc-biblioref">1988</a>)</span> demonstrates that multilevel models are valid under the fairly unrestrictive condition that the probability of missingness cannot depend on any unobserved predictors or the response. This is the approach we will follow in the remainder of the text.</li>
</ul>
<p>Now, we are ready to create our LONG data set. Fortunately, many packages (including R) have built-in functions for easing this conversion, and the functions are improving constantly. The resulting LONG data set is shown in Table <a href="ch-lon.html#tab:table3chp9">9.3</a>, where <code>year08</code> measures the number of years since 2008.</p>

<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:table3chp9">Table 9.3: </span>The first six observations in the long data set for the Charter Schools case study; these lines correspond to the first two observations from the wide data set illustrated in Table <a href="ch-lon.html#tab:table1chp9">9.1</a>.
</caption>
<thead>
<tr>
<th style="text-align:left;">
schoolName
</th>
<th style="text-align:right;">
charter
</th>
<th style="text-align:right;">
schPctsped
</th>
<th style="text-align:right;">
schPctfree
</th>
<th style="text-align:right;">
year08
</th>
<th style="text-align:right;">
MathAvgScore
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
RIPPLESIDE ELEMENTARY
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.1176
</td>
<td style="text-align:right;">
0.3627
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
652.8
</td>
</tr>
<tr>
<td style="text-align:left;">
RIPPLESIDE ELEMENTARY
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.1176
</td>
<td style="text-align:right;">
0.3627
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
656.6
</td>
</tr>
<tr>
<td style="text-align:left;">
RIPPLESIDE ELEMENTARY
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.1176
</td>
<td style="text-align:right;">
0.3627
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
652.6
</td>
</tr>
<tr>
<td style="text-align:left;">
WRENSHALL ELEMENTARY
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.1515
</td>
<td style="text-align:right;">
0.4242
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
646.9
</td>
</tr>
<tr>
<td style="text-align:left;">
WRENSHALL ELEMENTARY
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.1515
</td>
<td style="text-align:right;">
0.4242
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
645.3
</td>
</tr>
<tr>
<td style="text-align:left;">
WRENSHALL ELEMENTARY
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.1515
</td>
<td style="text-align:right;">
0.4242
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
651.9
</td>
</tr>
</tbody>
</table>
</div>
<div id="generalanalyses" class="section level3">
<h3><span class="header-section-number">9.3.3</span> Exploratory Analyses for General Multilevel Models</h3>
<p>Notice the <strong>longitudinal</strong>  structure of our data—we have up to three measurements of test scores at different time points for each of our 618 schools. With this structure, we can address questions at two levels:</p>
<ul>
<li>Within school—changes over time</li>
<li>Between schools—effects of school-specific covariates (charter or non-charter, urban or rural, percent free and reduced lunch, percent special education, and percent non-white) on 2008 math scores and rate of change between 2008 and 2010.</li>
</ul>
<p>As with any statistical analysis, it is vitally important to begin with graphical and numerical summaries of important variables and relationships between variables. We’ll begin with initial exploratory analyses that we introduced in the previous chapter, noting that we have no Level One covariates other than time at this point (potential covariates at this level may have included measures of the number of students tested or funds available per student). We will, however, consider the Level Two variables of charter or non-charter, urban or rural, percent free and reduced lunch, percent special education, and percent non-white. Although covariates such as percent free and reduced lunch may vary slightly from year to year within a school, the larger and more important differences tend to occur between schools, so we used percent free and reduced lunch for a school in 2010 as a Level Two variable.</p>
<p>As in Chapter <a href="ch-multilevelintro.html#ch-multilevelintro">8</a>, we can conduct initial investigations of relationships between Level Two covariates and test scores in two ways. First, we can use all 1733 observations to investigate relationships of Level Two covariates with test scores. Although these plots will contain dependent points, since each school is represented by up to three years of test score data, general patterns exhibited in these plots tend to be real. Second, we can calculate mean scores across all years for each of the 618 schools. While we lose some information with this approach, we can more easily consider each plotted point to be independent. Typically, both types of exploratory plots illustrate similar relationships, and in this case, both approaches are so similar that we will only show plots using the second approach, with one observation per school.</p>
<p>Figure <a href="ch-lon.html#fig:lon-hist1">9.1</a> shows the distribution of MCA math test scores as somewhat left-skewed. MCA test scores for sixth graders are scaled to fall between 600 and 700, where scores above 650 for individual students indicate “meeting standards”. Thus, schools with averages below 650 will often have increased incentive to improve their scores the following year. When we refer to the “math score” for a particular school in a particular year, we will assume that score represents the average for all sixth graders at that school. In Figure <a href="ch-lon.html#fig:lon-box1">9.2</a>, we see that test scores are generally higher for both schools in rural areas and for public non-charter schools. Note that in this data set there are 237 schools in rural areas and 381 schools in urban areas, as well as 545 public non-charter schools and 73 charter schools. In addition, we can see in Figure <a href="ch-lon.html#fig:lon-scat1">9.3</a> that schools tend to have lower math scores if they have higher percentages of students with free and reduced lunch, with special education needs, or who are non-white.</p>
<div class="figure" style="text-align: center"><span id="fig:lon-hist1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-hist1-1.png" alt="Histogram of mean sixth grade MCA math test scores over the years 2008-2010 for 618 Minnesota schools." width="60%" />
<p class="caption">
Figure 9.1: Histogram of mean sixth grade MCA math test scores over the years 2008-2010 for 618 Minnesota schools.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:lon-box1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-box1-1.png" alt="Boxplots of categorical Level Two covariates vs. average MCA math scores.  Plot (a) shows charter vs. public non-charter schools, while plot (b) shows urban vs. rural schools." width="60%" />
<p class="caption">
Figure 9.2: Boxplots of categorical Level Two covariates vs. average MCA math scores. Plot (a) shows charter vs. public non-charter schools, while plot (b) shows urban vs. rural schools.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:lon-scat1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-scat1-1.png" alt=" Scatterplots of average MCA math scores by (a) percent free and reduced lunch, (b) percent special education, and (c) percent non-white in a school." width="60%" />
<p class="caption">
Figure 9.3:  Scatterplots of average MCA math scores by (a) percent free and reduced lunch, (b) percent special education, and (c) percent non-white in a school.
</p>
</div>
</div>
<div id="longitudinalanalyses" class="section level3">
<h3><span class="header-section-number">9.3.4</span> Exploratory Analyses for Longitudinal Data</h3>
<p>In addition to the initial exploratory analyses above, longitudinal data—multilevel data with time at Level One—calls for further plots and summaries that describe time trends within and across individuals. For example, we can examine trends over time within individual schools. Figure <a href="ch-lon.html#fig:lon-lat1">9.4</a> provides a <strong>lattice plot</strong>  illustrating trends over time for the first 24 schools in the data set. We note differences among schools in starting point (test scores in 2008), slope (change in test scores over the three-year period), and form of the relationship. These differences among schools are nicely illustrated in so-called <strong>spaghetti plots</strong>  such as Figure <a href="ch-lon.html#fig:lon-spag1">9.5</a>, which overlays the individual schools’ time trends (for the math test scores) from Figure <a href="ch-lon.html#fig:lon-lat1">9.4</a> on a single set of axes. In order to illustrate the overall time trend without making global assumptions about the form of the relationship, we overlaid in bold a non-parametric fitted curve through a <strong>loess smoother</strong>.  LOESS comes from “locally estimated scatterplot smoother”, in which a low-degree polynomial is fit to each data point using weighted regression techniques, where nearby points receive greater weight. LOESS is a computationally intensive method which performs especially well with larger sets of data, although ideally there would be a greater diversity of x-values than the three time points we have. In this case, the loess smoother follows very closely to a linear trend, indicating that assuming a linear increase in test scores over the three-year period is probably a reasonable simplifying assumption. To further examine the hypothesis that linearity would provide a reasonable approximation to the form of the individual time trends in most cases, Figure <a href="ch-lon.html#fig:lon-lat2">9.6</a> shows a lattice plot containing linear fits through ordinary least squares rather than connected time points as in Figure <a href="ch-lon.html#fig:lon-lat1">9.4</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:lon-lat1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-lat1-1.png" alt="Lattice plot by school of math scores over time for the first 24 schools in the data set." width="60%" />
<p class="caption">
Figure 9.4: Lattice plot by school of math scores over time for the first 24 schools in the data set.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:lon-spag1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-spag1-1.png" alt=" Spaghetti plot of math scores over time by school, for all the charter schools and a random sample of public non-charter schools, with overall fit using loess (bold)." width="60%" />
<p class="caption">
Figure 9.5:  Spaghetti plot of math scores over time by school, for all the charter schools and a random sample of public non-charter schools, with overall fit using loess (bold).
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:lon-lat2"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-lat2-1.png" alt=" Lattice plot by school of math scores over time with linear fit for the first 24 schools in the data set." width="60%" />
<p class="caption">
Figure 9.6:  Lattice plot by school of math scores over time with linear fit for the first 24 schools in the data set.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:lon-spag3"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-spag3-1.png" alt="Spaghetti plots showing time trends for each school by school type, for a random sample of charter schools (left) and public non-charter schools (right), with overall fits using loess (bold)." width="60%" />
<p class="caption">
Figure 9.7: Spaghetti plots showing time trends for each school by school type, for a random sample of charter schools (left) and public non-charter schools (right), with overall fits using loess (bold).
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:lon-spagmat1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-spagmat1-1.png" alt="Spaghetti plots showing time trends for each school by quartiles of percent free and reduced lunch, with loess fits." width="60%" />
<p class="caption">
Figure 9.8: Spaghetti plots showing time trends for each school by quartiles of percent free and reduced lunch, with loess fits.
</p>
</div>
<p>Just as we explored the relationship between our response (average math scores) and important covariates in Section <a href="ch-lon.html#generalanalyses">9.3.3</a>, we can now examine the relationships between time trends by school and important covariates. For instance, Figure <a href="ch-lon.html#fig:lon-spag3">9.7</a> shows that charter schools had math scores that were lower on average than public non-charter schools and more variable. This type of plot is sometimes called a <strong>trellis graph</strong>,  since it displays a grid of smaller charts with consistent scales, where each smaller chart represents a condition—an item in a category. Trends over time by school type are denoted by bold loess curves. Public non-charter schools have higher scores across all years; both school types show little growth between 2008 and 2009, but greater growth between 2009 and 2010, especially charter schools. Exploratory analyses like this can be repeated for other covariates, such as percent free and reduced lunch in Figure <a href="ch-lon.html#fig:lon-spagmat1">9.8</a>. The trellis plot automatically divides schools into four groups based on quartiles of their percent free and reduced lunch, and we see that schools with lower percentages of free and reduced lunch students tend to have higher math scores and less variability. Across all levels of free and reduced lunch, we see greater gains between 2009 and 2010 than between 2008 and 2009.</p>
</div>
</div>
<div id="twostage9" class="section level2">
<h2><span class="header-section-number">9.4</span> Preliminary Two-Stage Modeling</h2>
<div id="lineartwostage" class="section level3">
<h3><span class="header-section-number">9.4.1</span> Linear Trends Within Schools</h3>
<p>Even though we know that every school’s math test scores were not strictly linearly increasing or decreasing over the observation period, a linear model for individual time trends is often a simple but reasonable way to model data. One advantage of using a linear model within school is that each school’s data points can be summarized with two summary statistics—an intercept and a slope (obviously, this is an even bigger advantage when there are more observations over time per school). For instance, we see in Figure <a href="ch-lon.html#fig:lon-lat2">9.6</a> that sixth graders from the school depicted in the top right slot slowly increased math scores over the three-year observation period, while students from the school depicted in the fourth column of the top row generally experienced decreasing math scores over the same period. As a whole, the linear model fits individual trends pretty well, and many schools appear to have slowly increasing math scores over time, as researchers in this study may have hypothesized.</p>
<p>Another advantage of assuming a linear trend at Level One (within schools) is that we can examine summary statistics across schools. Both the intercept and slope are meaningful for each school: the <em>intercept</em> conveys the school’s math score in 2008, while the <em>slope</em> conveys the school’s average yearly increase or decrease in math scores over the three-year period. Figure <a href="ch-lon.html#fig:lon-cis1">9.9</a> shows that point estimates and uncertainty surrounding individual estimates of intercepts and slopes vary considerably. In addition, we can generate summary statistics and histograms for the 618 intercepts and slopes produced by fitting linear regression models at Level One, in addition to R-squared values which describe the strength of fit of the linear model for each school (Figure <a href="ch-lon.html#fig:lon-histmat1">9.10</a>). For our 618 schools, the mean math score for 2008 was 651.4 (SD=7.28), and the mean yearly rate of change in math scores over the three-year period was 1.30 (SD=2.51). We can further examine the relationship between schools’ intercepts and slopes. Figure <a href="ch-lon.html#fig:lon-scat5">9.11</a> shows a general decreasing trend, suggesting that schools with lower 2008 test scores tend to have greater growth in scores between 2008 and 2010 (potentially because those schools have more room for improvement); this trend is supported with a correlation coefficient of <span class="math inline">\(-0.32\)</span> between fitted intercepts and slopes. Note that, with only 3 or fewer observations for each school, extreme or intractable values for the slope and R-squared are possible. For example, slopes cannot be estimated for those schools with just a single test score, R-squared values cannot be calculated for those schools with no variability in test scores between 2008 and 2010, and R-squared values must be 1 for those schools with only two test scores.</p>

<div class="figure" style="text-align: center"><span id="fig:lon-cis1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-cis1-1.png" alt="Point estimates and 95% confidence intervals for (a) intercepts and (b) slopes by school, for the first 24 schools in the data set." width="60%" />
<p class="caption">
Figure 9.9: Point estimates and 95% confidence intervals for (a) intercepts and (b) slopes by school, for the first 24 schools in the data set.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:lon-histmat1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-histmat1-1.png" alt=" Histograms for (a) intercepts, (b) slopes, and (c) R-squared values from fitted regression lines by school." width="60%" />
<p class="caption">
Figure 9.10:  Histograms for (a) intercepts, (b) slopes, and (c) R-squared values from fitted regression lines by school.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:lon-scat5"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-scat5-1.png" alt="Scatterplot showing the relationship between intercepts and slopes from fitted regression lines by school." width="60%" />
<p class="caption">
Figure 9.11: Scatterplot showing the relationship between intercepts and slopes from fitted regression lines by school.
</p>
</div>
</div>
<div id="lineartwostageL2effects" class="section level3">
<h3><span class="header-section-number">9.4.2</span> Effects of Level Two Covariates on Linear Time Trends</h3>
<p>Summarizing trends over time within schools is typically only a start, however. Most of the primary research questions from this study involve comparisons among schools, such as: (a) are there significant differences between charter schools and public non-charter schools, and (b) do any differences between charter schools and public schools change with percent free and reduced lunch, percent special education, or location? These are Level Two questions, and we can begin to explore these questions by graphically examining the effects of school-level variables on schools’ linear time trends. By school-level variables, we are referring to those covariates that differ by school but are not dependent on time. For example, school type (charter or public non-charter), urban or rural location, percent non-white, percent special education, and percent free and reduced lunch are all variables which differ by school but which don’t change over time, at least as they were assessed in this study. Variables which would be time-dependent include quantities such as per pupil funding and reading scores.</p>
<p>Figure <a href="ch-lon.html#fig:lon-box2">9.12</a> shows differences in the average time trends by school type, using estimated intercepts and slopes to support observations from the spaghetti plots in Figure <a href="ch-lon.html#fig:lon-spag3">9.7</a>. Based on intercepts, charter schools have lower math scores, on average, in 2008 than public non-charter schools. Based on slopes, however, charter schools tend to improve their math scores at a slightly faster rate than public schools, especially at the 75th percentile and above. By the end of the three-year observation period, we would nevertheless expect charter schools to have lower average math scores than public schools. For another exploratory perspective on school type comparisons, we can examine differences between school types with respect to math scores in 2008 and math scores in 2010. As expected, boxplots by school type (Figure <a href="ch-lon.html#fig:lon-box3">9.13</a>) show clearly lower math scores for charter schools in 2008, but differences are slightly less dramatic in 2010.</p>
<div class="figure" style="text-align: center"><span id="fig:lon-box2"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-box2-1.png" alt="Boxplots of (a) intercepts and (b) slopes by school type (charter vs. public non-charter)." width="60%" />
<p class="caption">
Figure 9.12: Boxplots of (a) intercepts and (b) slopes by school type (charter vs. public non-charter).
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:lon-box3"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-box3-1.png" alt="Boxplots of (a) 2008 and (b) 2010 math scores by school type (charter (1) vs. public non-charter (0))." width="60%" />
<p class="caption">
Figure 9.13: Boxplots of (a) 2008 and (b) 2010 math scores by school type (charter (1) vs. public non-charter (0)).
</p>
</div>
<p>Any initial exploratory analyses should also investigate effects of potential confounding variables such as school demographics and location. If we discover, for instance, that those schools with higher levels of poverty (measured by the percentage of students receiving free and reduced lunch) display lower test scores in 2008 but greater improvements between 2008 and 2010, then we might be able to use percentage of free and reduced lunch in statistical modeling of intercepts and slopes, leading to more precise estimates of the charter school effects on these two outcomes. In addition, we should also look for any interaction with school type—any evidence that the difference between charter and non-charter schools changes based on the level of a confounding variable. For example, do charter schools perform better relative to non-charter schools when there is a large percentage of non-white students at a school?</p>
<p>With a confounding variable such as percentage of free and reduced lunch, we will treat this variable as continuous to produce the most powerful exploratory analyses. We can begin by examining boxplots of free and reduced lunch percentage against school type (Figure <a href="ch-lon.html#fig:lon-boxcatmat1">9.14</a>). We observe that charter schools tend to have greater percentages of free and reduced lunch students as well as greater school-to-school variability. Next, we can use scatterplots to graphically illustrate the relationships between free and reduced lunch percentages and significant outcomes such as intercept and slope (also Figure <a href="ch-lon.html#fig:lon-boxcatmat1">9.14</a>). In this study, it appears that schools with higher levels of free and reduced lunch (i.e., greater poverty) tend to have lower math scores in 2008, but there is little evidence of a relationship between levels of free and reduced lunch and improvements in test scores between 2008 and 2010. These observations are supported with correlation coefficients between percent free and reduced lunch and intercepts (r=-0.61) and slopes (r=-0.06).</p>
<p>A less powerful but occasionally informative way to look at the effect of a continuous confounder on an outcome variable is by creating a categorical variable out of the confounder. For instance, we could classify any school with a percentage of free and reduced lunch students above the median as having a high percentage of free and reduced lunch students, and all other schools as having a low percentage of free and reduced lunch students. Then we could examine a possible interaction between percent free and reduced lunch and school type through a series of four boxplots (Figure <a href="ch-lon.html#fig:lon-boxmat1">9.15</a>). In fact, these boxplots suggest that the gap between charter and public non-charter schools in 2008 was greater in schools with a high percentage of free and reduced lunch students, while the difference in rate of change in test scores between charter and public non-charter schools appeared similar for high and low levels of free and reduced lunch. We will investigate these trends more thoroughly with statistical modeling.</p>
<div class="figure" style="text-align: center"><span id="fig:lon-boxcatmat1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-boxcatmat1-1.png" alt="(a) Boxplot of percent free and reduced lunch by school type (charter vs. public non-charter), along with scatterplots of (b) intercepts and (c) slopes from fitted regression lines by school vs. percent free and reduced lunch." width="60%" />
<p class="caption">
Figure 9.14: (a) Boxplot of percent free and reduced lunch by school type (charter vs. public non-charter), along with scatterplots of (b) intercepts and (c) slopes from fitted regression lines by school vs. percent free and reduced lunch.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:lon-boxmat1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-boxmat1-1.png" alt="Boxplots of (a) intercepts and (b) slopes from fitted regression lines by school vs. school type (charter vs. public non-charter), separated by high and low levels of percent free and reduced lunch." width="60%" />
<p class="caption">
Figure 9.15: Boxplots of (a) intercepts and (b) slopes from fitted regression lines by school vs. school type (charter vs. public non-charter), separated by high and low levels of percent free and reduced lunch.
</p>
</div>
<p>The effect of other confounding variables (e.g., percent non-white, percent special education, urban or rural location) can be investigated in a similar fashion to free and reduced lunch percentage, both in terms of main effect (variability in outcomes such as slope and intercept which can be explained by the confounding variable) and interaction with school type (ability of the confounding variable to explain differences between charter and public non-charter schools). We leave these explorations as an exercise.</p>
</div>
<div id="lineartwostageerror2" class="section level3">
<h3><span class="header-section-number">9.4.3</span> Error Structure Within Schools</h3>
<p>Finally, with longitudinal data it is important to investigate the error variance-covariance structure of data collected within a school (the Level Two observational unit). In multilevel data, as in the examples we introduced in Chapter <a href="ch-corrdata.html#ch-corrdata">7</a>, we suspect observations within group (like a school) to be correlated, and we strive to model that correlation. When the data within group is collected over time, we often see distinct patterns in the residuals that can be modeled—correlations which decrease systematically as the time interval increases, variances that change over time, correlation structure that depends on a covariate, etc. A first step in modeling the error variance-covariance structure is the production of an exploratory plot such as Figure <a href="ch-lon.html#fig:lon-cor1">9.16</a>. To generate this plot, we begin by modeling MCA math score as a linear function of time using all 1733 observations and ignoring the school variable. This population (marginal) trend is illustrated in Figure <a href="ch-lon.html#fig:lon-spag1">9.5</a> and is given by:</p>
<p><span class="math display">\[\begin{equation*}
\hat{Y}_{ij}=651.69+1.20\textrm{Time}_{ij},
\end{equation*}\]</span>
where <span class="math inline">\(\hat{Y}_{ij}\)</span> is the predicted math score of the <span class="math inline">\(i^{th}\)</span> school at time <span class="math inline">\(j\)</span>, where time <span class="math inline">\(j\)</span> is the number of years since 2008. In this model, the predicted math score will be identical for all schools at a given time point <span class="math inline">\(j\)</span>. Residuals <span class="math inline">\(Y_{ij}-\hat{Y}_{ij}\)</span> are then calculated for each observation, measuring the difference between actual math score and the average overall time trend. Figure <a href="ch-lon.html#fig:lon-cor1">9.16</a> then combines three pieces of information: the upper right triangle contains correlation coefficients for residuals between pairs of years, the diagonal contains histograms of residuals at each time point, and the lower left triangle contains scatterplots of residuals from two different years. In our case, we see that correlation between residuals from adjacent years is strongly positive (0.81-0.83) and does not drop off greatly as the time interval between years increases.</p>
<div class="figure" style="text-align: center"><span id="fig:lon-cor1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-cor1-1.png" alt="Correlation structure within school.  The upper right contains correlation coefficients between residuals at pairs of time points, the lower left contains scatterplots of the residuals at time point pairs, and the diagonal contains histograms of residuals at each of the three time points." width="60%" />
<p class="caption">
Figure 9.16: Correlation structure within school. The upper right contains correlation coefficients between residuals at pairs of time points, the lower left contains scatterplots of the residuals at time point pairs, and the diagonal contains histograms of residuals at each of the three time points.
</p>
</div>
</div>
</div>
<div id="lineartwostageerror" class="section level2">
<h2><span class="header-section-number">9.5</span> Initial Models</h2>
<p>Throughout the exploratory analysis phase, our original research questions have guided our work, and now with modeling we return to familiar questions such as:</p>
<ul>
<li>are differences between charter and public non-charter schools (in intercept, in slope, in 2010 math score) statistically significant?</li>
<li>are differences between school types statistically significant, even after accounting for school demographics and location?</li>
<li>do charter schools offer any measurable benefit over non-charter public schools, either overall or within certain subgroups of schools based on demographics or location?</li>
</ul>
<p>As you might expect, answers to these questions will arise from proper consideration of variability and properly identified statistical models.
As in Chapter <a href="ch-multilevelintro.html#ch-multilevelintro">8</a>, we will begin model fitting with some simple, preliminary models, in part to establish a baseline for evaluating larger models. Then, we can build toward a final model for inference by attempting to add important covariates, centering certain variables, and checking assumptions.</p>
<div id="modela" class="section level3">
<h3><span class="header-section-number">9.5.1</span> Unconditional Means Model</h3>
<p>In the multilevel context, we almost always begin with the <strong>unconditional means model</strong>,  in which there are no predictors at any level. The purpose of the unconditional means model is to assess the amount of variation at each level, and to compare variability within school to variability between schools. Define <span class="math inline">\(Y_{ij}\)</span> as the MCA-II math score from school <span class="math inline">\(i\)</span> and year <span class="math inline">\(j\)</span>. Using the composite model specification from Chapter <a href="ch-multilevelintro.html#ch-multilevelintro">8</a>:</p>
<p><span class="math display">\[\begin{equation*}
Y _{ij} = \alpha_{0} + u_{i} + \epsilon_{ij} \textrm{ with } u_{i} \sim N(0, \sigma^2_u) \textrm{ and } \epsilon_{ij} \sim N(0, \sigma^2)
\end{equation*}\]</span>
the unconditional means model can be fit to the MCA-II data:</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="ch-lon.html#cb215-1"></a><span class="co">#Model A (Unconditional means model)</span></span>
<span id="cb215-2"><a href="ch-lon.html#cb215-2"></a>model.a &lt;-<span class="st"> </span><span class="kw">lmer</span>(MathAvgScore<span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>schoolid), </span>
<span id="cb215-3"><a href="ch-lon.html#cb215-3"></a>                <span class="dt">REML=</span>T, <span class="dt">data=</span>chart.long)</span></code></pre></div>
<pre><code>##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept) 41.9     6.47    
##  Residual             10.6     3.25</code></pre>
<pre><code>##  Number of Level Two groups =  618</code></pre>
<pre><code>##             Estimate Std. Error t value
## (Intercept)    652.7     0.2726    2395</code></pre>
<p>From this output, we obtain estimates of our three model parameters:</p>
<ul>
<li><p><span class="math inline">\(\hat{\alpha}_{0}\)</span> = 652.7 = the mean math score across all schools and all years</p></li>
<li><p><span class="math inline">\(\hat{\sigma}^2\)</span>= 10.6 = the variance in within-school deviations between individual yearly scores and the school mean across all years</p></li>
<li><p><span class="math inline">\(\hat{\sigma}^2_u\)</span>= 41.9 = the variance in between-school deviations between school means and the overall mean across all schools and all years</p></li>
</ul>
<p>Based on the intraclass correlation coefficient:</p>
<p><span class="math display">\[\begin{equation*}
\hat{\rho}=\frac{\hat{\sigma}^2_u}{\hat{\sigma}^2_u + \hat{\sigma}^2} = \frac{41.869}{41.869+10.571}= 0.798
\end{equation*}\]</span>
79.8% of the total variation in math scores is attributable to differences among schools rather than changes over time within schools. We can also say that the average correlation for any pair of responses from the same school is 0.798.</p>
</div>
<div id="modelb9" class="section level3">
<h3><span class="header-section-number">9.5.2</span> Unconditional Growth Model</h3>
<p>The second model in most multilevel contexts introduces a covariate at Level One (see Model B in Chapter <a href="ch-multilevelintro.html#ch-multilevelintro">8</a>). With longitudinal data, this second model introduces time as a predictor at Level One, but there are still no predictors at Level Two. This model is then called the <strong>unconditional growth model</strong>.  The unconditional growth model allows us to assess how much of the within-school variability can be attributed to systematic changes over time.</p>
<p>At the lowest level, we can consider building individual growth models over time for each of the 618 schools in our study. First, we must decide upon a form for each of our 618 growth curves. Based on our initial exploratory analyses, assuming that an individual school’s MCA-II math scores follow a linear trend seems like a reasonable starting point. Under the assumption of linearity, we must estimate an intercept and a slope for each school, based on their 1-3 test scores over a period of three years. Compared to time series analyses of economic data, most longitudinal data analyses have relatively few time periods for each subject (or school), and the basic patterns within subject are often reasonably described by simpler functional forms.</p>
<p>Let <span class="math inline">\(Y_{ij}\)</span> be the math score of the <span class="math inline">\(i^{th}\)</span> school in year <span class="math inline">\(j\)</span>. Then we can model the linear change in math test scores over time for School <span class="math inline">\(i\)</span> according to Model B:</p>
<p><span class="math display">\[\begin{equation*}
Y_{ij} = a_{i} + b_{i}\textrm{Year08}_{ij} + \epsilon_{ij} \textrm{ where } \epsilon_{ij} \sim N(0, \sigma^2)
\end{equation*}\]</span></p>
<p>The parameters in this model <span class="math inline">\((a_{i}, b_{i},\)</span> and <span class="math inline">\(\sigma^2)\)</span> can be estimated through LLSR methods. <span class="math inline">\(a_{i}\)</span> represents the true intercept for School <span class="math inline">\(i\)</span>—i.e., the expected test score level for School <span class="math inline">\(i\)</span> when time is zero (2008)—while <span class="math inline">\(b_{i}\)</span> represents the true slope for School <span class="math inline">\(i\)</span>—i.e., the expected yearly rate of change in math score for School <span class="math inline">\(i\)</span> over the three-year observation period. Here we use Roman letters rather than Greek for model parameters since models by school will eventually be a conceptual first step in a multilevel model. The <span class="math inline">\(\epsilon_{ij}\)</span> terms represent the deviation of School <span class="math inline">\(i\)</span>’s actual test scores from the expected results under linear growth—the part of school <span class="math inline">\(i\)</span>’s test score at time <span class="math inline">\(j\)</span> that is not explained by linear changes over time. The variability in these deviations from the linear model is given by <span class="math inline">\(\sigma^2\)</span>. In Figure <a href="ch-lon.html#fig:lon-scat3">9.17</a>, which illustrates a linear growth model for Norwood Central Middle School, <span class="math inline">\(a_{i}\)</span> is estimated by the <span class="math inline">\(y\)</span>-intercept of the fitted regression line, <span class="math inline">\(b_{i}\)</span> is estimated by the slope of the fitted regression line, and <span class="math inline">\(\sigma^2\)</span> is estimated by the variability in the vertical distances between each point (the actual math score in year <span class="math inline">\(j\)</span>) and the line (the predicted math score in year <span class="math inline">\(j\)</span>).</p>
<div class="figure" style="text-align: center"><span id="fig:lon-scat3"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-scat3-1.png" alt="Linear growth model for Norwood Central Middle School." width="60%" />
<p class="caption">
Figure 9.17: Linear growth model for Norwood Central Middle School.
</p>
</div>
<p>In a multilevel model, we let intercepts (<span class="math inline">\(a_{i}\)</span>) and slopes (<span class="math inline">\(b_{i}\)</span>) vary by school and build models for these intercepts and slopes using school-level variables at Level Two. An unconditional growth model features no predictors at Level Two and can be specified either using formulations at both levels:</p>
<ul>
<li><p>Level One:
<span class="math display">\[\begin{equation*}
Y_{ij}=a_{i}+b_{i}\textrm{Year08}_{ij} + \epsilon_{ij}
\end{equation*}\]</span></p></li>
<li><p>Level Two:
<span class="math display">\[\begin{align*}
a_{i}&amp;=\alpha_{0} + u_{i}\\
b_{i}&amp;=\beta_{0} + v_{i}
\end{align*}\]</span></p></li>
</ul>
<p>or as a composite model:</p>
<p><span class="math display">\[\begin{equation*}
Y_{ij}=\alpha_{0} + \beta_{0}\textrm{Year08}_{ij}+u_{i}+v_{i}\textrm{Year08}_{ij} + \epsilon_{ij}
\end{equation*}\]</span>
where <span class="math inline">\(\epsilon_{ij}\sim N(0,\sigma^2)\)</span> and</p>
<p><span class="math display">\[ \left[ \begin{array}{c}
            u_{i} \\ v_{i}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cc}
            \sigma_{u}^{2} &amp; \\
            \sigma_{uv} &amp; \sigma_{v}^{2}
          \end{array} \right] \right) . \]</span></p>
<p>As before, <span class="math inline">\(\sigma^2\)</span> quantifies the within-school variability (the scatter of points around schools’ linear growth trajectories), while now the between-school variability is partitioned into variability in initial status <span class="math inline">\((\sigma^2_u)\)</span> and variability in rates of change <span class="math inline">\((\sigma^2_v)\)</span>.</p>
<p>Using the composite model specification, the unconditional growth model can be fit to the MCA-II test data:</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="ch-lon.html#cb219-1"></a><span class="co">#Model B (Unconditional growth)</span></span>
<span id="cb219-2"><a href="ch-lon.html#cb219-2"></a>model.b &lt;-<span class="st"> </span><span class="kw">lmer</span>(MathAvgScore<span class="op">~</span><span class="st"> </span>year08 <span class="op">+</span><span class="st"> </span>(year08<span class="op">|</span>schoolid), </span>
<span id="cb219-3"><a href="ch-lon.html#cb219-3"></a>  <span class="dt">REML=</span>T, <span class="dt">data=</span>chart.long)</span></code></pre></div>
<pre><code>##  Groups   Name        Variance Std.Dev. Corr
##  schoolid (Intercept) 39.441   6.280        
##           year08       0.111   0.332    0.72
##  Residual              8.820   2.970</code></pre>
<pre><code>##  Number of Level Two groups =  618</code></pre>
<pre><code>##             Estimate Std. Error t value
## (Intercept)  651.408    0.27934 2331.96
## year08         1.265    0.08997   14.06</code></pre>
<pre><code>##  AIC =  10352 ;  BIC =  10384</code></pre>
<p>From this output, we obtain estimates of our six model parameters:</p>
<ul>
<li><span class="math inline">\(\hat{\alpha}_{0}\)</span> = 651.4 = the mean math score for the population of schools in 2008.</li>
<li><span class="math inline">\(\hat{\beta}_{0}\)</span> = 1.26 = the mean yearly change in math test scores for the population during the three-year observation period.</li>
<li><span class="math inline">\(\hat{\sigma}^2\)</span> = 8.82 = the variance in within-school deviations.</li>
<li><span class="math inline">\(\hat{\sigma}^2_u\)</span> = 39.4 = the variance between schools in 2008 scores.</li>
<li><span class="math inline">\(\hat{\sigma}^2_v\)</span> = 0.11 = the variance between schools in rates of change in math test scores during the three-year observation period.</li>
<li><span class="math inline">\(\hat{\rho}_{uv}\)</span> = 0.72 = the correlation in schools’ 2008 math score and their rate of change in scores between 2008 and 2010.</li>
</ul>
<p>We see that schools had a mean math test score of 651.4 in 2008 and their mean test scores tended to increase by 1.26 points per year over the three-year observation period, producing a mean test score at the end of three years of 653.9. According to the t-value (14.1), the increase in mean test scores noted during the three-year observation period is statistically significant.</p>
<p>The estimated within-school variance <span class="math inline">\(\hat{\sigma}^2\)</span> decreased by about 17% from the unconditional means model, implying that 17% of within-school variability in test scores can be explained by a linear increase over time:</p>
<p><span class="math display">\[\begin{align*}
\textrm{Pseudo }R^2_{L1} &amp; = \frac{\hat{\sigma}^2(\textrm{uncond means}) - \hat{\sigma}^2(\textrm{uncond growth})}{\hat{\sigma^2}(\textrm{uncond means})} \\
 &amp; = \frac{10.571-8.820}{10.571}= 0.17
\end{align*}\]</span></p>
</div>
<div id="othertimetrends" class="section level3">
<h3><span class="header-section-number">9.5.3</span> Modeling Other Trends over Time</h3>
<p>While modeling linear trends over time is often a good approximation of reality, it is by no means the only way to model the effect of time. One alternative is to model the quadratic effect of time, which implies adding terms for both time and the square of time. Typically, to reduce the correlation between the linear and quadratic components of the time effect, the time variable is often centered first; we have already “centered” on 2008. Modifying Model B to produce an <strong>unconditional quadratic growth model</strong> would take the following form:</p>
<ul>
<li><p>Level One:
<span class="math display">\[\begin{equation*}
Y_{ij}=a_{i}+b_{i}\textrm{Year08}_{ij}+c_{i}\textrm{Year08}^{2}_{ij} + \epsilon_{ij}
\end{equation*}\]</span></p></li>
<li><p>Level Two:
<span class="math display">\[\begin{align*}
a_{i} &amp; = \alpha_{0} + u_{i}\\
b_{i} &amp; = \beta_{0} + v_{i}\\
c_{i} &amp; = \gamma_{0} + w_{i}
\end{align*}\]</span>
where <span class="math inline">\(\epsilon_{ij}\sim N(0,\sigma^2)\)</span> and</p></li>
</ul>
<p><span class="math display">\[ \left[ \begin{array}{c}
            u_{i} \\ v_{i} \\ w_{i}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0 \\ 0
          \end{array} \right], \left[
          \begin{array}{ccc}
            \sigma_{u}^{2} &amp; &amp; \\
            \sigma_{uv} &amp; \sigma_{v}^{2} &amp; \\
            \sigma_{uw} &amp; \sigma_{vw} &amp; \sigma_{w}^{2}
          \end{array} \right] \right) . \]</span></p>
<p>With the extra term at Level One for the quadratic effect, we now have 3 equations at Level Two, and 6 variance components at Level Two (3 variance terms and 3 covariance terms). However, with only a maximum of 3 observations per school, we lack the data for fitting 3 equations with error terms at Level Two. Instead, we could model the quadratic time effect with fewer variance components—for instance, by only using an error term on the intercept at Level Two:<br />
<span class="math display">\[\begin{align*}
a_{i} &amp; = \alpha_{0} + u_{i}\\
b_{i} &amp; = \beta_{0}\\ 
c_{i} &amp; = \gamma_{0}
\end{align*}\]</span>
where <span class="math inline">\(u_{i}\sim N(0,\sigma^2_u)\)</span>. Models like this are frequently used in practice—they allow for a separate overall effect on test scores for each school, while minimizing parameters that must be estimated. The tradeoff is that this model does not allow linear and quadratic effects to differ by school, but we have little choice here without more observations per school. Thus, using the composite model specification, the unconditional quadratic growth model with random intercept for each school can be fit to the MCA-II test data:</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="ch-lon.html#cb224-1"></a><span class="co"># Modeling quadratic time trend</span></span>
<span id="cb224-2"><a href="ch-lon.html#cb224-2"></a>model.b2 &lt;-<span class="st"> </span><span class="kw">lmer</span>(MathAvgScore<span class="op">~</span><span class="st"> </span>yearc <span class="op">+</span><span class="st"> </span>yearc2 <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>schoolid), </span>
<span id="cb224-3"><a href="ch-lon.html#cb224-3"></a>  <span class="dt">REML=</span>T, <span class="dt">data=</span>chart.long)</span></code></pre></div>
<pre><code>##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept) 43.05    6.56    
##  Residual              8.52    2.92</code></pre>
<pre><code>##  Number of Level Two groups =  618</code></pre>
<pre><code>##             Estimate Std. Error  t value
## (Intercept)  651.942    0.29229 2230.448
## yearc          1.270    0.08758   14.501
## yearc2         1.068    0.15046    7.101</code></pre>
<pre><code>##  AIC =  10308 ;  BIC =  10335</code></pre>
<p>From this output, we see that the quadratic effect is positive and significant (t=7.1), in this case indicating that increases in test scores are greater between 2009 and 2010 than between 2008 and 2009. Based on AIC and BIC values, the quadratic growth model outperforms the linear growth model with random intercepts only at level Two (AIC: 10308 vs. 10354; BIC: 10335 vs. 10375).</p>
<p>Another frequently used approach to modeling time effects is the <strong>piecewise linear model</strong>. In this model, the complete time span of the study is divided into two or more segments, with a separate slope relating time to the response in each segment. In our case study there is only one piecewise option—fitting separate slopes in 2008-09 and 2009-10. With only 3 time points, creating a piecewise linear model is a bit simplified, but this idea can be generalized to segments with more than two years each.</p>
<p>The performance of this model is very similar to the quadratic growth model by AIC and BIC measures, and the story told by fixed effects estimates is also very similar. While the mean yearly increase in math scores was 0.2 points between 2008 and 2009, it was 2.3 points between 2009 and 2010.</p>
<p>Despite the good performances of the quadratic growth and piecewise linear models on our three-year window of data, we will continue to use linear growth assumptions in the remainder of this chapter. Not only is a linear model easier to interpret and explain, but it’s probably a more reasonable assumption in years beyond 2010. Predicting future performance is more risky by assuming a steep one-year rise or a non-linear rise will continue, rather than by using the average increase over two years.</p>
</div>
</div>
<div id="finalmodel" class="section level2">
<h2><span class="header-section-number">9.6</span> Building to a Final Model</h2>
<div id="sec:modelc9" class="section level3">
<h3><span class="header-section-number">9.6.1</span> Uncontrolled Effects of School Type</h3>
<p>Initially, we can consider whether or not there are significant differences in individual school growth parameters (intercepts and slopes) based on school type. From a modeling perspective, we would build a system of two Level Two models:</p>
<p><span class="math display">\[\begin{align*}
a_{i} &amp; = \alpha_{0} + \alpha_{1}\textrm{Charter}_i + u_{i} \\
b_{i} &amp; = \beta_{0} + \beta_{1}\textrm{Charter}_i + v_{i}
\end{align*}\]</span>
where <span class="math inline">\(\textrm{Charter}_i=1\)</span> if School <span class="math inline">\(i\)</span> is a charter school, and <span class="math inline">\(\textrm{Charter}_i=0\)</span> if School <span class="math inline">\(i\)</span> is a non-charter public school. In addition, the error terms at Level Two are assumed to follow a multivariate normal distribution:</p>
<p><span class="math display">\[ \left[ \begin{array}{c}
            u_{i} \\ v_{i}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cc}
            \sigma_{u}^{2} &amp; \\
            \sigma_{uv} &amp; \sigma_{v}^{2}
          \end{array} \right] \right) . \]</span></p>
<p>With a binary predictor at Level Two such as school type, we can write out what our Level Two model looks like for public non-charter schools and charter schools.</p>
<ul>
<li>Public schools</li>
</ul>
<p><span class="math display">\[\begin{align*}
a_{i} &amp; = \alpha_{0} + u_{i}\\
b_{i} &amp; = \beta_{0} + v_{i},
\end{align*}\]</span></p>
<ul>
<li>Charter schools</li>
</ul>
<p><span class="math display">\[\begin{align*}
a_{i} &amp; = (\alpha_{0} + \alpha_{1}) + u_{i}\\
b_{i} &amp; = (\beta_{0}+ \beta_{1}) + v_{i}
\end{align*}\]</span></p>
<p>Writing the Level Two model in this manner helps us interpret the model parameters from our two-level model. We can use statistical software (such as the <code>lmer()</code> function from the <code>lme4</code> package in R) to obtain parameter estimates using our <span class="math inline">\(1733\)</span> observations, after first converting our Level One and Level Two models into a composite model (Model C) with fixed effects and random effects separated:</p>
<p><span class="math display">\[\begin{align*}
Y_{ij} &amp; = a_{i} + b_{i}\textrm{Year08}_{ij}+ \epsilon_{ij} \\
       &amp; = (\alpha_{0} + \alpha_{1}\textrm{Charter}_i +u_{i}) + (\beta_{0} + \beta_{1}\textrm{Charter}_i + v_{i})\textrm{Year08}_{ij} + \epsilon_{ij} \\
       &amp; = [\alpha_{0} + \beta_{0}\textrm{Year08}_{ij} +\alpha_{1}\textrm{Charter}_i+ \beta_{1}\textrm{Charter}_i\textrm{Year08}_{ij}] + \\
       &amp; \quad [u_{i} + v_{i}\textrm{Year08}_{ij} + \epsilon_{ij}]
\end{align*}\]</span></p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="ch-lon.html#cb229-1"></a><span class="co">#Model C (uncontrolled effects of school type on </span></span>
<span id="cb229-2"><a href="ch-lon.html#cb229-2"></a><span class="co">#   intercept and slope)</span></span>
<span id="cb229-3"><a href="ch-lon.html#cb229-3"></a>model.c &lt;-<span class="st"> </span><span class="kw">lmer</span>(MathAvgScore<span class="op">~</span><span class="st"> </span>charter <span class="op">+</span><span class="st"> </span>year08 <span class="op">+</span><span class="st"> </span></span>
<span id="cb229-4"><a href="ch-lon.html#cb229-4"></a><span class="st">  </span>charter<span class="op">:</span>year08 <span class="op">+</span><span class="st"> </span>(year08<span class="op">|</span>schoolid), </span>
<span id="cb229-5"><a href="ch-lon.html#cb229-5"></a>  <span class="dt">REML=</span>T, <span class="dt">data=</span>chart.long)</span></code></pre></div>
<pre><code>##  Groups   Name        Variance Std.Dev. Corr
##  schoolid (Intercept) 35.832   5.986        
##           year08       0.131   0.362    0.88
##  Residual              8.784   2.964</code></pre>
<pre><code>##  Number of Level Two groups =  618</code></pre>
<pre><code>##                Estimate Std. Error  t value
## (Intercept)    652.0584    0.28449 2291.996
## charter         -6.0184    0.86562   -6.953
## year08           1.1971    0.09427   12.698
## charter:year08   0.8557    0.31430    2.723</code></pre>
<pre><code>##  AIC =  10308 ;  BIC =  10351</code></pre>
<p>Armed with our parameter estimates, we can offer concrete interpretations:</p>
<ul>
<li><p>Fixed effects:</p>
<ul>
<li><span class="math inline">\(\hat{\alpha}_{0} = 652.1.\)</span> The estimated mean test score for 2008 for non-charter public schools is 652.1.</li>
<li><span class="math inline">\(\hat{\alpha}_{1}= -6.02.\)</span> Charter schools have an estimated test score in 2008 which is 6.02 points lower than public non-charter schools.</li>
<li><span class="math inline">\(\hat{\beta}_{0}= 1.20.\)</span> Public non-charter schools have an estimated mean increase in test scores of 1.20 points per year.</li>
<li><span class="math inline">\(\hat{\beta}_{1}= 0.86.\)</span> Charter schools have an estimated mean increase in test scores of 2.06 points per year over the three-year observation period, 0.86 points higher than the mean yearly increase among public non-charter schools.</li>
</ul></li>
<li><p>Variance components:</p>
<ul>
<li><span class="math inline">\(\hat{\sigma}_u= 5.99.\)</span> The estimated standard deviation of 2008 test scores is 5.99 points, after controlling for school type.</li>
<li><span class="math inline">\(\hat{\sigma}_v= 0.36.\)</span> The estimated standard deviation of yearly changes in test scores during the three-year observation period is 0.36 points, after controlling for school type.</li>
<li><span class="math inline">\(\hat{\rho}_{uv}= 0.88.\)</span> The estimated correlation between 2008 test scores and yearly changes in test scores is 0.88, after controlling for school type.</li>
<li><span class="math inline">\(\hat{\sigma}= 2.96.\)</span> The estimated standard deviation in residuals for the individual growth curves is 2.96 points.</li>
</ul></li>
</ul>
<p>Based on t-values reported by R, the effects of <code>year08</code> and <code>charter</code> both appear to be statistically significant, and there is also significant evidence of an interaction between <code>year08</code> and <code>charter</code>. Public schools had a significantly higher mean math score in 2008, while charter schools had significantly greater improvement in scores between 2008 and 2010 (although the mean score of charter schools still lagged behind that of public schools in 2010, as indicated in the graphical comparison of Models B and C in Figure <a href="ch-lon.html#fig:lon-scat4">9.18</a>). Based on pseudo R-squared values, the addition of a charter school indicator to the unconditional growth model has decreased unexplained school-to-school variability in 2008 math scores by 4.7%, while unexplained variability in yearly improvement actually increased slightly. Obviously, it makes little sense that introducing an additional predictor would <em>reduce</em> the amount of variability in test scores explained, but this is an example of the limitations in the pseudo R-squared values discussed in Section <a href="ch-multilevelintro.html#pseudoR2">8.7.2</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:lon-scat4"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lon-scat4-1.png" alt=" Fitted growth curves for Models B and C." width="60%" />
<p class="caption">
Figure 9.18:  Fitted growth curves for Models B and C.
</p>
</div>
</div>
<div id="modeld" class="section level3">
<h3><span class="header-section-number">9.6.2</span> Add Percent Free and Reduced Lunch as a Covariate</h3>
<p>Although we will still be primarily interested in the effect of school type on both 2008 test scores and rate of change in test scores (as we observed in Model C), we can try to improve our estimates of school type effects through the introduction of meaningful covariates. In this study, we are particularly interested in Level Two covariates—those variables which differ by school but which remain basically constant for a given school over time—such as urban or rural location, percentage of special education students, and percentage of students with free and reduced lunch. In Section <a href="ch-lon.html#twostage9">9.4</a>, we investigated the relationship between percent free and reduced lunch and a school’s test score in 2008 and their rate of change from 2008 to 2010.</p>
<p>Based on these analyses, we will begin by adding percent free and reduced lunch as a Level Two predictor for both intercept and slope (Model D):</p>
<ul>
<li><p>Level One:
<span class="math display">\[\begin{equation*}
Y_{ij}=a_{i} + b_{i}\textrm{Year08}_{ij} + \epsilon_{ij}
\end{equation*}\]</span></p></li>
<li><p>Level Two:
<span class="math display">\[\begin{align*}
a_{i} &amp; = \alpha_{0} + \alpha_{1}\textrm{Charter}_i + \alpha_{2}\textrm{schpctfree}_i + u_{i}\\
b_{i} &amp; = \beta_{0} + \beta_{1}\textrm{Charter}_i + \beta_{2}\textrm{schpctfree}_i + v_{i}
\end{align*}\]</span></p></li>
</ul>
<p>The composite model is then:</p>
<p><span class="math display">\[\begin{align*}
Y_{ij}= [\alpha_{0}&amp;+\alpha_{1}\textrm{Charter}_i +\alpha_{2}\textrm{schpctfree}_i + \beta_{0}\textrm{Year08}_{ij} \nonumber \\
 &amp;+ \beta_{1}\textrm{Charter}_i\textrm{Year08}_{ij}  + \beta_{2}\textrm{schpctfree}_i\textrm{Year08}_{ij}] \nonumber \\ 
 &amp;+ [u_{i} + v_{i}\textrm{Year08}_{ij} + \epsilon_{ij}]
\end{align*}\]</span>
where error terms are defined as in Model C.</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="ch-lon.html#cb234-1"></a><span class="co">#Model D2 (Introduce SchPctFree at level 2)</span></span>
<span id="cb234-2"><a href="ch-lon.html#cb234-2"></a>model.d2 &lt;-<span class="st"> </span><span class="kw">lmer</span>(MathAvgScore<span class="op">~</span><span class="st"> </span>charter <span class="op">+</span><span class="st"> </span>SchPctFree <span class="op">+</span><span class="st"> </span>year08 <span class="op">+</span><span class="st"> </span></span>
<span id="cb234-3"><a href="ch-lon.html#cb234-3"></a><span class="st">  </span>charter<span class="op">:</span>year08 <span class="op">+</span><span class="st"> </span>SchPctFree<span class="op">:</span>year08 <span class="op">+</span><span class="st"> </span>(year08<span class="op">|</span>schoolid),</span>
<span id="cb234-4"><a href="ch-lon.html#cb234-4"></a>  <span class="dt">REML=</span>T, <span class="dt">data=</span>chart.long)</span></code></pre></div>
<pre><code>##  Groups   Name        Variance Std.Dev. Corr
##  schoolid (Intercept) 19.13    4.37         
##           year08       0.16    0.40     0.51
##  Residual              8.80    2.97</code></pre>
<pre><code>##  Number of Level Two groups =  618</code></pre>
<pre><code>##                    Estimate Std. Error  t value
## (Intercept)       659.27848   0.444690 1482.558
## charter            -3.43994   0.712836   -4.826
## SchPctFree         -0.16654   0.008907  -18.697
## year08              1.64137   0.189499    8.662
## charter:year08      0.98076   0.318583    3.078
## SchPctFree:year08  -0.01041   0.003839   -2.711</code></pre>
<pre><code>##  AIC =  9988 ;  BIC =  10043</code></pre>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="ch-lon.html#cb239-1"></a>drop_in_dev &lt;-<span class="st"> </span><span class="kw">anova</span>(model.d2, model.c, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>         npar   AIC   BIC logLik   dev Chisq Df
model.c     8 10305 10348  -5144 10289    NA NA
model.d2   10  9967 10022  -4974  9947 341.5  2
              pval
model.c         NA
model.d2 7.158e-75</code></pre>
<p>Compared to Model C, the introduction of school-level poverty based on percentage of students receiving free and reduced lunch in Model D leads to similar conclusions about the significance of the charter school effect on both the intercept and the slope, although the magnitude of these estimates changes after controlling for poverty levels. The estimated gap in test scores between charter and non-charter schools in 2008 is smaller in Model D, while estimates of improvement between 2008 and 2010 increase for both types of schools. Inclusion of free and reduced lunch reduces the unexplained variability between schools in 2008 math scores by 27%, while unexplained variability in rates of change between schools again increases slightly based on pseudo R-squared values. A <strong>likelihood ratio test</strong> using maximum likelihood estimates illustrates that adding free and reduced lunch as a Level Two covariate significantly improves our model (<span class="math inline">\(\chi^2 = 341.5, df=2, p&lt;.001\)</span>). Specific fixed effect parameter estimates are given below:</p>
<ul>
<li><p><span class="math inline">\(\hat{\alpha}_{0}= 659.3.\)</span> The estimated mean math test score for 2008 is 659.3 for non-charter public schools with no students receiving free and reduced lunch.</p></li>
<li><p><span class="math inline">\(\hat{\alpha}_{1}= -3.44.\)</span> Charter schools have an estimated mean math test score in 2008 which is 3.44 points lower than non-charter public schools, controlling for effects of school-level poverty.</p></li>
<li><p><span class="math inline">\(\hat{\alpha}_{2}= -0.17.\)</span> Each 10% increase in the percentage of students at a school receiving free and reduced lunch is associated with a 1.7 point decrease in mean math test scores for 2008, after controlling for school type.</p></li>
<li><p><span class="math inline">\(\hat{\beta}_{0}= 1.64.\)</span> Public non-charter schools with no students receiving free and reduced lunch have an estimated mean increase in math test score of 1.64 points per year during the three years of observation.</p></li>
<li><p><span class="math inline">\(\hat{\beta}_{1}= 0.98.\)</span> Charter schools have an estimated mean yearly increase in math test scores over the three-year observation period of 2.62, which is 0.98 points higher than the annual increase for public non-charter schools, after controlling for school-level poverty.</p></li>
<li><p><span class="math inline">\(\hat{\beta}_{2}= -0.010.\)</span> Each 10% increase in the percentage of students at a school receiving free and reduced lunch is associated with a 0.10 point decrease in rate of change over the three years of observation, after controlling for school type.</p></li>
</ul>
</div>
<div id="modelf9" class="section level3">
<h3><span class="header-section-number">9.6.3</span> A Final Model with Three Level Two Covariates</h3>
<p>We now begin iterating toward a “final model” for these data, on which we will base conclusions. Being cognizant of typical features of a “final model” as outlined in Chapter <a href="ch-multilevelintro.html#ch-multilevelintro">8</a>, we offer one possible final model for this data—Model F:</p>
<ul>
<li>Level One:</li>
</ul>
<p><span class="math display">\[\begin{equation*}
Y_{ij}= a_{i} + b_{i}\textrm{Year08}_{ij} + \epsilon_{ij}
\end{equation*}\]</span></p>
<ul>
<li>Level Two:</li>
</ul>
<p><span class="math display">\[\begin{align*}
a_{i} &amp; = \alpha_{0} + \alpha_{1}\textrm{Charter}_i + \alpha_{2}\textrm{urban}_i + \alpha_{3}\textrm{schpctsped}_i + \alpha_{4}\textrm{schpctfree}_i + u_{i} \\
b_{i} &amp; = \beta_{0} + \beta_{1}\textrm{Charter}_i + \beta_{2}\textrm{urban}_i + \beta_{3}\textrm{schpctsped}_i + v_{i}
\end{align*}\]</span></p>
<p>where we find the effect of charter schools on 2008 test scores after adjusting for urban or rural location, percentage of special education students, and percentage of students that receive free or reduced lunch, and the effect of charter schools on yearly change between 2008 and 2010 after adjusting for urban or rural location and percentage of special education students. We can use AIC and BIC criteria to compare Model F with Model D, since the two models are not nested. By both criteria, Model F is significantly better than Model D: AIC of 9885 vs. 9988, and BIC of 9956 vs. 10043. Based on the R output below, we offer interpretations for estimates of model fixed effects:</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="ch-lon.html#cb241-1"></a>model.f2 &lt;-<span class="st"> </span><span class="kw">lmer</span>(MathAvgScore <span class="op">~</span><span class="st"> </span>charter <span class="op">+</span><span class="st"> </span>urban <span class="op">+</span><span class="st"> </span>SchPctFree <span class="op">+</span><span class="st"> </span></span>
<span id="cb241-2"><a href="ch-lon.html#cb241-2"></a><span class="st">  </span>SchPctSped <span class="op">+</span><span class="st"> </span>charter<span class="op">:</span>year08 <span class="op">+</span><span class="st"> </span>urban<span class="op">:</span>year08 <span class="op">+</span><span class="st"> </span></span>
<span id="cb241-3"><a href="ch-lon.html#cb241-3"></a><span class="st">  </span>SchPctSped<span class="op">:</span>year08 <span class="op">+</span><span class="st"> </span>year08 <span class="op">+</span></span>
<span id="cb241-4"><a href="ch-lon.html#cb241-4"></a><span class="st">  </span>(year08<span class="op">|</span>schoolid), <span class="dt">REML=</span>T, <span class="dt">data=</span>chart.long)</span></code></pre></div>
<pre><code>##  Groups   Name        Variance Std.Dev. Corr
##  schoolid (Intercept) 16.94756 4.1167       
##           year08       0.00475 0.0689   0.85
##  Residual              8.82197 2.9702</code></pre>
<pre><code>##  Number of Level Two groups =  618</code></pre>
<pre><code>##                    Estimate Std. Error  t value
## (Intercept)       661.01042   0.512888 1288.800
## charter            -3.22286   0.698547   -4.614
## urban              -1.11383   0.427566   -2.605
## SchPctFree         -0.15281   0.008096  -18.874
## SchPctSped         -0.11770   0.020612   -5.710
## year08              2.14430   0.200867   10.675
## charter:year08      1.03087   0.315159    3.271
## urban:year08       -0.52749   0.186480   -2.829
## SchPctSped:year08  -0.04674   0.010166   -4.598</code></pre>
<pre><code>##  AIC =  9885 ;  BIC =  9956</code></pre>
<ul>
<li><span class="math inline">\(\hat{\alpha}_{0}= 661.0.\)</span> The estimated mean math test score for 2008 is 661.0 for public schools in rural areas with no students qualifying for special education or free and reduced lunch.</li>
<li><span class="math inline">\(\hat{\alpha}_{1}= -3.22.\)</span> Charter schools have an estimated mean math test score in 2008 which is 3.22 points lower than non-charter public schools, after controlling for urban or rural location, percent special education, and percent free and reduced lunch.</li>
<li><span class="math inline">\(\hat{\alpha}_{2}= -1.11.\)</span> Schools in urban areas have an estimated mean math score in 2008 which is 1.11 points lower than schools in rural areas, after controlling for school type, percent special education, and percent free and reduced lunch.</li>
<li><span class="math inline">\(\hat{\alpha}_{3}= -0.118.\)</span> A 10% increase in special education students at a school is associated with a 1.18 point decrease in estimated mean math score for 2008, after controlling for school type, urban or rural location, and percent free and reduced lunch.</li>
<li><span class="math inline">\(\hat{\alpha}_{4}= -0.153.\)</span> A 10% increase in free and reduced lunch students at a school is associated with a 1.53 point decrease in estimated mean math score for 2008, after controlling for school type, urban or rural location, and percent special education.</li>
<li><span class="math inline">\(\hat{\beta}_{0}= 2.14.\)</span> Public non-charter schools in rural areas with no students qualifying for special education have an estimated increase in mean math test score of 2.14 points per year over the three-year observation period, after controlling for percent of students receiving free and reduced lunch.</li>
<li><span class="math inline">\(\hat{\beta}_{1}= 1.03.\)</span> Charter schools have an estimated mean annual increase in math score that is 1.03 points higher than public non-charter schools over the three-year observation period, after controlling for urban or rural location, percent special education, and percent free and reduced lunch.</li>
<li><span class="math inline">\(\hat{\beta}_{2}= -0.53.\)</span> Schools in urban areas have an estimated mean annual increase in math score that is 0.53 points lower than schools from rural areas over the three-year observation period, after controlling for school type, percent special education, and percent free and reduced lunch.</li>
<li><span class="math inline">\(\hat{\beta}_{3}= -0.047.\)</span> A 10% increase in special education students at a school is associated with an estimated mean annual increase in math score that is 0.47 points lower over the three-year observation period, after controlling for school type, urban or rural location, and percent free and reduced lunch.</li>
</ul>
<p>From this model, we again see that 2008 sixth grade math test scores from charter schools were significantly lower than similar scores from public non-charter schools, after controlling for school location and demographics. However, charter schools showed significantly greater improvement between 2008 and 2010 compared to public non-charter schools, although charter school test scores were still lower than public school scores in 2010, on average. We also tested several interactions between Level Two covariates and charter schools and found none to be significant, indicating that the 2008 gap between charter schools and public non-charter schools was consistent across demographic subgroups. The faster improvement between 2008 and 2010 for charter schools was also consistent across demographic subgroups (found by testing three-way interactions). Controlling for school location and demographic variables provided more reliable and nuanced estimates of the effects of charter schools, while also providing interesting insights. For example, schools in rural areas not only had higher test scores than schools in urban areas in 2008, but the gap grew larger over the study period given fixed levels of percent special education, percent free and reduced lunch, and school type. In addition, schools with higher levels of poverty lagged behind other schools and showed no signs of closing the gap, and schools with higher levels of special education students had both lower test scores in 2008 and slower rates of improvement during the study period, again given fixed levels of other covariates.</p>
<p>As we demonstrated in this case study, applying multilevel methods to two-level longitudinal data yields valuable insights about our original research questions while properly accounting for the structure of the data.</p>
</div>
<div id="longitudinal-paraboot" class="section level3">
<h3><span class="header-section-number">9.6.4</span> Parametric Bootstrap Testing</h3>
<p>We could further examine whether or not a simplified version of Model F, with fewer random effects, might be preferable. For instance, consider testing whether we could remove <span class="math inline">\(v_i\)</span> in Model F in Section <a href="ch-lon.html#modelf9">9.6.3</a>, to create Model F0. Removing <span class="math inline">\(v_i\)</span> is equivalent to setting <span class="math inline">\(\sigma_{v}^{2} = 0\)</span> and <span class="math inline">\(\rho_{uv} = 0\)</span>. We begin by comparing Model F (full model) to Model F0 (reduced model) using a likelihood ratio test:</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="ch-lon.html#cb246-1"></a><span class="co">#Model F0 (remove 2 variance components from Model F)</span></span>
<span id="cb246-2"><a href="ch-lon.html#cb246-2"></a>model.f0 &lt;-<span class="st"> </span><span class="kw">lmer</span>(MathAvgScore <span class="op">~</span><span class="st"> </span>charter <span class="op">+</span><span class="st"> </span>urban <span class="op">+</span><span class="st"> </span>SchPctFree <span class="op">+</span><span class="st"> </span></span>
<span id="cb246-3"><a href="ch-lon.html#cb246-3"></a><span class="st">  </span>SchPctSped <span class="op">+</span><span class="st"> </span>charter<span class="op">:</span>year08 <span class="op">+</span><span class="st"> </span>urban<span class="op">:</span>year08 <span class="op">+</span><span class="st"> </span></span>
<span id="cb246-4"><a href="ch-lon.html#cb246-4"></a><span class="st">  </span>SchPctSped<span class="op">:</span>year08 <span class="op">+</span><span class="st"> </span>year08 <span class="op">+</span></span>
<span id="cb246-5"><a href="ch-lon.html#cb246-5"></a><span class="st">  </span>(<span class="dv">1</span><span class="op">|</span>schoolid), <span class="dt">REML=</span>T, <span class="dt">data=</span>chart.long)</span></code></pre></div>
<pre><code>##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept) 17.46    4.18    
##  Residual              8.83    2.97</code></pre>
<pre><code>##  Number of Level Two groups =  618</code></pre>
<pre><code>##                    Estimate Std. Error  t value
## (Intercept)       661.02599    0.51691 1278.813
## charter            -3.21918    0.70543   -4.563
## urban              -1.11852    0.43204   -2.589
## SchPctFree         -0.15302    0.00810  -18.892
## SchPctSped         -0.11813    0.02080   -5.680
## year08              2.13924    0.20097   10.644
## charter:year08      1.03157    0.31551    3.270
## urban:year08       -0.52330    0.18651   -2.806
## SchPctSped:year08  -0.04645    0.01017   -4.568</code></pre>
<pre><code>##  AIC =  9881 ;  BIC =  9941</code></pre>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="ch-lon.html#cb251-1"></a>drop_in_dev &lt;-<span class="st"> </span><span class="kw">anova</span>(model.f2, model.f0, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>         npar  AIC  BIC logLik  dev  Chisq Df   pval
model.f0   11 9854 9914  -4916 9832     NA NA     NA
model.f2   13 9857 9928  -4916 9831 0.3376  2 0.8447</code></pre>
<p>When testing random effects at the boundary (such as <span class="math inline">\(\sigma_{v}^{2} = 0\)</span>) or those with restricted ranges (such as <span class="math inline">\(\rho_{uv} = 0\)</span>), using a chi-square distribution to conduct a likelihood ratio test is not appropriate. In fact, this will produce a conservative test, with p-values that are too large and not rejected enough (<span class="citation">Raudenbush and Bryk (<a href="#ref-Bryk2002" role="doc-biblioref">2002</a>)</span>, <span class="citation">Singer and Willett (<a href="#ref-Singer2003" role="doc-biblioref">2003</a>)</span>, <span class="citation">Faraway (<a href="#ref-Faraway2005" role="doc-biblioref">2005</a>)</span>). For example, we should suspect that the p-value (.8447) produced by the likelihood ratio test comparing Models F and F0 is too large, that the real probability of getting a likelihood ratio test statistic of 0.3376 or greater when Model F0 is true is smaller than .8447.</p>
<p>Researchers often use methods like the <strong>parametric bootstrap</strong>  to better approximate the distribution of the likelihood test statistic and produce more accurate p-values by simulating data under the null hypothesis. Here are the basic steps for running a parametric bootstrap procedure to compare Model F0 with Model F (see associated diagram in Figure <a href="ch-lon.html#fig:parabootdiagram">9.19</a>):</p>
<ul>
<li>Fit Model F0 (the null model) to obtain estimated fixed effects and variance components (this is the “parametric” part.)</li>
<li>Use the estimated fixed effects and variance components from the null model to regenerate a new set of math test scores with the same sample size (<span class="math inline">\(n=1733\)</span>) and associated covariates for each observation as the original data (this is the “bootstrap” part.)</li>
<li>Fit both Model F0 (the reduced model) and Model F (the full model) to the new data</li>
<li>Compute a likelihood ratio statistic comparing Models F0 and F</li>
<li>Repeat the previous 3 steps many times (e.g., 1000)</li>
<li>Produce a histogram of likelihood ratio statistics to illustrate its behavior when the null hypothesis is true</li>
<li>Calculate a p-value by finding the proportion of times the bootstrapped test statistic is greater than our observed test statistic</li>
</ul>
<div class="figure"><span id="fig:parabootdiagram"></span>
<img src="data/ParametricBootstrapDiagram9.png" alt="The steps in conducting a parametric bootstrap test comparing Models F and F0." width="90%" />
<p class="caption">
Figure 9.19: The steps in conducting a parametric bootstrap test comparing Models F and F0.
</p>
</div>
<p>Let’s see how new test scores are generated under the parametric bootstrap. Consider, for instance, <span class="math inline">\(i=1\)</span> and <span class="math inline">\(j=1,2,3\)</span>; that is, consider test scores for School #1 (Rippleside Elementary) across all three years (2008, 2009, and 2010). Table <a href="ch-lon.html#tab:rippleside">9.4</a> shows the original data for Rippleside Elementary.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:rippleside">Table 9.4: </span>Original data for Rippleside Elementary (School 1).
</caption>
<thead>
<tr>
<th style="text-align:left;">
schoolName
</th>
<th style="text-align:right;">
urban
</th>
<th style="text-align:right;">
charter
</th>
<th style="text-align:right;">
schPctsped
</th>
<th style="text-align:right;">
schPctfree
</th>
<th style="text-align:right;">
year08
</th>
<th style="text-align:right;">
MathAvgScore
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
RIPPLESIDE ELEMENTARY
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.1176
</td>
<td style="text-align:right;">
0.3627
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
652.8
</td>
</tr>
<tr>
<td style="text-align:left;">
RIPPLESIDE ELEMENTARY
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.1176
</td>
<td style="text-align:right;">
0.3627
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
656.6
</td>
</tr>
<tr>
<td style="text-align:left;">
RIPPLESIDE ELEMENTARY
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.1176
</td>
<td style="text-align:right;">
0.3627
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
652.6
</td>
</tr>
</tbody>
</table>
<p><strong>Level Two</strong></p>
<p>One way to see the data generation process under the null model (Model F0) is to start with Level Two and work backwards to Level One. Recall that our Level Two models for <span class="math inline">\(a_{i}\)</span> and <span class="math inline">\(b_{i}\)</span>, the true intercept and slope for school <span class="math inline">\(i\)</span>, in Model F0 are:</p>
<p><span class="math display">\[\begin{align*}
a_{i} &amp; = \alpha_{0} + \alpha_{1}\textrm{Charter}_i + \alpha_{2}\textrm{urban}_i + \alpha_{3}\textrm{schpctsped}_i + \alpha_{4}\textrm{schpctfree}_i + u_{i} \\
b_{i} &amp; = \beta_{0} + \beta_{1}\textrm{Charter}_i + \beta_{2}\textrm{urban}_i + \beta_{3}\textrm{schpctsped}_i
\end{align*}\]</span></p>
<p>All the <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> terms will be fixed at their estimated values, so the one term that will change for each bootstrapped data set is <span class="math inline">\(u_{i}\)</span>. As we obtain a numeric value for <span class="math inline">\(u_{i}\)</span> for each school, we will fix the subscript. For example, if <span class="math inline">\(u_{i}\)</span> is set to -5.92 for School #1, then we would denote this by <span class="math inline">\(u_{1}=-5.92\)</span>. Similarly, in the context of Model F0, <span class="math inline">\(a_{1}\)</span> represents the 2008 math test score for School #1, where <span class="math inline">\(u_{1}\)</span> quantifies how School #1’s 2008 score differs from the average 2008 score across all schools with the same attributes: charter status, urban or rural location, percent of special education students, and percent of free and reduced lunch students.</p>
<p>According to Model F0, each <span class="math inline">\(u_{i}\)</span> is sampled from a normal distribution with mean 0 and standard deviation 4.18. That is, a random component to the intercept for School #1 (<span class="math inline">\(u_{1}\)</span>) would be sampled from a normal distribution with mean 0 and SD 4.18; say, for instance, <span class="math inline">\(u_{1}=-5.92\)</span>. We would sample <span class="math inline">\(u_{2},...,u_{618}\)</span> in a similar manner for all 618 schools. Then we can produce a model-based intercept and slope for School #1:</p>
<p><span class="math display">\[\begin{align*}
a_{1} &amp; = 661.03-3.22(0)-1.12(0)-0.12(11.8)-0.15(36.3)-5.92 = 648.2 \\
b_{1} &amp; = 2.14+1.03(0)-0.52(0)-.046(11.8) = 1.60
\end{align*}\]</span></p>
<p>Notice a couple of features of the above derivations. First, all of the coefficients from the above equations (<span class="math inline">\(\alpha_{0}=661.03\)</span>, <span class="math inline">\(\alpha_{1}=-3.22\)</span>, etc.) come from the estimated fixed effects from Model F0. Second, “public non-charter” is the reference level for <code>charter</code> and “rural” is the reference level for <code>urban</code>, so both of those predictors are 0 for Rippleside Elementary. Third, the mean intercept (2008 test scores) for schools like Rippleside that are rural and public non-charter, with 11.8% special education students and 36.3% free and reduced lunch students, is 661.03 - 0.12(11.8) - 0.15(36.3) = 654.2. The mean yearly improvement in test scores for rural, public non-charter schools with 11.8% special education students is then 1.60 points per year (2.14 - .046*11.8). School #1 (Rippleside) therefore has a 2008 test score that is 5.92 points below the mean for all similar schools, but every such school is assumed to have the same improvement rate in test scores of 1.60 points per year because of our assumption that there is no school-to-school variability in yearly rate of change (i.e., <span class="math inline">\(v_{i}=0\)</span>).</p>
<p><strong>Level One</strong></p>
<p>We next proceed to Level One, where the scores from Rippleside are modeled as a linear function of year (<span class="math inline">\(654.2 + 1.60\textrm{Year08}_{ij}\)</span>) with a normally distributed residual <span class="math inline">\(\epsilon_{1k}\)</span> at each time point <span class="math inline">\(k\)</span>. Three residuals (one for each year) are sampled independently from a normal distribution with mean 0 and standard deviation 2.97 – the standard deviation again coming from parameter estimates from fitting Model F0 to the actual data. Suppose we obtain residuals of <span class="math inline">\(\epsilon_{11}=-3.11\)</span>, <span class="math inline">\(\epsilon_{12}=1.19\)</span>, and <span class="math inline">\(\epsilon_{13}=2.41\)</span>. In that case, our parametrically generated data for Rippleside Elementary (School #1) would look like:</p>
<p><span class="math display">\[ \begin{array}{rcccl}
   Y_{11} &amp; = &amp; 654.2+1.60(0)-3.11 &amp; = &amp; 651.1 \\
   Y_{12} &amp; = &amp; 654.2+1.60(1)+1.19 &amp; = &amp; 657.0 \\
   Y_{13} &amp; = &amp; 654.2+1.60(2)+2.41 &amp; = &amp; 659.8 \\
   \end{array} \]</span></p>
<p>We would next turn to School #2 (<span class="math inline">\(i=2\)</span>)—Wrenshall Elementary. Fixed effects would remain the same but covariates would change, as Wrenshall has 15.2% special education students and 42.4% free and reduced lunch students. We would, however, sample a new residual <span class="math inline">\(u_{2}\)</span> at Level Two, producing a different intercept <span class="math inline">\(a_{2}\)</span> than observed for School #1. Three new independent residuals <span class="math inline">\(\epsilon_{2k}\)</span> would also be selected at Level One, from the same normal distribution as before with mean 0 and standard deviation 2.97.</p>
<p>Once an entire set of simulated scores for every school and year have been generated based on Model F0, two models are fit to this data:</p>
<ul>
<li>Model F0 – the correct (null) model that was actually used to generate the responses</li>
<li>Model F – the incorrect (full) model that contains two extra variance components – <span class="math inline">\(\sigma_{v}^{2}\)</span> and <span class="math inline">\(\sigma_{uv}\)</span> – that were not actually used when generating the responses</li>
</ul>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="ch-lon.html#cb253-1"></a><span class="co"># Generate 1 set of bootstrapped data and run chi-square test</span></span>
<span id="cb253-2"><a href="ch-lon.html#cb253-2"></a><span class="co">#  (will also work if use REML models, but may take longer)</span></span>
<span id="cb253-3"><a href="ch-lon.html#cb253-3"></a><span class="kw">set.seed</span>(<span class="dv">3333</span>)</span>
<span id="cb253-4"><a href="ch-lon.html#cb253-4"></a>d &lt;-<span class="st"> </span><span class="kw">drop</span>(<span class="kw">simulate</span>(model.f0ml))</span>
<span id="cb253-5"><a href="ch-lon.html#cb253-5"></a>m2 &lt;-<span class="kw">refit</span>(model.f2ml, <span class="dt">newresp=</span>d)</span>
<span id="cb253-6"><a href="ch-lon.html#cb253-6"></a>m1 &lt;-<span class="kw">refit</span>(model.f0ml, <span class="dt">newresp=</span>d)</span>
<span id="cb253-7"><a href="ch-lon.html#cb253-7"></a>drop_in_dev &lt;-<span class="st"> </span><span class="kw">anova</span>(m2, m1, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>   npar  AIC  BIC logLik  dev Chisq Df   pval
m1   11 9891 9951  -4935 9869    NA NA     NA
m2   13 9891 9962  -4932 9865 4.581  2 0.1012</code></pre>
<p>A likelihood ratio test statistic is calculated comparing Model F0 to Model F. For example, after continuing as above to generate new <span class="math inline">\(Y_{ij}\)</span> values corresponding to all 1733 score observations, we fit both models to the “bootstrapped” data. Since the data was generated using Model F0, we would expect the two extra terms in Model F (<span class="math inline">\(\sigma^2_{v}\)</span> and <span class="math inline">\(\sigma_{uv}\)</span>) to contribute very little to the quality of the fit; Model F will have a slightly larger likelihood and loglikelihood since it contains every parameter from Model F0 plus two more, but the difference in the likelihoods should be due to chance. In fact, that is what the output above shows. Model F does have a larger loglikelihood than Model F0 (-4932 vs. -4935), but this small difference is not statistically significant based on a chi-square test with 2 degrees of freedom (p=.1012).</p>
<p>However, we are really only interested in saving the likelihood ratio test statistic from this bootstrapped sample (<span class="math inline">\(2*(-4932) - (-4935) = 4.581\)</span>). By generating (“bootstrapping”) many sets of responses based on estimated parameters from Model F0 and calculating many likelihood ratio test statistics, we can observe how this test statistic behaves under the null hypothesis of <span class="math inline">\(\sigma_{v}^{2} = \sigma_{uv} = 0\)</span>, rather than making the (dubious) assumption that its behavior is described by a chi-square distribution with 2 degrees of freedom. Figure <a href="ch-lon.html#fig:paraboot9">9.20</a> illustrates the null distribution of the likelihood ratio test statistic derived by the parametric bootstrap procedure as compared to a chi-square distribution. A p-value for comparing our full and reduced models can be approximated by finding the proportion of likelihood ratio test statistics generated under the null model which exceed our observed likelihood ratio test (0.3376). The parametric bootstrap provides a more reliable p-value in this case (.578 from table below); a chi-square distribution puts too much mass in the tail and not enough near 0, leading to overestimation of the p-value. Based on this test, we would still choose our simpler Model F0.</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="ch-lon.html#cb255-1"></a><span class="kw">bootstrapAnova</span>(<span class="dt">mA=</span>model.f2ml, <span class="dt">m0=</span>model.f0ml, <span class="dt">B=</span><span class="dv">1000</span>)</span></code></pre></div>
<pre><code>   npar logLik  dev  Chisq Df pval_boot
m0   11  -4916 9832     NA NA        NA
mA   13  -4916 9831 0.3376  2     0.578</code></pre>
<div class="figure" style="text-align: center"><span id="fig:paraboot9"></span>
<img src="bookdown-BeyondMLR_files/figure-html/paraboot9-1.png" alt="Null distribution of likelihood ratio test statistic derived using parametric bootstrap (histogram) compared to a chi-square distribution with 2 degrees of freedom (smooth curve).  The vertical line represents the observed likelihood ratio test statistic." width="60%" />
<p class="caption">
Figure 9.20: Null distribution of likelihood ratio test statistic derived using parametric bootstrap (histogram) compared to a chi-square distribution with 2 degrees of freedom (smooth curve). The vertical line represents the observed likelihood ratio test statistic.
</p>
</div>
<p>Another way of examining whether or not we should stick with the reduced model or reject it in favor of the larger model is by generating parametric bootstrap samples, and then using those samples to produce 95% confidence intervals for both <span class="math inline">\(\rho_{uv}\)</span> and <span class="math inline">\(\sigma_{v}\)</span>.</p>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="ch-lon.html#cb257-1"></a>bootciF =<span class="st"> </span><span class="kw">confint</span>(model.f2, <span class="dt">method=</span><span class="st">&quot;boot&quot;</span>, <span class="dt">oldNames=</span>F)</span>
<span id="cb257-2"><a href="ch-lon.html#cb257-2"></a>bootciF</span></code></pre></div>
<pre><code>##                                      2.5 %    97.5 %
## sd_(Intercept)|schoolid           3.801826   4.50866
## cor_year08.(Intercept)|schoolid  -1.000000   1.00000
## sd_year08|schoolid                0.009203   0.91060
## sigma                             2.779393   3.07776
## (Intercept)                     660.071996 662.04728
## charter                          -4.588611  -2.07372
## urban                            -2.031600  -0.29152
## SchPctFree                       -0.169426  -0.13738
## SchPctSped                       -0.156065  -0.07548
## year08                            1.722458   2.56106
## charter:year08                    0.449139   1.65928
## urban:year08                     -0.905941  -0.17156
## SchPctSped:year08                -0.066985  -0.02617</code></pre>
<p>From the output above, the 95% bootstrapped confidence interval for <span class="math inline">\(\rho_{uv}\)</span> (-1, 1) contains 0, and the interval for <span class="math inline">\(\sigma_{v}\)</span> (0.0092, 0.9106) nearly contains 0, providing further evidence that the larger model is not needed.</p>
<p>In this section, we have offered the parametric bootstrap as a noticeable improvement over the likelihood ratio test with an approximate chi-square distribution for testing random effects, especially those near a boundary. Typically when we conduct hypothesis tests involving variance terms we are testing at the boundary, since we are asking if the variance term is really necessary (i.e., <span class="math inline">\(H_0: \sigma^2=0\)</span> vs. <span class="math inline">\(H_A: \sigma^2 &gt; 0\)</span>). However, what if we are conducting a hypothesis test about a fixed effect? For the typical test of whether or not a fixed effect is significant – e.g., <span class="math inline">\(H_0: \alpha_i=0\)</span> vs. <span class="math inline">\(H_A: \alpha_i \neq 0\)</span> – we are <em>not</em> testing at the boundary, since most fixed effects have no bounds on allowable values. We have often used a likelihood ratio test with an approximate chi-square distribution in these settings. Does that provide accurate p-values? Although some research (e.g., <span class="citation">Faraway (<a href="#ref-Faraway2005" role="doc-biblioref">2005</a>)</span>) shows that p-values of fixed effects from likelihood ratio tests can tend to be anti-conservative (too low), in general the approximation is not bad. We will continue to use the likelihood ratio test with a chi-square distribution for fixed effects, but you could always check your p-values using a parametric bootstrap approach.</p>
</div>
</div>
<div id="errorcovariance" class="section level2">
<h2><span class="header-section-number">9.7</span> Covariance Structure among Observations</h2>
<p>Part of our motivation for framing our model for multilevel data was to account for the correlation among observations made on the same school (the Level Two observational unit). Our two-level model, through error terms on both Level One and Level Two variables, actually implies a specific within-school covariance structure  among observations, yet we have not (until now) focused on this imposed structure. For example:</p>
<ul>
<li>What does our two-level model say about the relative variability of 2008 and 2010 scores from the same school?</li>
<li>What does it say about the correlation between 2008 and 2009 scores from the same school?</li>
</ul>
<p>In this section, we will describe the within-school covariance structure imposed by our two-level model and offer alternative covariance structures that we might consider, especially in the context of longitudinal data. In short, we will discuss how we might decide if our implicit covariance structure in our two-level model is satisfactory for the data at hand. Then, in the succeeding optional section, we provide derivations of the imposed within-school covariance structure for our standard two-level model using results from probability theory.</p>
<div id="standarderror" class="section level3">
<h3><span class="header-section-number">9.7.1</span> Standard Covariance Structure</h3>
<p>We will use Model C (uncontrolled effects of school type) to illustrate covariance structure within subjects. Recall that, in composite form, Model C is:</p>
<p><span class="math display">\[\begin{align*}
Y_{ij} &amp; = a_{i}+b_{i}\textrm{Year08}_{ij}+ \epsilon_{ij} \\
       &amp; = (\alpha_{0}+ \alpha_{1}\textrm{Charter}_i + u_{i}) + (\beta_{0}+\beta_{1}\textrm{Charter}_i +v_{i}) \textrm{Year08}_{ij} + \epsilon_{ij} \\
       &amp; = [\alpha_{0}+\alpha_{1}\textrm{Charter}_i + \beta_{0}\textrm{Year08}_{ij} + \beta_{1}\textrm{Charter}_i\textrm{Year08}_{ij}] + [u_{i} \\
       &amp; \quad + v_{i}\textrm{Year08}_{ij} + \epsilon_{ij}]
\end{align*}\]</span>
where <span class="math inline">\(\epsilon_{ij}\sim N(0,\sigma^2)\)</span> and</p>
<p><span class="math display">\[ \left[ \begin{array}{c}
            u_{i} \\ v_{i}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cc}
            \sigma_{u}^{2} &amp; \\
            \sigma_{uv} &amp; \sigma_{v}^{2}
          \end{array} \right] \right) . \]</span></p>
<p>For School <span class="math inline">\(i\)</span>, the covariance structure for the three time points has general form:</p>
<p><span class="math display">\[ Cov(\mathbf{Y}_i) =  \left[
          \begin{array}{cccc}
            Var(Y_{i1}) &amp; Cov(Y_{i1},Y_{i2}) &amp; Cov(Y_{i1},Y_{i3}) \\
            Cov(Y_{i1},Y_{i2}) &amp; Var(Y_{i2}) &amp; Cov(Y_{i2},Y_{i3}) \\
            Cov(Y_{i1},Y_{i3}) &amp; Cov(Y_{i2},Y_{i3}) &amp; Var(Y_{i3})
          \end{array} \right] \]</span>
where, for instance, <span class="math inline">\(Var(Y_{i1})\)</span> is the variability in 2008 test scores (time <span class="math inline">\(j=1\)</span>), <span class="math inline">\(Cov(Y_{i1},Y_{i2})\)</span> is the covariance between 2008 and 2009 test scores (times <span class="math inline">\(j=1\)</span> and <span class="math inline">\(j=2\)</span>), etc. Since covariance measures the tendency of two variables to move together, we expect positive values for all three covariance terms in <span class="math inline">\(Cov(\mathbf{Y}_i)\)</span>, since schools with relatively high test scores in 2008 are likely to also have relatively high test scores in 2009 or 2010. The correlation between two variables then scales covariance terms to values between -1 and 1, so by the same rationale, we expect correlation coefficients between two years to be near 1. If observations within school were independent—that is, knowing a school had relatively high scores in 2008 tells nothing about whether that school will have relatively high scores in 2009 or 2010—then we would expect covariance and correlation values near 0.</p>
<p>It is important to notice that the error structure at Level Two is <em>not</em> the same as the within-school covariance structure among observations. That is, the relationship between <span class="math inline">\(u_{i}\)</span> and <span class="math inline">\(v_{i}\)</span> from the Level Two equations is not the same as the relationship between test scores from different years at the same school (e.g., the relationship between <span class="math inline">\(Y_{i1}\)</span> and <span class="math inline">\(Y_{i2}\)</span>). In other words,</p>
<p><span class="math display">\[ Cov(\mathbf{Y}_i) \neq \left[ \begin{array}{c}
            u_{i} \\ v_{i}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cc}
            \sigma_{u}^{2} &amp; \\
            \sigma_{uv} &amp; \sigma_{v}^{2}
          \end{array} \right] \right) . \]</span>
Yet, the error structure and the covariance structure <em>are</em> connected to each other, as we will now explore.</p>
<p>Using results from probability theory (see Section <a href="ch-lon.html#optionalcov">9.7.5</a>), we can show that:</p>
<p><span class="math display">\[\begin{align*}
Var(Y_{ij}) &amp; = \sigma_{u}^{2} + t^{2}_{ij} \sigma_{v}^{2} + \sigma^{2} + 2t_{ij}\sigma_{uv}, \\
Cov(Y_{ij},Y_{ik}) &amp; = \sigma_{u}^{2} + t_{ij}t_{ik} \sigma_{v}^{2} + (t_{ij}+t_{ik})\sigma_{uv}
\end{align*}\]</span>
for all <span class="math inline">\(i\)</span>, where our time variable (<code>year08</code>) has values <span class="math inline">\(t_{i1}=0\)</span>, <span class="math inline">\(t_{i2}=1\)</span>, and <span class="math inline">\(t_{i3}=2\)</span> for every School <span class="math inline">\(i\)</span>. Intuitively, these formulas are sensible. For instance, <span class="math inline">\(Var(Y_{i1})\)</span>, the uncertainty (variability) around a school’s score in 2008, increases as the uncertainty in intercepts and slopes increases, as the uncertainty around that school’s linear time trend increases, and as the covariance between intercept and slope residuals increases (since if one is off, the other one is likely off as well). Also, <span class="math inline">\(Cov(Y_{i1},Y_{i2})\)</span>, the covariance between 2008 and 2009 scores, does not depend on Level One error. Thus, in the 3-by-3 within-school covariance structure of the charter schools case study, our standard two-level model determines all 6 covariance matrix elements through the estimation of four parameters (<span class="math inline">\(\sigma_{u}^{2}, \sigma_{uv}, \sigma_{v}^{2}, \sigma^2\)</span>) and the imposition of a specific structure related to time.</p>
<p>To obtain estimated variances for individual observations and covariances between two time points from the same school, we can simply plug estimated variance components from our two-level model along with time points from our data collection into the equations above. For instance, in Section <a href="ch-lon.html#sec:modelc9">9.6.1</a>, we obtained the following estimates of variance components: <span class="math inline">\(\hat{\sigma}^{2}=8.784\)</span>, <span class="math inline">\(\hat{\sigma}^{2}_{u}=35.832\)</span>, <span class="math inline">\(\hat{\sigma}^{2}_{v}=0.131\)</span>, and <span class="math inline">\(\hat{\sigma}_{uv}=\hat{\rho}\hat{\sigma_{u}}\hat{\sigma_{v}}=1.907\)</span>. Therefore, our estimated within-school variances for the three time points would be:</p>
<p><span class="math display">\[\begin{align*}
\hat{Var}(Y_{i1}) &amp; = 35.832 + 0^{2} 0.131 + 8.784 + 2(0)1.907 = 44.62 \\
\hat{Var}(Y_{i2}) &amp; = 35.832 + 1^{2} 0.131 + 8.784 + 2(1)1.907 = 48.56 \\
\hat{Var}(Y_{i3}) &amp; = 35.832 + 2^{2} 0.131 + 8.784 + 2(2)1.907 = 52.77
\end{align*}\]</span>
and our estimated within-school covariances between different time points would be:</p>
<p><span class="math display">\[\begin{align*}
\hat{Cov}(Y_{i1},Y_{i2}) &amp; = 35.832 + (0)(1)0.131 + (0+1)1.907 = 37.74 \\
\hat{Cov}(Y_{i1},Y_{i3}) &amp; = 35.832 + (0)(2)0.131 + (0+2)1.907 = 39.65 \\
\hat{Cov}(Y_{i2},Y_{i3}) &amp; = 35.832 + (1)(2)0.131 + (1+2)1.907 = 41.81
\end{align*}\]</span>
In fact, these values will be identical for every School <span class="math inline">\(i\)</span>, since scores were assessed at the same three time points. Thus, we will drop the subscript <span class="math inline">\(i\)</span> moving forward.</p>
<p>Written in matrix form, our two-level model implicitly imposes this estimated covariance structure on within-school observations for any specific School <span class="math inline">\(i\)</span>:</p>
<p><span class="math display">\[ \hat{Cov}(\mathbf{Y}) =  \left[
          \begin{array}{cccc}
            44.62 &amp; &amp;   \\
            37.74 &amp; 48.56 &amp;  \\
            39.65 &amp; 41.81 &amp; 52.77
          \end{array} \right] \]</span>
and this estimated covariance matrix can be converted into an estimated within-school correlation matrix using the identity <span class="math inline">\(Corr(Y_{1},Y_{2})=\frac{Cov(Y_{1},Y_{2})}{\sqrt{Var(Y_{1}) Var(Y_{2})}}\)</span>:</p>
<p><span class="math display">\[ \hat{Corr}(\mathbf{Y}) =  \left[
          \begin{array}{cccc}
            1 &amp; &amp;   \\
            .811 &amp; 1 &amp;  \\
            .817 &amp; .826 &amp; 1
          \end{array} \right] \]</span></p>
<p>A couple of features of these two matrices can be highlighted that offer insights into implications of our standard two-level model on the covariance structure among observations at Level One from the same school:</p>
<ul>
<li>Many longitudinal data sets show higher correlation for observations that are closer in time. In this case, we see that correlation is very consistent between all pairs of observations from the same school; the correlation between test scores separated by two years (.817) is approximately the same as the correlation between test scores separated by a single year (.811 for 2008 and 2009 scores; .826 for 2009 and 2010 scores).</li>
<li>Many longitudinal data sets show similar variability at all time points. In this case, the variability in 2010 (52.77) is about 18% greater than the variability in 2008 (44.62), while the variability in 2009 is in between (48.56).</li>
<li>Our two-level model actually imposes a quadratic structure on the relationship between variance and time; note that the equation for <span class="math inline">\(Var(Y_{j})\)</span> contains both <span class="math inline">\(t^{2}_{j}\)</span> and <span class="math inline">\(t_{j}\)</span>. The variance is therefore minimized at <span class="math inline">\(t=\frac{-\sigma_{uv}}{\sigma^{2}_{v}}\)</span>. With the charter school data, the variance in test scores is minimized when <span class="math inline">\(t=\frac{-\sigma_{uv}}{\sigma^{2}_{v}}=\frac{-1.907}{0.131}=-14.6\)</span>; that is, the smallest within-school variance in test scores is expected 14.6 years prior to 2008 (i.e., about 1994), and the variance increases parabolically from there. In general, cases in which <span class="math inline">\(\sigma^{2}_{v}\)</span> and <span class="math inline">\(\sigma_{uv}\)</span> are relatively small have little curvature and fairly consistent variability over time.</li>
<li>There is no requirement that time points within school need to be evenly spaced or even that each school has an equal number of measurements over time, which makes the two-level model structure nicely flexible.</li>
</ul>
</div>
<div id="alternateerror" class="section level3">
<h3><span class="header-section-number">9.7.2</span> Alternative Covariance Structures</h3>
<p>The standard covariance structure that’s implied by our multilevel modeling structure provides a useful model in a wide variety of situations—it provides a reasonable model for Level One variability with a relatively small number of parameters, and it has sufficient flexibility to accommodate irregular time intervals as well as subjects with a different number of observations over time. However, there may be cases in which a better fitting model requires additional parameters, or when a simpler model with fewer parameters still provides a good fit to the data. Here is an outline of a few alternative error structures:</p>
<ul>
<li><em>Unstructured</em> - Every variance and covariance term for observations within a school is a separate parameter and is therefore estimated uniquely; no patterns among variances or correlations are assumed. This structure offers maximum flexibility but is most costly in terms of parameters estimated.</li>
<li><em>Compound symmetry</em> - Assume variance is constant across all time points and correlation is constant across all pairs of time points. This structure is highly restrictive but least costly in terms of parameters estimated.</li>
<li><em>Autoregressive</em> - Assume variance is constant across all time points, but correlation drops off in a systematic fashion as the gap in time increases. Autoregressive models expand compound symmetry by allowing for a common structure where points closest in time are most highly correlated.</li>
<li><em>Toeplitz</em> - Toeplitz is similar to the autoregressive model, except that it does not impose any structure on the decline in correlation as time gaps increase. Thus, it requires more parameters to be estimated than the autoregressive model while providing additional flexibility.</li>
<li><em>Heterogeneous variances</em> - The assumption that variances are equal across time points found in the compound symmetry, autoregressive, and Toeplitz models can be relaxed by introducing additional parameters to allow unequal (heterogeneous) variances.</li>
</ul>
<p>When the focus of an analysis is on stochastic parameters (variance components) rather than fixed effects, parameter estimates are typically based on restricted maximum likelihood (REML) methods; model performance statistics then reflect only the stochastic portion of the model. Models with the same fixed effects but different covariance structures can be compared as usual—with AIC and BIC measures when models are not nested and with likelihood ratio tests when models are nested. However, using a chi-square distribution to conduct a likelihood ratio test in these cases can often produce a conservative test, with p-values that are too large and not rejected enough (<span class="citation">Raudenbush and Bryk (<a href="#ref-Bryk2002" role="doc-biblioref">2002</a>)</span>; <span class="citation">Singer and Willett (<a href="#ref-Singer2003" role="doc-biblioref">2003</a>)</span>; <span class="citation">Faraway (<a href="#ref-Faraway2005" role="doc-biblioref">2005</a>)</span>). In Section <a href="ch-lon.html#longitudinal-paraboot">9.6.4</a>, we introduced the parametric bootstrap as a potentially better way of testing models nested in their random effects.</p>
</div>
<div id="non-longitudinal-multilevel-models" class="section level3">
<h3><span class="header-section-number">9.7.3</span> Non-longitudinal Multilevel Models</h3>
<p>Careful modeling and estimation of the Level One covariance matrix is especially important and valuable for longitudinal data (with time at Level One) and as we’ve seen, our standard two-level model has several nice properties for this purpose. The standard model is also often appropriate for non-longitudinal multilevel models as discussed in Chapter <a href="ch-multilevelintro.html#ch-multilevelintro">8</a>, although we must remain aware of the covariance structure implicitly imposed. In other words, the ideas in this section generalize even if time isn’t a Level One covariate.</p>
<p>As an example, in Case Study <a href="ch-multilevelintro.html#cs:music">8.2</a> where Level One observational units are musical performances rather than time points, the standard model implies the following covariance structure for Musician <span class="math inline">\(i\)</span> in Model C, which uses an indicator for large ensembles as a Level One predictor:</p>
<p><span class="math display">\[\begin{align*}
Var(Y_{ij}) &amp; = \sigma_{u}^{2} + \textrm{Large}^{2}_{ij} \sigma_{v}^{2} + \sigma^{2} + 2\textrm{Large}_{ij}\sigma_{uv} \\
 &amp; = \left\{ \begin{array}{ll}
                 \sigma^{2} + \sigma_{u}^{2} &amp; \mbox{if $\textrm{Large}_{ij}=0$} \\
                 \sigma^{2} + \sigma_{u}^{2} + \sigma_{v}^{2} + 2\sigma_{uv} &amp; \mbox{if $\textrm{Large}_{ij}=1$}
               \end{array}
       \right.
\end{align*}\]</span>
and</p>
<p><span class="math display">\[\begin{align*}
Cov(Y_{ij},Y_{ik}) &amp; = \sigma_{u}^{2} + \textrm{Large}_{ij}\textrm{Large}_{ik} \sigma_{v}^{2} + (\textrm{Large}_{ij} + 
  \textrm{Large}_{ik}) \sigma_{uv} \\
 &amp; = \left\{ \begin{array}{ll}
                 \sigma_{u}^{2} &amp; \mbox{if $\textrm{Large}_{ij}=\textrm{Large}_{ik}=0$} \\
                 \sigma_{u}^{2} + \sigma_{uv} &amp; \mbox{if $\textrm{Large}_{ij}=0$, $\textrm{Large}_{ik}=1$ or vice versa} \\
                 \sigma_{u}^{2} + \sigma_{v}^{2} + 2\sigma_{uv} &amp; \mbox{if $\textrm{Large}_{ij}=\textrm{Large}_{ik}=1$}
               \end{array}
       \right.
\end{align*}\]</span>
Note that, in the Music Performance Anxiety case study, each subject will have a unique Level One variance-covariance structure, since each subject has a different number of performances and a different mix of large ensemble and small ensemble or solo performances.</p>
</div>
<div id="final-thoughts-regarding-covariance-structures" class="section level3">
<h3><span class="header-section-number">9.7.4</span> Final Thoughts Regarding Covariance Structures</h3>
<p>In the charter school example, as is often true in multilevel models, the choice of covariance matrix does not greatly affect estimates of fixed effects. The choice of covariance structure could potentially impact the standard errors of fixed effects, and thus the associated test statistics, but the impact appears minimal in this particular case study. In fact, the standard model typically works very well. So is it worth the time and effort to accurately model the covariance structure? If primary interest is in inference regarding fixed effects, and if the standard errors for the fixed effects appear robust to choice of covariance structure, then extensive time spent modeling the covariance structure is not advised. However, if researchers are interested in predicted random effects and estimated variance components in addition to estimated fixed effects, then choice of covariance structure can make a big difference. For instance, if researchers are interested in drawing conclusions about particular schools rather than charter schools in general, they may more carefully model the covariance structure in this study.</p>
</div>
<div id="optionalcov" class="section level3">
<h3><span class="header-section-number">9.7.5</span> Details of Covariance Structures (optional)</h3>
<p>Using Model C as specified in Section <a href="ch-lon.html#standarderror">9.7.1</a>, we specified the general covariance structure for School <span class="math inline">\(i\)</span> as:</p>
<p><span class="math display">\[ Cov(\mathbf{Y}_i) =  \left[
          \begin{array}{cccc}
            Var(Y_{i1}) &amp; Cov(Y_{i1},Y_{i2}) &amp; Cov(Y_{i1},Y_{i3}) \\
            Cov(Y_{i1},Y_{i2}) &amp; Var(Y_{i2}) &amp; Cov(Y_{i2},Y_{i3}) \\
            Cov(Y_{i1},Y_{i3}) &amp; Cov(Y_{i2},Y_{i3}) &amp; Var(Y_{i3})
          \end{array} \right] \]</span>
If <span class="math inline">\(Y_1 = a_1 X_1 + a_2 X_2 + a_3\)</span> and <span class="math inline">\(Y_2 = b_1 X_1 + b_2 X_2 + b_3\)</span> where <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are random variables and <span class="math inline">\(a_i\)</span> and <span class="math inline">\(b_i\)</span> are constants for <span class="math inline">\(i=1,2,3\)</span>, then we know from probability theory that:</p>
<p><span class="math display">\[\begin{align*}
Var(Y_1) &amp; = a^{2}_{1} Var(X_1) + a^{2}_{2} Var(X_2) + 2 a_1 a_2 Cov(X_1,X_2) \\
Cov(Y_1,Y_2) &amp; = a_1 b_1 Var(X_1) + a_2 b_2 Var(X_2) + (a_1 b_2 + a_2 b_1) Cov(X_1,X_2)
\end{align*}\]</span>
Applying these identities to Model C, we first see that we can ignore all fixed effects, since they do not contribute to the variability. Thus,</p>
<p><span class="math display">\[\begin{align*}
Var(Y_{ij}) &amp; = Var(u_{i}+v_{i}\textrm{Year08}_{ij}+\epsilon_{ij}) \\
 &amp; = Var(u_{i}) + \textrm{Year08}^{2}_{ij} Var(v_{i}) + Var(\epsilon_{ij}) + 2\textrm{Year08}_{ij} Cov(u_{i},v_{i}) \\
 &amp; = \sigma_{u}^{2} + \textrm{Year08}^{2}_{ij} \sigma_{v}^{2} + \sigma^{2} + 2\textrm{Year08}_{ij}\sigma_{uv} \\
 &amp; = \sigma_{u}^{2} + t^{2}_{j} \sigma_{v}^{2} + \sigma^{2} + 2t_{j}\sigma_{uv}
\end{align*}\]</span>
where the last line reflects the fact that observations were taken at the same time points for all schools. We can derive the covariance terms in a similar fashion:</p>
<p><span class="math display">\[\begin{align*}
Cov(Y_{ij},Y_{ik}) &amp; = Cov(u_{i}+ v_{i}\textrm{Year08}_{ij}+\epsilon_{ij}, u_{i}+v_{i}\textrm{Year08}_{ik}+\epsilon_{ik}) \\
 &amp; = Var(u_{i}) + \textrm{Year08}_{ij}\textrm{Year08}_{ik} Var(v_{i}) + \\
 &amp; \qquad (\textrm{Year08}_{ij} + \textrm{Year08}_{ik}) Cov(u_{i},v_{i}) \\
 &amp; = \sigma_{u}^{2} + t_{j}t_{k} \sigma_{v}^{2} + (t_{j}+t_{k})\sigma_{uv}
\end{align*}\]</span></p>
<p>In Model C, we obtained the following estimates of variance components: <span class="math inline">\(\hat{\sigma}^{2}=8.784\)</span>, <span class="math inline">\(\hat{\sigma}^{2}_{u}=35.832\)</span>, <span class="math inline">\(\hat{\sigma}^{2}_{v}=0.131\)</span>, and <span class="math inline">\(\hat{\sigma}_{uv}=\hat{\rho}\hat{\sigma_{u}}\hat{\sigma_{v}}=1.907\)</span>. Therefore, our two-level model implicitly imposes this covariance structure on within-subject observations:</p>
<p><span class="math display">\[ Cov(\mathbf{Y}_i) =  \left[
          \begin{array}{cccc}
            44.62 &amp; &amp;   \\
            37.74 &amp; 48.56 &amp;  \\
            39.65 &amp; 41.81 &amp; 52.77
          \end{array} \right] \]</span>
and this covariance matrix can be converted into a within-subject correlation matrix:</p>
<p><span class="math display">\[ Corr(\mathbf{Y}_i) =  \left[
          \begin{array}{cccc}
            1 &amp; &amp;   \\
            .811 &amp; 1 &amp;  \\
            .817 &amp; .826 &amp; 1
          \end{array} \right] \]</span></p>
</div>
</div>
<div id="notesr9" class="section level2">
<h2><span class="header-section-number">9.8</span> Notes on Using R (optional)</h2>
<p>The model below is our final model with <span class="math inline">\(\sigma_{uv}\)</span> set to 0—i.e., we have added the restriction that Level Two error terms are uncorrelated. Motivation for this restriction came from repeated estimates of correlation in different versions of the final model near 1, when empirically a slightly negative correlation might be expected. As we will describe in Chapter <a href="ch-3level.html#ch-3level">10</a>, inclusion of the Level Two correlation as a model parameter appears to lead to boundary constraints—maximum likelihood parameter estimates near the maximum or minimum allowable value for a parameter. A likelihood ratio test using full maximum likelihood estimates confirms that the inclusion of a correlation term does not lead to an improved model (LRT test statistic = .223 on 1 df, <span class="math inline">\(p=.637\)</span>); a parametric bootstrap test provides a similar result and is more trustworthy when testing a hypothesis about a variance component. Estimates of fixed effects and their standard errors are extremely consistent with the full model in Section <a href="ch-lon.html#modelf9">9.6.3</a>; only the estimate of the variability in <span class="math inline">\(\sigma_{1}\)</span> is noticeably higher.</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="ch-lon.html#cb259-1"></a><span class="co"># Modified final model</span></span>
<span id="cb259-2"><a href="ch-lon.html#cb259-2"></a>model.f2a &lt;-<span class="st"> </span><span class="kw">lmer</span>(MathAvgScore <span class="op">~</span><span class="st"> </span>charter <span class="op">+</span><span class="st"> </span>urban <span class="op">+</span><span class="st"> </span>SchPctFree <span class="op">+</span></span>
<span id="cb259-3"><a href="ch-lon.html#cb259-3"></a><span class="st">  </span>SchPctSped <span class="op">+</span><span class="st"> </span>charter<span class="op">:</span>year08 <span class="op">+</span><span class="st"> </span>urban<span class="op">:</span>year08 <span class="op">+</span></span>
<span id="cb259-4"><a href="ch-lon.html#cb259-4"></a><span class="st">  </span>SchPctSped<span class="op">:</span>year08 <span class="op">+</span><span class="st"> </span>year08 <span class="op">+</span></span>
<span id="cb259-5"><a href="ch-lon.html#cb259-5"></a><span class="st">  </span>(<span class="dv">1</span><span class="op">|</span>schoolid) <span class="op">+</span><span class="st"> </span>(<span class="dv">0</span><span class="op">+</span>year08<span class="op">|</span>schoolid), <span class="dt">REML=</span>T, <span class="dt">data=</span>chart.long)</span></code></pre></div>
<pre><code>##  Groups     Name        Variance Std.Dev.
##  schoolid   (Intercept) 17.355   4.166   
##  schoolid.1 year08       0.114   0.337   
##  Residual                8.716   2.952</code></pre>
<pre><code>##  Number of Level Two groups =  618</code></pre>
<pre><code>##                    Estimate Std. Error  t value
## (Intercept)       661.01770   0.515461 1282.381
## charter            -3.22468   0.703174   -4.586
## urban              -1.11663   0.430422   -2.594
## SchPctFree         -0.15295   0.008096  -18.890
## SchPctSped         -0.11777   0.020739   -5.679
## year08              2.14271   0.202090   10.603
## charter:year08      1.03341   0.317174    3.258
## urban:year08       -0.52442   0.187678   -2.794
## SchPctSped:year08  -0.04672   0.010219   -4.572</code></pre>
<pre><code>##  AIC =  9883 ;  BIC =  9948</code></pre>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="ch-lon.html#cb264-1"></a><span class="co"># LRT comparing final model in chapter (model.f2ml) with maximum</span></span>
<span id="cb264-2"><a href="ch-lon.html#cb264-2"></a><span class="co">#  likelihood estimates to modified final model (model.f2aml)</span></span>
<span id="cb264-3"><a href="ch-lon.html#cb264-3"></a><span class="co">#  with uncorrelated Level Two errors.</span></span>
<span id="cb264-4"><a href="ch-lon.html#cb264-4"></a>drop_in_dev &lt;-<span class="st"> </span><span class="kw">anova</span>(model.f2ml, model.f2aml, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>            npar  AIC  BIC logLik  dev  Chisq Df
model.f2aml   12 9855 9921  -4916 9831     NA NA
model.f2ml    13 9857 9928  -4916 9831 0.2231  1
              pval
model.f2aml     NA
model.f2ml  0.6367</code></pre>
</div>
<div id="exercises-8" class="section level2">
<h2><span class="header-section-number">9.9</span> Exercises</h2>
<div id="conceptual-exercises-6" class="section level3">
<h3><span class="header-section-number">9.9.1</span> Conceptual Exercises</h3>
<ol style="list-style-type: decimal">
<li><p><strong>Parenting and gang activity.</strong> <span class="citation">Walker-Barnes and Mason (<a href="#ref-Walker-Barnes2001" role="doc-biblioref">2001</a>)</span> describe, “Ethnic differences in the effect of parenting on gang involvement and gang delinquency: a longitudinal, hierarchical linear modeling perspective”. In this study, 300 ninth graders from one high school in an urban southeastern city were assessed at the beginning of the school year about their gang activity, the gang activity of their peers, behavior of their parents, and their ethnic and cultural heritage. Then, information about their gang activity was collected at 7 additional occasions during the school year. For this study: (a) give the observational units at Level One and Level Two, and (b) list potential explanatory variables at both Level One and Level Two.</p></li>
<li><p>Describe the difference between the wide and long formats for longitudinal data in this study.</p></li>
<li><p>Describe scenarios or research questions in which a lattice plot would be more informative than a spaghetti plot, and other scenarios or research questions in which a spaghetti plot would be preferable to a lattice plot.</p></li>
<li><p>Walker-Barnes and Mason summarize their analytic approach in the following way, where HLM = hierarchical linear models, a synonym for multilevel models:</p>
<p><em>The first series [of analyses] tested whether there was overall change and/or significant individual variability in gang [activity] over time, regardless of parenting behavior, peer behavior, or ethnic and cultural heritage. Second, given the well documented relation between peer and adolescent behavior . . . HLM analyses were conducted examining the effect of peer gang [activity] on [initial gang activity and] changes in gang [activity] over time. Finally, four pairs of analyses were conducted examining the role of each of the four parenting variables on [initial gang activity and] changes in gang [activity].</em></p>
<p>The last series of analyses controlled for peer gang activity and ethnic and cultural heritage, in addition to examining interactions between parenting and ethnic and cultural heritage.</p>
<p>Although the authors examined four parenting behaviors—behavioral control, lax control, psychological control, and parental warmth—they did so one at a time, using four separate multilevel models. Based on their description, write out a sample model from each of the three steps in the series. For each model, (a) write out the two-level model for predicting gang activity, (b) write out the corresponding composite model, and (c) determine how many model parameters (fixed effects and variance components) must be estimated.</p></li>
<li><p>Table <a href="ch-lon.html#tab:table4chp9">9.5</a> shows a portion of Table 2: Results of Hierarchical Linear Modeling Analyses Modeling Gang Involvement from <span class="citation">Walker-Barnes and Mason (<a href="#ref-Walker-Barnes2001" role="doc-biblioref">2001</a>)</span>. Provide interpretations of significant coefficients in context.</p></li>
</ol>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:table4chp9">Table 9.5: </span>A portion of Table 2: Results of Hierarchical Linear Modeling Analyses Modeling Gang Involvement from Walker-Barnes and Mason (2001).
</caption>
<thead>
<tr>
<th style="text-align:left;">
Predictor
</th>
<th style="text-align:left;">
Coefficient
</th>
<th style="text-align:left;">
SE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
Intercept (initial status)
</td>
<td style="text-align:left;font-weight: bold;">
</td>
<td style="text-align:left;font-weight: bold;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Base (intercept for predicting int term)
</td>
<td style="text-align:left;">
-.219
</td>
<td style="text-align:left;">
.160
</td>
</tr>
<tr>
<td style="text-align:left;">
Peer behavior
</td>
<td style="text-align:left;">
.252**
</td>
<td style="text-align:left;">
.026
</td>
</tr>
<tr>
<td style="text-align:left;">
Black ethnicity
</td>
<td style="text-align:left;">
.671*
</td>
<td style="text-align:left;">
.289
</td>
</tr>
<tr>
<td style="text-align:left;">
White/Other ethnicity
</td>
<td style="text-align:left;">
.149
</td>
<td style="text-align:left;">
.252
</td>
</tr>
<tr>
<td style="text-align:left;">
Parenting
</td>
<td style="text-align:left;">
.076
</td>
<td style="text-align:left;">
.050
</td>
</tr>
<tr>
<td style="text-align:left;">
Black ethnicity X parenting
</td>
<td style="text-align:left;">
-.161+
</td>
<td style="text-align:left;">
.088
</td>
</tr>
<tr>
<td style="text-align:left;">
White/Other ethnicity X parenting
</td>
<td style="text-align:left;">
-.026
</td>
<td style="text-align:left;">
.082
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Slope (change)
</td>
<td style="text-align:left;font-weight: bold;">
</td>
<td style="text-align:left;font-weight: bold;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Base (intercept for predicting slope term)
</td>
<td style="text-align:left;">
.028
</td>
<td style="text-align:left;">
.030
</td>
</tr>
<tr>
<td style="text-align:left;">
Peer behavior
</td>
<td style="text-align:left;">
-.011*
</td>
<td style="text-align:left;">
.005
</td>
</tr>
<tr>
<td style="text-align:left;">
Black ethnicity
</td>
<td style="text-align:left;">
-.132*
</td>
<td style="text-align:left;">
.054
</td>
</tr>
<tr>
<td style="text-align:left;">
White/Other ethnicity
</td>
<td style="text-align:left;">
-.059
</td>
<td style="text-align:left;">
.046
</td>
</tr>
<tr>
<td style="text-align:left;">
Parenting
</td>
<td style="text-align:left;">
-.015+
</td>
<td style="text-align:left;">
.009
</td>
</tr>
<tr>
<td style="text-align:left;">
Black ethnicity X parenting
</td>
<td style="text-align:left;">
.048**
</td>
<td style="text-align:left;">
.017
</td>
</tr>
<tr>
<td style="text-align:left;">
White/Other ethnicity X parenting
</td>
<td style="text-align:left;">
.016
</td>
<td style="text-align:left;">
.015
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> These columns focus on the parenting behavior of psychological control.
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> Table reports values for coefficients in the final model with all
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> variables entered. * p&lt;.05; ** p&lt;.01; + p&lt;.10
</td>
</tr>
</tfoot>
</table>
<ol start="6" style="list-style-type: decimal">
<li><p><strong>Charter schools.</strong> Differences exist in both sets of boxplots in Figure <a href="ch-lon.html#fig:lon-box2">9.12</a>. What do these differences imply for multilevel modeling?</p></li>
<li><p>What implications do the scatterplots in Figures <a href="ch-lon.html#fig:lon-boxcatmat1">9.14</a> (b) and (c) have for multilevel modeling? What implications does the boxplot in Figure <a href="ch-lon.html#fig:lon-boxcatmat1">9.14</a> (a) have?</p></li>
<li><p>What are the implications of Figure <a href="ch-lon.html#fig:lon-boxmat1">9.15</a> for multilevel modeling?</p></li>
<li><p>Sketch a set of boxplots to indicate an obvious interaction between percent special education and percent non-white in modeling 2008 math scores. Where would this interaction appear in the multilevel model?</p></li>
<li><p>In Model A, <span class="math inline">\(\sigma^2\)</span> is defined as the variance in within-school deviations and <span class="math inline">\(\sigma^2_u\)</span> is defined as the variance in between-school deviations. Give potential sources of within-school and between-school deviations.</p></li>
<li><p>In Chapter <a href="ch-multilevelintro.html#ch-multilevelintro">8</a> Model B is called the “random slopes and intercepts model”, while in this chapter Model B is called the “unconditional growth model”. Are these models essentially the same or systematically different? Explain.</p></li>
<li><p>In Section <a href="ch-lon.html#modelb9">9.5.2</a>, why don’t we examine the pseudo R-squared value for Level Two?</p></li>
<li><p>If we have test score data from 2001-2010, explain how we’d create new variables to fit a piecewise model.</p></li>
<li><p>In Section <a href="ch-lon.html#modeld">9.6.2</a>, could we have used percent free and reduced lunch as a Level One covariate rather than 2010 percent free and reduced lunch as a Level Two covariate? If so, explain how interpretations would have changed. What if we had used average percent free and reduced lunch over all three years or 2008 percent free and reduced lunch instead of 2010 percent free and reduced lunch. How would this have changed the interpretation of this term?</p></li>
<li><p>In Section <a href="ch-lon.html#modeld">9.6.2</a>, why do we look at a 10% increase in the percentage of students receiving free and reduced lunch when interpreting <span class="math inline">\(\hat{\alpha}_{2}\)</span>?</p></li>
<li><p>In Section <a href="ch-lon.html#modelf9">9.6.3</a>, if the gap in 2008 math scores between charter and non-charter schools differed for schools of different poverty levels (as measured by percent free and reduced lunch), how would the final model have differed?</p></li>
<li><p>Explain in your own words why “the error structure at Level Two is <em>not</em> the same as the within-school covariance structure among observations”.</p></li>
<li><p>Here is the estimated unstructured covariance matrix for Model C:</p>
<p><span class="math display">\[ Cov(\mathbf{Y}_i) =  \left[
      \begin{array}{cccc}
        41.87 &amp; &amp;   \\
        36.46 &amp; 48.18 &amp;  \\
        35.20 &amp; 39.84 &amp; 45.77
      \end{array} \right] \]</span>
Explain why this matrix cannot represent an estimated covariance matrix with a compound symmetry, autoregressive, or Toeplitz structure. Also explain why it cannot represent our standard two-level model.</p></li>
</ol>
</div>
<div id="guided-exercises-7" class="section level3">
<h3><span class="header-section-number">9.9.2</span> Guided Exercises</h3>
<ol style="list-style-type: decimal">
<li><p><strong>Teen alcohol use.</strong> <span class="citation">Curran, Stice, and Chassin (<a href="#ref-Curran1997" role="doc-biblioref">1997</a>)</span> collected data on 82 adolescents at three time points starting at age 14 to assess factors that affect teen drinking behavior. Key variables in the data set <code>alcohol.csv</code> (accessed via <span class="citation">Singer and Willett (<a href="#ref-Singer2003" role="doc-biblioref">2003</a>)</span>) are as follows:</p>
<ul>
<li><code>id</code> = numerical identifier for subject</li>
<li><code>age</code> = 14, 15, or 16</li>
<li><code>coa</code> = 1 if the teen is a child of an alcoholic parent; 0 otherwise</li>
<li><code>male</code> = 1 if male; 0 if female</li>
<li><code>peer</code> = a measure of peer alcohol use, taken when each subject was 14. This is the square root of the
sum of two 6-point items about the proportion of friends who drink occasionally or regularly.</li>
<li><code>alcuse</code> = the primary response. Four items—(a) drank beer or wine, (b) drank hard liquor, (c) 5 or
more drinks in a row, and (d) got drunk—were each scored on an 8-point scale, from 0=“not at all” to
7=“every day”. Then <code>alcuse</code> is the square root of the sum of these four items.
</ul></li>
</ul>
<p>Primary research questions included: Do trajectories of alcohol use differ by parental alcoholism? Do trajectories of alcohol use differ by peer alcohol use?</p>
<ol style="list-style-type: lower-alpha">
<li><p>Identify Level One and Level Two predictors.</p></li>
<li><p>Perform a quick EDA. What can you say about the shape of <code>alcuse</code>, and the relationship between <code>alcuse</code> and <code>coa</code>, <code>male</code>, and <code>peer</code>? Appeal to plots and summary statistics in making your statements.</p></li>
<li><p>Generate a plot as in Figure <a href="ch-lon.html#fig:lon-lat1">9.4</a> with alcohol use over time for all 82 subjects. Comment.</p></li>
<li><p>Generate three spaghetti plots with loess fits similar to Figure <a href="ch-lon.html#fig:lon-spag3">9.7</a> (one for <code>coa</code>, one for <code>male</code>, and one after creating a binary variable from <code>peer</code>). Comment on what you can conclude from each plot.</p></li>
<li><p>Fit a linear trend to the data from each of the 82 subjects using <code>age</code> as the time variable. Generate histograms as in Figure <a href="ch-lon.html#fig:lon-histmat1">9.10</a> showing the results of these 82 linear regression lines, and generate pairs of boxplots as in Figure <a href="ch-lon.html#fig:lon-box2">9.12</a> for <code>coa</code> and <code>male</code>. No commentary necessary. [Hint: to produce Figure <a href="ch-lon.html#fig:lon-box2">9.12</a>, you will need a data frame with one observation per subject.]</p></li>
<li><p>Repeat (e) using centered age (<code>age14 = age - 14</code>) as the time variable. Also generate a pair of scatterplots as in Figure <a href="ch-lon.html#fig:lon-boxcatmat1">9.14</a> for peer alcohol use. Comment on trends you observe in these plots. [Hint: after forming <code>age14</code>, append it to your current data frame.]</p></li>
<li><p>Discuss similarities and differences between (e) and (f). Why does using <code>age14</code> as the time variable make more sense in this example?</p></li>
<li><p>(Model A) Run an unconditional means model. Report and interpret the intraclass correlation coefficient.</p></li>
<li><p>(Model B) Run an unconditional growth model with <code>age14</code> as the time variable at Level One. Report and interpret estimated fixed effects, using proper notation. Also report and interpret a pseudo R-squared value.</p></li>
<li><p>(Model C) Build upon the unconditional growth model by adding the effects of having an alcoholic parent and peer alcohol use in both Level Two equations. Report and interpret all estimated fixed effects, using proper notation.</p></li>
<li><p>(Model D) Remove the child of an alcoholic indicator variable as a predictor of slope in Model C (it will still be a predictor of intercept). Write out Model D as both a two-level and a composite model using proper notation (including error distributions); how many parameters (fixed effects and variance components) must be estimated? Compare Model D to Model C using an appropriate method and state a conclusion.</p></li>
</ol></li>
<li><p><strong>Ambulance diversions</strong>. One response to emergency department overcrowding is “ambulance diversion”—closing its doors and forcing ambulances to bring patients to alternative hospitals. The California Office of Statewide Health Planning and Development collected data on how often hospitals enacted “diversion status”, enabling researchers to investigate factors associated with increasing amounts of ambulance diversions. An <a href="https://www.causeweb.org/usproc/usclap/2019/spring/winners">award-winning</a> student project <span class="citation">(Fisher, Murney, and Radtke <a href="#ref-Radtke2019" role="doc-biblioref">2019</a>)</span> examined a data set (<code>ambulance3.csv</code>) which contains the following variables from 184 California hospitals over a 3-year period (2013-2015):</p>
<ul>
<li><code>diverthours</code> = number of hours of diversion status over the year (response)</li>
<li><code>year2013</code> = year (centered at 2013)</li>
<li><code>totalvisits1</code> = total number of patient visits to the emergency department over the year (in 1000s)</li>
<li><code>ems_basic</code> = 1 if the emergency department can only handle a basic level of severity; 0 if the emergency department can handle higher levels of severity</li>
<li><code>stations</code> = number of emergency department stations available for patients (fixed over 3 years)</li>
</ul>
<ol style="list-style-type: lower-alpha">
<li><p>State the observational units at Level One and Level Two in this study, then state the explanatory variables at each level from the list above.</p></li>
<li><p>Create latticed spaghetti plots that illustrate the relationship between diversion hours and (i) EMS level, and (ii) number of stations (divided into “high” and “low”). Describe terms that might be worth testing in your final model based on these plots.</p></li>
<li><p>Write out an unconditional growth model, where <span class="math inline">\(Y_{ij}\)</span> is the number of diversion hours for the <span class="math inline">\(i^{th}\)</span> hospital in the <span class="math inline">\(j^{th}\)</span> year. Interpret both <span class="math inline">\(a_i\)</span> and <span class="math inline">\(v_i\)</span> in the context of this problem (using words – no numbers necessary).</p></li>
<li><p>In Model E (see R code at the end of these problems), focus on the <code>ems_basic:year2013</code> interaction term.</p></li>
</ol>
<ul>
<li>provide a careful interpretation in context.</li>
<li>why are there no p-values for testing significance in the <code>lmer()</code> output?</li>
<li>confidence intervals can be formed for parameters in Model E using two different methods. What can we conclude about the significance of the interaction from the CIs? Be sure to make a statement about significance in context; no need to interpret the CI itself.</li>
</ul>
<ol start="5" style="list-style-type: lower-alpha">
<li><p>Write out Model G in terms of its Level 1 and Level 2 equations (see R code at the end of these problems). Be sure to use proper subscripts everywhere, and be sure to also provide expressions for any assumptions made about error terms. How many total parameters must be estimated?</p></li>
<li><p>In Model G, provide careful interpretations in context for the coefficient estimates of <code>year2013</code> and <code>stations</code>.</p></li>
<li><p>We wish to compare Models D and D0.</p></li>
</ol>
<ul>
<li>Write out null and alternative hypotheses in terms of model parameters.</li>
<li>State a conclusion based on a likelihood ratio test.</li>
<li>State a conclusion based on a parametric bootstrap.</li>
<li>Generate a plot that compares the null distributions and p-values for the likelihood ratio test and parametric bootstrap.</li>
<li>Why might we consider using a parametric bootstrap p-value rather than a likelihood ratio test p-value?</li>
<li>Show how you would produce a bootstrapped value for <span class="math inline">\(Y_{11}\)</span>, the first row of <code>ambulance3.csv</code>. Show all calculations with as many specific values filled in as possible. If you need to select a random value from a normal distribution, identify the mean and SD for the normal distribution you’d like to sample from.</li>
</ul></li>
</ol>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="ch-lon.html#cb266-1"></a>modelD &lt;-<span class="st"> </span><span class="kw">lmer</span>(diverthours <span class="op">~</span><span class="st"> </span>year2013 <span class="op">+</span><span class="st"> </span>ems_basic <span class="op">+</span><span class="st"> </span></span>
<span id="cb266-2"><a href="ch-lon.html#cb266-2"></a><span class="st">  </span>(year2013 <span class="op">|</span><span class="st"> </span>id), <span class="dt">data =</span> ambulance3)</span>
<span id="cb266-3"><a href="ch-lon.html#cb266-3"></a></span>
<span id="cb266-4"><a href="ch-lon.html#cb266-4"></a>modelD0 &lt;-<span class="st"> </span><span class="kw">lmer</span>(diverthours <span class="op">~</span><span class="st"> </span>year2013 <span class="op">+</span><span class="st"> </span>ems_basic <span class="op">+</span><span class="st"> </span></span>
<span id="cb266-5"><a href="ch-lon.html#cb266-5"></a><span class="st">  </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id), <span class="dt">data =</span> ambulance3)</span>
<span id="cb266-6"><a href="ch-lon.html#cb266-6"></a></span>
<span id="cb266-7"><a href="ch-lon.html#cb266-7"></a>modelE &lt;-<span class="st"> </span><span class="kw">lmer</span>(diverthours <span class="op">~</span><span class="st"> </span>year2013 <span class="op">+</span><span class="st"> </span>ems_basic <span class="op">+</span></span>
<span id="cb266-8"><a href="ch-lon.html#cb266-8"></a><span class="st">  </span>ems_basic<span class="op">:</span>year2013 <span class="op">+</span><span class="st"> </span>(year2013 <span class="op">|</span><span class="st"> </span>id), <span class="dt">data =</span> ambulance3)</span>
<span id="cb266-9"><a href="ch-lon.html#cb266-9"></a></span>
<span id="cb266-10"><a href="ch-lon.html#cb266-10"></a>modelG &lt;-<span class="st"> </span><span class="kw">lmer</span>(diverthours <span class="op">~</span><span class="st"> </span>year2013 <span class="op">+</span><span class="st"> </span>totalvisits1 <span class="op">+</span><span class="st"> </span></span>
<span id="cb266-11"><a href="ch-lon.html#cb266-11"></a><span class="st">  </span>ems_basic <span class="op">+</span><span class="st"> </span>stations <span class="op">+</span><span class="st"> </span>ems_basic<span class="op">:</span>year2013 <span class="op">+</span><span class="st"> </span></span>
<span id="cb266-12"><a href="ch-lon.html#cb266-12"></a><span class="st">  </span>stations<span class="op">:</span>year2013 <span class="op">+</span><span class="st"> </span>(year2013 <span class="op">|</span><span class="st"> </span>id), <span class="dt">data =</span> ambulance3)</span></code></pre></div>
</div>
<div id="open-ended-exercises-5" class="section level3">
<h3><span class="header-section-number">9.9.3</span> Open-Ended Exercises</h3>
<ol style="list-style-type: decimal">
<li><p><strong>UCLA nurse blood pressure study.</strong> A study by <span class="citation">Goldstein and Shapiro (<a href="#ref-Goldstein2000" role="doc-biblioref">2000</a>)</span> collected information from 203 registered nurses in the Los Angeles area between 24 and 50 years of age on blood pressure (BP) and potential factors that contribute to hypertension. This information includes family history, and whether the subject had one or two hypertensive parents, as well as a wide range of measures of the physical and emotional condition of each nurse throughout the day. Researchers sought to study the links between BP and family history, personality, mood changes, working status, and menstrual phase.</p>
<p>Data from this study provided by <span class="citation">Weiss (<a href="#ref-Weiss2005" role="doc-biblioref">2005</a>)</span> includes observations (40-60 per nurse) repeatedly taken on the 203 nurses over the course of a single day. The first BP measurement was taken half an hour before the subject’s normal start of work, and BP was then measured approximately every 20 minutes for the rest of the day. At each BP reading, the nurses also rate their mood on several dimensions, including how stressed they feel at the moment the BP is taken. In addition, the activity of each subject during the 10 minutes before each reading was measured using an actigraph worn on the waist. Each of the variables in <code>nursebp.csv</code> is described below:</p>
<ul>
<li><code>SNUM</code>: subject identification number</li>
<li><code>SYS</code>: systolic blood pressure (mmHg)</li>
<li><code>DIA</code>: diastolic blood pressure (mmHg)</li>
<li><code>HRT</code>: heart rate (beats per minute)</li>
<li><code>MNACT5</code>: activity level (frequency of movements in 1-minute intervals, over a 10-minute period )</li>
<li><code>PHASE</code>: menstrual phase (follicular—beginning with the end of menstruation and ending with ovulation, or luteal—beginning with ovulation and ending with pregnancy or menstruation)</li>
<li><code>DAY</code>: workday or non-workday</li>
<li><code>POSTURE</code>: position during BP measurement—either sitting, standing, or reclining</li>
<li><code>STR</code>, <code>HAP</code>, <code>TIR</code>: self-ratings by each nurse of their level of stress, happiness and tiredness at the time of each BP measurement on a 5-point scale, with 5 being the strongest sensation of that feeling and 1 the weakest</li>
<li><code>AGE</code>: age in years</li>
<li><code>FH123</code>: coded as either NO (no family history of hypertension), YES (1 hypertensive parent), or YESYES (both parents hypertensive)</li>
<li><code>time</code>: in minutes from midnight</li>
<li><code>timept</code>: number of the measurement that day (approximately 50 for each subject)</li>
<li><code>timepass</code>: time in minutes beginning with 0 at time point 1
</ul></li>
</ul>
<p>Using systolic blood pressure as the primary response, write a short report detailing factors that are significantly associated with higher systolic blood pressure. Be sure to support your conclusions with appropriate exploratory plots and multilevel models. In particular, how are work conditions—activity level, mood, and work status—related to trends in BP levels? As an appendix to your report, describe your modeling process—how did you arrive at your final model, which covariates are Level One or Level Two, what did you learn from exploratory plots, etc.?</p>
<p>Potential alternative directions: consider diastolic blood pressure or heart rate as the primary response variable, or even try modeling emotion rating using a multilevel model.</p></li>
<li><p><strong>Completion rates at U.S. colleges.</strong> Education researchers wonder which factors most affect the completion rates at U.S. colleges. Using the IPEDS database containing data from 1310 institutions over the years 2002-2009 <span class="citation">(National Center for Education Statistics <a href="#ref-IPEDS" role="doc-biblioref">2018</a>)</span>, the following variables were assembled in <code>colleges.csv</code>:</p>
<ul>
<li><code>id</code> = unique identification number for each college or university
</ul></li>
</ul>
<p>Response:</p>
<ul>
<li><code>rate</code> = completion rate (number of degrees awarded per 100 students enrolled)
</ul></li>
</ul>
<p>Level 1 predictors:</p>
<ul>
<li><code>year</code></li>
<li><code>instpct</code> = percentage of students who receive an institutional grant</li>
<li><code>instamt</code> = typical amount of an institutional grant among recipients (in $1000s)
</ul></li>
</ul>
<p>Level 2 predictors:</p>
<ul>
<li><code>faculty</code> = mean number of full-time faculty per 100 students during 2002-2009</li>
<li><code>tuition</code> = mean yearly tuition during 2002-2009 (in $1000s)
</ul></li>
</ul>
<p>Perform exploratory analyses and run multilevel models to determine significant predictors of baseline (2002) completion rates and changes in completion rates between 2002 and 2009. In particular, is the percentage of grant recipients or the average institutional grant awarded related to completion rate?</p></li>
<li><p><strong>Beating the Blues.</strong> Depression is a common mental disorder affecting approximately 121 million people worldwide, making it one of the leading causes of disability. Evidence has shown that cognitive behavioral therapy (CBT) can be an effective treatment, but delivery of the usual face-to-face treatment is expensive and dependent on the availability of trained therapists. As a result, Proudfoot et al. <span class="citation">(<a href="#ref-Proudfoot2003" role="doc-biblioref">2003</a>)</span> developed and studied an interactive multimedia program of CBT called Beating the Blues (BtheB). In their study, 167 participants suffering from anxiety and/or depression were randomly allocated to receive BtheB therapy or treatment as usual (TAU). BtheB consisted of 8, 50-minute computerized weekly sessions with “homework” projects between sessions, while treatment as usual consisted of whatever treatment the patient’s general practitioner (GP) prescribed, including drug treatment or referral to a counselor. Subjects in the BtheB group could also receive pharmacotherapy if prescribed by their GP (who reviewed a computer-generated progress report after each subject’s session), but they could not receive face-to-face counseling. The primary response was the Beck Depression Inventory (BDI), measured prior to treatment, at the end of treatment (2 months later), and at 2, 4, and 6 months post-treatment follow-up. Researchers wished to examine the effect of treatment on depression levels, controlling for potential explanatory variables such as baseline BDI, if the patient took anti-depressant drugs, and the length of the current episode of depression (more or less than 6 months). Was treatment effective in both the active treatment phase and the post-treatment follow-up?</p>
<p>Data from the BtheB study can be found in <code>BtheB.csv</code>; it is also part of the <code>HSAUR</code> package <span class="citation">(Everitt and Hothorn <a href="#ref-Everitt2006" role="doc-biblioref">2006</a>)</span> in R. Examination of the data reveals the following variables:</p>
<ul>
<li><code>drug</code> = Was the subject prescribed concomitant drug therapy?</li>
<li><code>length</code> = Was the current episode of depression (at study entry) longer or shorter than 6 months?</li>
<li><code>treatment</code> = TAU or BtheB</li>
<li><code>bdi.pre</code> = Baseline BDI at time of study entry (before treatment began)</li>
<li><code>bdi.2m</code> = BDI level after 2 months (at the end of treatment phase)</li>
<li><code>bdi.4m</code> = BDI level after 4 months (or 2 months after treatment ended)</li>
<li><code>bdi.6m</code> = BDI level after 6 months (or 4 months after treatment ended)</li>
<li><code>bdi.8m</code> = BDI level after 8 months (or 6 months after treatment ended)</li>
</ul>
<p>Things to consider when analyzing data from this case study:</p>
<ul>
<li>Examine patterns of missing data.</li>
<li>Convert to LONG form (and eliminate subjects with no post-baseline data).</li>
<li>Exploratory data analyses, including lattice, spaghetti, and correlation plots.</li>
<li>Set time 0 to be 2 months into the study (then the intercept represents BDI level at the end of active treatment, while the slope represents change in BDI level over the posttreatment follow-up).</li>
<li>Note that treatment is the variable of primary interest, while baseline BDI, concomitant drug use, and length of previous episode are confounding variables.</li>
</ul></li>
</ol>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Buddin2005">
<p>Buddin, Richard, and Ron Zimmer. 2005. “Student Achievement in Charter Schools: A Complex Picture.” <em>Journal of Policy Analysis and Management</em> 24 (2): 351–71. <a href="http://dx.doi.org/10.1002/pam.20093">http://dx.doi.org/10.1002/pam.20093</a>.</p>
</div>
<div id="ref-Curran1997">
<p>Curran, Patrick J., Eric Stice, and Laurie Chassin. 1997. “The Relation Between Adolescent Alcohol Use and Peer Alcohol Use: A Longitudinal Random Coefficients Model.” <em>Journal of Consulting and Clinical Psychology</em> 65 (1): 130–40. <a href="http://dx.doi.org/10.1037/0022-006X.65.1.130">http://dx.doi.org/10.1037/0022-006X.65.1.130</a>.</p>
</div>
<div id="ref-Everitt2006">
<p>Everitt, Brian S., and Torsten Hothorn. 2006. <em>A Handbook of Statistical Analyses Using R</em>. Boca Raton, FL: Chapman &amp; Hall/ CRC.</p>
</div>
<div id="ref-Faraway2005">
<p>Faraway, Julian. 2005. <em>Extending the Linear Model with R: Generalized Linear, Mixed Effects and Nonparametric Regression Models</em>. Boca Raton, FL: Chapman &amp; Hall/ CRC.</p>
</div>
<div id="ref-Finnigan2004">
<p>Finnigan, Kara, Nancy Adelman, Lee Anderson, Lynyonne Cotton, Mary Beth Donnelly, and Tiffany Price. 2004. <em>Evaluation of Public Charter Schools Program: Final Evaluation Report</em>. Washington, D.C.: U.S. Department of Education.</p>
</div>
<div id="ref-Radtke2019">
<p>Fisher, Lisa, Katie Murney, and Tyler Radtke. 2019. “Emergency Department Overcrowding and Factors That Contribute to Ambulance Diversion.”</p>
</div>
<div id="ref-Goldstein2000">
<p>Goldstein, I. B., and D. Shapiro. 2000. “Ambulatory Blood Pressure in Women: Family History of Hypertension and Personality.” <em>Psychology, Health &amp; Medicine</em> 5 (3): 227–40. <a href="https://doi.org/10.1080/713690197">https://doi.org/10.1080/713690197</a>.</p>
</div>
<div id="ref-Green2003">
<p>Green III, Preston C., Bruce D. Baker, and Joseph O. Oluwole. 2003. “Having It Both Ways: How Charter Schools Try to Obtain Funding of Public Schools and the Autonomy of Private Schools.” <em>Emory Law Journal</em> 63 (2): 303–37.</p>
</div>
<div id="ref-KIPP">
<p>KIPP. 2018. “KIPP North Star Academy.” <a href="http://www.kipp.org/school/kipp-north-star-academy/">http://www.kipp.org/school/kipp-north-star-academy/</a>.</p>
</div>
<div id="ref-Laird1988">
<p>Laird, Nan M. 1988. “Missing Data in Longitudinal Studies.” <em>Statistics in Medicine</em> 7 (1-2): 305–15. <a href="http://dx.doi.org/10.1002/sim.4780070131">http://dx.doi.org/10.1002/sim.4780070131</a>.</p>
</div>
<div id="ref-MNDepartmentOfEducation">
<p>Minnesota Department of Education. 2018. “Minnesota Department of Education Data Center.” <a href="https://education.mn.gov/MDE/Data/">https://education.mn.gov/MDE/Data/</a>.</p>
</div>
<div id="ref-IPEDS">
<p>National Center for Education Statistics. 2018. “The Integrated Postsecondary Education Data System.” <a href="https://nces.ed.gov/ipeds/">https://nces.ed.gov/ipeds/</a>.</p>
</div>
<div id="ref-Proudfoot2003">
<p>Proudfoot, J, D Goldberg, A Mann, B Everitt, I Marks, and J A Gray. 2003. “Computerized, Interactive, Multimedia Cognitive-Behavioural Program for Anxiety and Depression in General Practice.” <em>Psychological Medicine</em> 33 (2): 217–27. <a href="https://doi.org/10.1017/s0033291702007225">https://doi.org/10.1017/s0033291702007225</a>.</p>
</div>
<div id="ref-Bryk2002">
<p>Raudenbush, Stephen W., and Anthony S. Bryk. 2002. <em>Hierarchical Linear Models: Applications and Data Analysis Methods</em>. 2nd ed. Thousand Oaks, CA: SAGE Publications, Inc.</p>
</div>
<div id="ref-Singer2003">
<p>Singer, Judith D., and John B. Willett. 2003. <em>Applied Longitudinal Data Analysis: Modeling Change and Event Occurrence</em>. 1st ed. New York: Oxford University Press, Inc.</p>
</div>
<div id="ref-CharterSchools">
<p>U.S. Department of Education. 2018. “National Charter School Resource Center.” <a href="https://charterschoolcenter.ed.gov/faqs">https://charterschoolcenter.ed.gov/faqs</a>.</p>
</div>
<div id="ref-Walker-Barnes2001">
<p>Walker-Barnes, Chanequa J., and Craig A. Mason. 2001. “Ethnic Differences in the Effect of Parenting on Gang Involvement and Gang Delinquency: A Longitudinal, Hierarchical Linear Modeling Perspective.” <em>Child Development</em> 72 (6): 1814–31. <a href="http://dx.doi.org/10.1111/1467-8624.00380">http://dx.doi.org/10.1111/1467-8624.00380</a>.</p>
</div>
<div id="ref-Weiss2005">
<p>Weiss, Robert E. 2005. <em>Modeling Longitudinal Data</em>. New York: Springer-Verlag.</p>
</div>
<div id="ref-Witte2007">
<p>Witte, John, David Weimer, Arnold Shober, and Paul Schlomer. 2007. “The Performance of Charter Schools in Wisconsin.” <em>Journal of Policy Analysis and Management</em> 26 (3): 557–73. <a href="http://dx.doi.org/10.1002/pam.20265">http://dx.doi.org/10.1002/pam.20265</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-multilevelintro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-3level.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
